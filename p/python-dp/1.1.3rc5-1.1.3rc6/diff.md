# Comparing `tmp/python_dp-1.1.3rc5-cp39-cp39-macosx_10_14_x86_64.whl.zip` & `tmp/python_dp-1.1.3rc6-cp39-cp39-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,33 +1,31 @@
-Zip file size: 3903168 bytes, number of entries: 31
--rw-r--r--  2.0 unx      326 b- defN 23-Feb-21 21:53 pydp/BUILD
--rw-r--r--  2.0 unx      164 b- defN 23-Feb-21 21:53 pydp/__init__.py
--rwxr-xr-x  2.0 unx 21545544 b- defN 23-Feb-21 22:04 pydp/_pydp.so
--rw-r--r--  2.0 unx      198 b- defN 23-Feb-21 21:53 pydp/algorithms/__init__.py
--rw-r--r--  2.0 unx     6381 b- defN 23-Feb-21 21:53 pydp/algorithms/_algorithm.py
--rw-r--r--  2.0 unx      193 b- defN 23-Feb-21 21:53 pydp/algorithms/numerical_mechanisms.py
--rw-r--r--  2.0 unx     2266 b- defN 23-Feb-21 21:53 pydp/algorithms/partition_selection.py
--rw-r--r--  2.0 unx       76 b- defN 23-Feb-21 21:53 pydp/algorithms/quantile_tree.py
--rw-r--r--  2.0 unx      562 b- defN 23-Feb-21 21:53 pydp/algorithms/laplacian/__init__.py
--rw-r--r--  2.0 unx     3281 b- defN 23-Feb-21 21:53 pydp/algorithms/laplacian/_bounded_algorithms.py
--rw-r--r--  2.0 unx      582 b- defN 23-Feb-21 21:53 pydp/algorithms/laplacian/_count.py
--rw-r--r--  2.0 unx      896 b- defN 23-Feb-21 21:53 pydp/algorithms/laplacian/_percentile.py
--rw-r--r--  2.0 unx       53 b- defN 23-Feb-21 21:53 pydp/distributions/__init__.py
--rw-r--r--  2.0 unx       21 b- defN 23-Feb-21 21:53 pydp/ml/__init__.py
--rw-r--r--  2.0 unx    15075 b- defN 23-Feb-21 21:53 pydp/ml/naive_bayes.py
--rw-r--r--  2.0 unx        0 b- defN 23-Feb-21 21:53 pydp/ml/mechanisms/__init__.py
--rw-r--r--  2.0 unx    10993 b- defN 23-Feb-21 21:53 pydp/ml/mechanisms/base.py
--rw-r--r--  2.0 unx     7042 b- defN 23-Feb-21 21:53 pydp/ml/mechanisms/geometric.py
--rw-r--r--  2.0 unx    13236 b- defN 23-Feb-21 21:53 pydp/ml/mechanisms/laplace.py
--rw-r--r--  2.0 unx        0 b- defN 23-Feb-21 21:53 pydp/ml/util/__init__.py
--rw-r--r--  2.0 unx    14298 b- defN 23-Feb-21 21:53 pydp/ml/util/accountant.py
--rw-r--r--  2.0 unx     5775 b- defN 23-Feb-21 21:53 pydp/ml/util/utils.py
--rw-r--r--  2.0 unx     8078 b- defN 23-Feb-21 21:53 pydp/ml/util/validation.py
--rw-r--r--  2.0 unx       60 b- defN 23-Feb-21 21:53 pydp/util/__init__.py
--rw-r--r--  2.0 unx      217 b- defN 23-Feb-21 21:53 python/BUILD
--rw-r--r--  2.0 unx        0 b- defN 23-Feb-21 21:53 python/__init__.py
--rw-r--r--  2.0 unx    11357 b- defN 23-Feb-21 22:05 python_dp-1.1.3rc5.dist-info/LICENSE
--rw-r--r--  2.0 unx     5144 b- defN 23-Feb-21 22:05 python_dp-1.1.3rc5.dist-info/METADATA
--rw-r--r--  2.0 unx      110 b- defN 23-Feb-21 22:05 python_dp-1.1.3rc5.dist-info/WHEEL
--rw-r--r--  2.0 unx       12 b- defN 23-Feb-21 22:05 python_dp-1.1.3rc5.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     2577 b- defN 23-Feb-21 22:05 python_dp-1.1.3rc5.dist-info/RECORD
-31 files, 21654517 bytes uncompressed, 3899024 bytes compressed:  82.0%
+Zip file size: 2081783 bytes, number of entries: 29
+-rw-rw-rw-  2.0 fat      174 b- defN 23-May-29 20:38 pydp/__init__.py
+-rw-rw-rw-  2.0 fat  8383488 b- defN 23-May-29 20:46 pydp/_pydp.pyd
+-rw-rw-rw-  2.0 fat      204 b- defN 23-May-29 20:38 pydp/algorithms/__init__.py
+-rw-rw-rw-  2.0 fat     6560 b- defN 23-May-29 20:38 pydp/algorithms/_algorithm.py
+-rw-rw-rw-  2.0 fat      199 b- defN 23-May-29 20:38 pydp/algorithms/numerical_mechanisms.py
+-rw-rw-rw-  2.0 fat     3484 b- defN 23-May-29 20:38 pydp/algorithms/partition_selection.py
+-rw-rw-rw-  2.0 fat       79 b- defN 23-May-29 20:38 pydp/algorithms/quantile_tree.py
+-rw-rw-rw-  2.0 fat      584 b- defN 23-May-29 20:38 pydp/algorithms/laplacian/__init__.py
+-rw-rw-rw-  2.0 fat     3376 b- defN 23-May-29 20:38 pydp/algorithms/laplacian/_bounded_algorithms.py
+-rw-rw-rw-  2.0 fat      607 b- defN 23-May-29 20:38 pydp/algorithms/laplacian/_count.py
+-rw-rw-rw-  2.0 fat      930 b- defN 23-May-29 20:38 pydp/algorithms/laplacian/_percentile.py
+-rw-rw-rw-  2.0 fat       55 b- defN 23-May-29 20:38 pydp/distributions/__init__.py
+-rw-rw-rw-  2.0 fat       22 b- defN 23-May-29 20:38 pydp/ml/__init__.py
+-rw-rw-rw-  2.0 fat    15433 b- defN 23-May-29 20:38 pydp/ml/naive_bayes.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-May-29 20:38 pydp/ml/mechanisms/__init__.py
+-rw-rw-rw-  2.0 fat    11314 b- defN 23-May-29 20:38 pydp/ml/mechanisms/base.py
+-rw-rw-rw-  2.0 fat     7254 b- defN 23-May-29 20:38 pydp/ml/mechanisms/geometric.py
+-rw-rw-rw-  2.0 fat    13659 b- defN 23-May-29 20:38 pydp/ml/mechanisms/laplace.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-May-29 20:38 pydp/ml/util/__init__.py
+-rw-rw-rw-  2.0 fat    14691 b- defN 23-May-29 20:38 pydp/ml/util/accountant.py
+-rw-rw-rw-  2.0 fat     5937 b- defN 23-May-29 20:38 pydp/ml/util/utils.py
+-rw-rw-rw-  2.0 fat     8298 b- defN 23-May-29 20:38 pydp/ml/util/validation.py
+-rw-rw-rw-  2.0 fat       62 b- defN 23-May-29 20:38 pydp/util/__init__.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-May-29 20:38 python/__init__.py
+-rw-rw-rw-  2.0 fat    11558 b- defN 23-May-29 20:48 python_dp-1.1.3rc6.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat     5276 b- defN 23-May-29 20:48 python_dp-1.1.3rc6.dist-info/METADATA
+-rw-rw-rw-  2.0 fat      100 b- defN 23-May-29 20:48 python_dp-1.1.3rc6.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       12 b- defN 23-May-29 20:48 python_dp-1.1.3rc6.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat     2443 b- defN 23-May-29 20:48 python_dp-1.1.3rc6.dist-info/RECORD
+29 files, 8495799 bytes uncompressed, 2077833 bytes compressed:  75.5%
```

## zipnote {}

```diff
@@ -1,14 +1,11 @@
-Filename: pydp/BUILD
-Comment: 
-
 Filename: pydp/__init__.py
 Comment: 
 
-Filename: pydp/_pydp.so
+Filename: pydp/_pydp.pyd
 Comment: 
 
 Filename: pydp/algorithms/__init__.py
 Comment: 
 
 Filename: pydp/algorithms/_algorithm.py
 Comment: 
@@ -66,29 +63,26 @@
 
 Filename: pydp/ml/util/validation.py
 Comment: 
 
 Filename: pydp/util/__init__.py
 Comment: 
 
-Filename: python/BUILD
-Comment: 
-
 Filename: python/__init__.py
 Comment: 
 
-Filename: python_dp-1.1.3rc5.dist-info/LICENSE
+Filename: python_dp-1.1.3rc6.dist-info/LICENSE
 Comment: 
 
-Filename: python_dp-1.1.3rc5.dist-info/METADATA
+Filename: python_dp-1.1.3rc6.dist-info/METADATA
 Comment: 
 
-Filename: python_dp-1.1.3rc5.dist-info/WHEEL
+Filename: python_dp-1.1.3rc6.dist-info/WHEEL
 Comment: 
 
-Filename: python_dp-1.1.3rc5.dist-info/top_level.txt
+Filename: python_dp-1.1.3rc6.dist-info/top_level.txt
 Comment: 
 
-Filename: python_dp-1.1.3rc5.dist-info/RECORD
+Filename: python_dp-1.1.3rc6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## pydp/__init__.py

```diff
@@ -1,10 +1,10 @@
-# stdlib
-import sys
-
-# pydp absolute
-from pydp import algorithms
-from pydp import distributions
-from pydp import util
-from pydp import ml
-
-__version__ = "1.1.3rc5"
+# stdlib
+import sys
+
+# pydp absolute
+from pydp import algorithms
+from pydp import distributions
+from pydp import util
+from pydp import ml
+
+__version__ = "1.1.3rc6"
```

## pydp/algorithms/__init__.py

 * *Ordering differences only*

```diff
@@ -1,6 +1,6 @@
-# pydp relative
-from . import laplacian
-from . import partition_selection
-from . import numerical_mechanisms
-
-__all__ = ["laplacian", "partition_selection", "numerical_mechanisms", "quantile_tree"]
+# pydp relative
+from . import laplacian
+from . import partition_selection
+from . import numerical_mechanisms
+
+__all__ = ["laplacian", "partition_selection", "numerical_mechanisms", "quantile_tree"]
```

## pydp/algorithms/_algorithm.py

 * *Ordering differences only*

```diff
@@ -1,179 +1,179 @@
-# stdlib
-import math
-from typing import List
-from typing import Union
-
-# pydp relative
-from .._pydp import _algorithms
-
-
-class MetaAlgorithm:
-    def __init__(self, **kwargs):
-        dtype = kwargs.pop("dtype")
-
-        for arg_name in ["lower_bound", "upper_bound"]:
-            if arg_name in kwargs:
-                if kwargs[arg_name] is None:
-                    # Delete bound params if they are not set to avoid conflicts with builder
-                    kwargs.pop(arg_name)
-                else:
-                    # If they are set, check for edge cases
-                    self.__check_input(name=arg_name, value=kwargs[arg_name])
-
-        binded_class = self.__class__.__name__ + self.__map_dtype_str(dtype)
-        class_ = getattr(_algorithms, binded_class)
-
-        self.dtype = dtype
-        self.__algorithm = class_(**kwargs)
-        self._l0_sensitivity = kwargs.get("l0_sensitivity", "Not set")
-        self._linf_sensitivity = kwargs.get("linf_sensitivity", "Not set")
-
-    @staticmethod
-    def __check_input(name: str, value: float):
-        if math.isnan(value) or math.isinf(value):
-            raise ValueError(f"invalid value '{value}' for paramater '{name}'.")
-
-    @staticmethod
-    def __map_dtype_str(dtype: str):
-        if dtype == "int":
-            return "Int"
-        elif dtype == "int64":
-            return "Int64"
-        elif dtype == "float":
-            return "Double"
-        else:
-            raise ValueError(f"dtype '{dtype}' is not supported.")
-
-    @property
-    def epsilon(self) -> float:
-        """
-        Returns the epsilon set at initialization.
-        """
-        return self.__algorithm.epsilon
-
-    @property
-    def delta(self) -> float:
-        """
-        Returns the epsilon set at initialization.
-        """
-        return self.__algorithm.delta
-
-    @property
-    def l0_sensitivity(self) -> float:
-        """
-        Returns the l0_sensitivity set at initialization.
-        """
-        return self._l0_sensitivity
-
-    @property
-    def linf_sensitivity(self) -> float:
-        """
-        Returns the linf_sensitivity set at initialization.
-        """
-        return self._linf_sensitivity
-
-    def memory_used(self) -> float:
-        """
-        Returns the memory currently used by the algorithm in bytes.
-        """
-        return self.__algorithm.memory_used()
-
-    def add_entries(self, data: List[Union[int, float]]) -> None:
-        """
-        Adds multiple inputs to the algorithm.
-
-        Note: If the data exceeds the overflow limit of storage, the current list passed is not added.
-        """
-        return self.__algorithm.add_entries(data)
-
-    def add_entry(self, value: Union[int, float]) -> None:
-        """
-        Adds one input to the algorithm.
-
-        Note: If the data exceeds the overflow limit of storage, the current data passed is not added.
-        """
-        return self.__algorithm.add_entry(value)
-
-    def quick_result(self, data: List[Union[int, float]]) -> Union[int, float]:
-        """
-        Runs the algorithm on the input using the epsilon parameter provided in the constructor and returns output.
-
-        Consumes 100% of the privacy budget.
-
-        Note: It resets the privacy budget first.
-        """
-        return self.__algorithm.result(data)
-
-    def result(
-        self,
-        noise_interval_level: Union[float, None] = None,
-    ) -> Union[int, float]:
-        """
-        Gets the algorithm result.
-
-        `noise_interval_level` provides the confidence level of the noise confidence interval, which may be included in the algorithm output.
-        """
-        if noise_interval_level is None:
-            return self.__algorithm.partial_result()
-        else:
-            return self.__algorithm.partial_result(noise_interval_level)
-
-    def reset(self) -> None:
-        """
-        Resets the algorithm to a state in which it has received no input. After Reset is called, the algorithm should only consider input added after the last Reset call when providing output.
-        """
-        return self.__algorithm.reset()
-
-    def serialize(self):
-        """
-        Serializes summary data of current entries into Summary proto. This allows results from distributed aggregation to be recorded and later merged.
-
-        Returns empty summary for algorithms for which serialize is unimplemented.
-        """
-        return self.__algorithm.serialize()
-
-    def merge(self, summary):
-        """
-        Merges serialized summary data into this algorithm. The summary proto must represent data from the same algorithm type with identical parameters. The  data field must contain the algorithm summary type of the corresponding algorithm used. The summary proto cannot be empty.
-        """
-        return self.__algorithm.merge(summary)
-
-    def noise_confidence_interval(
-        self, confidence_level: float, privacy_budget: float
-    ) -> float:
-        """
-        Returns the confidence_level confidence interval of noise added within the algorithm with specified privacy budget, using epsilon and other relevant, algorithm-specific parameters (e.g. bounds) provided by the constructor.
-
-        This metric may be used to gauge the error rate introduced by the noise.
-
-        If the returned value is <x,y>, then the noise added has a confidence_level chance of being in the domain [x,y].
-
-        By default, NoiseConfidenceInterval() returns an error. Algorithms for which a confidence interval can feasibly be calculated override this and output the relevant value.
-
-        Conservatively, we do not release the error rate for algorithms whose confidence intervals rely on input size.
-        """
-        return self.__algorithm.noise_confidence_interval(
-            confidence_level, privacy_budget
-        )
-
-
-class BoundedAlgorithm(MetaAlgorithm):
-    def __init__(
-        self,
-        epsilon: float = 1.0,
-        delta: float = 0,
-        lower_bound: Union[int, float, None] = None,
-        upper_bound: Union[int, float, None] = None,
-        l0_sensitivity: int = 1,
-        linf_sensitivity: int = 1,
-        dtype: str = "int",
-    ):
-        super().__init__(
-            epsilon=epsilon,
-            delta=delta,
-            lower_bound=lower_bound,
-            upper_bound=upper_bound,
-            l0_sensitivity=l0_sensitivity,
-            linf_sensitivity=linf_sensitivity,
-            dtype=dtype,
-        )
+# stdlib
+import math
+from typing import List
+from typing import Union
+
+# pydp relative
+from .._pydp import _algorithms
+
+
+class MetaAlgorithm:
+    def __init__(self, **kwargs):
+        dtype = kwargs.pop("dtype")
+
+        for arg_name in ["lower_bound", "upper_bound"]:
+            if arg_name in kwargs:
+                if kwargs[arg_name] is None:
+                    # Delete bound params if they are not set to avoid conflicts with builder
+                    kwargs.pop(arg_name)
+                else:
+                    # If they are set, check for edge cases
+                    self.__check_input(name=arg_name, value=kwargs[arg_name])
+
+        binded_class = self.__class__.__name__ + self.__map_dtype_str(dtype)
+        class_ = getattr(_algorithms, binded_class)
+
+        self.dtype = dtype
+        self.__algorithm = class_(**kwargs)
+        self._l0_sensitivity = kwargs.get("l0_sensitivity", "Not set")
+        self._linf_sensitivity = kwargs.get("linf_sensitivity", "Not set")
+
+    @staticmethod
+    def __check_input(name: str, value: float):
+        if math.isnan(value) or math.isinf(value):
+            raise ValueError(f"invalid value '{value}' for paramater '{name}'.")
+
+    @staticmethod
+    def __map_dtype_str(dtype: str):
+        if dtype == "int":
+            return "Int"
+        elif dtype == "int64":
+            return "Int64"
+        elif dtype == "float":
+            return "Double"
+        else:
+            raise ValueError(f"dtype '{dtype}' is not supported.")
+
+    @property
+    def epsilon(self) -> float:
+        """
+        Returns the epsilon set at initialization.
+        """
+        return self.__algorithm.epsilon
+
+    @property
+    def delta(self) -> float:
+        """
+        Returns the epsilon set at initialization.
+        """
+        return self.__algorithm.delta
+
+    @property
+    def l0_sensitivity(self) -> float:
+        """
+        Returns the l0_sensitivity set at initialization.
+        """
+        return self._l0_sensitivity
+
+    @property
+    def linf_sensitivity(self) -> float:
+        """
+        Returns the linf_sensitivity set at initialization.
+        """
+        return self._linf_sensitivity
+
+    def memory_used(self) -> float:
+        """
+        Returns the memory currently used by the algorithm in bytes.
+        """
+        return self.__algorithm.memory_used()
+
+    def add_entries(self, data: List[Union[int, float]]) -> None:
+        """
+        Adds multiple inputs to the algorithm.
+
+        Note: If the data exceeds the overflow limit of storage, the current list passed is not added.
+        """
+        return self.__algorithm.add_entries(data)
+
+    def add_entry(self, value: Union[int, float]) -> None:
+        """
+        Adds one input to the algorithm.
+
+        Note: If the data exceeds the overflow limit of storage, the current data passed is not added.
+        """
+        return self.__algorithm.add_entry(value)
+
+    def quick_result(self, data: List[Union[int, float]]) -> Union[int, float]:
+        """
+        Runs the algorithm on the input using the epsilon parameter provided in the constructor and returns output.
+
+        Consumes 100% of the privacy budget.
+
+        Note: It resets the privacy budget first.
+        """
+        return self.__algorithm.result(data)
+
+    def result(
+        self,
+        noise_interval_level: Union[float, None] = None,
+    ) -> Union[int, float]:
+        """
+        Gets the algorithm result.
+
+        `noise_interval_level` provides the confidence level of the noise confidence interval, which may be included in the algorithm output.
+        """
+        if noise_interval_level is None:
+            return self.__algorithm.partial_result()
+        else:
+            return self.__algorithm.partial_result(noise_interval_level)
+
+    def reset(self) -> None:
+        """
+        Resets the algorithm to a state in which it has received no input. After Reset is called, the algorithm should only consider input added after the last Reset call when providing output.
+        """
+        return self.__algorithm.reset()
+
+    def serialize(self):
+        """
+        Serializes summary data of current entries into Summary proto. This allows results from distributed aggregation to be recorded and later merged.
+
+        Returns empty summary for algorithms for which serialize is unimplemented.
+        """
+        return self.__algorithm.serialize()
+
+    def merge(self, summary):
+        """
+        Merges serialized summary data into this algorithm. The summary proto must represent data from the same algorithm type with identical parameters. The  data field must contain the algorithm summary type of the corresponding algorithm used. The summary proto cannot be empty.
+        """
+        return self.__algorithm.merge(summary)
+
+    def noise_confidence_interval(
+        self, confidence_level: float, privacy_budget: float
+    ) -> float:
+        """
+        Returns the confidence_level confidence interval of noise added within the algorithm with specified privacy budget, using epsilon and other relevant, algorithm-specific parameters (e.g. bounds) provided by the constructor.
+
+        This metric may be used to gauge the error rate introduced by the noise.
+
+        If the returned value is <x,y>, then the noise added has a confidence_level chance of being in the domain [x,y].
+
+        By default, NoiseConfidenceInterval() returns an error. Algorithms for which a confidence interval can feasibly be calculated override this and output the relevant value.
+
+        Conservatively, we do not release the error rate for algorithms whose confidence intervals rely on input size.
+        """
+        return self.__algorithm.noise_confidence_interval(
+            confidence_level, privacy_budget
+        )
+
+
+class BoundedAlgorithm(MetaAlgorithm):
+    def __init__(
+        self,
+        epsilon: float = 1.0,
+        delta: float = 0,
+        lower_bound: Union[int, float, None] = None,
+        upper_bound: Union[int, float, None] = None,
+        l0_sensitivity: int = 1,
+        linf_sensitivity: int = 1,
+        dtype: str = "int",
+    ):
+        super().__init__(
+            epsilon=epsilon,
+            delta=delta,
+            lower_bound=lower_bound,
+            upper_bound=upper_bound,
+            l0_sensitivity=l0_sensitivity,
+            linf_sensitivity=linf_sensitivity,
+            dtype=dtype,
+        )
```

## pydp/algorithms/numerical_mechanisms.py

 * *Ordering differences only*

```diff
@@ -1,6 +1,6 @@
-from .._pydp._mechanisms import (
-    NumericalMechanism,  # type: ignore
-    GaussianMechanism,  # type: ignore
-    LaplaceMechanism,  # type: ignore
-    ConfidenceInterval,  # type: ignore
-)
+from .._pydp._mechanisms import (
+    NumericalMechanism,  # type: ignore
+    GaussianMechanism,  # type: ignore
+    LaplaceMechanism,  # type: ignore
+    ConfidenceInterval,  # type: ignore
+)
```

## pydp/algorithms/partition_selection.py

```diff
@@ -1,63 +1,91 @@
-from .._pydp._partition_selection import (
-    create_truncated_geometric_partition_strategy,  # type: ignore
-    create_laplace_partition_strategy,  # type: ignore
-    create_gaussian_partition_strategy,  # type: ignore
-)
-
-__all__ = [
-    "PartitionSelectionStrategy",
-    "create_partition_strategy",
-    "create_truncated_geometric_partition_strategy",
-    "create_laplace_partition_strategy",
-    "create_gaussian_partition_strategy",
-]
-
-
-class PartitionSelectionStrategy:
-    """
-    Base class for all (Æ, ð›¿)-differenially private partition selection strategies.
-    """
-
-    def should_keep(self, num_users: int) -> bool:
-        """
-        Decides whether or not to keep a partition with `num_users` based on differential privacy parameters and strategy.
-        """
-        raise NotImplementedError("PartitionSelectionStrategy is an abstract class.")
-
-
-def create_partition_strategy(
-    strategy: str, epsilon: float, delta: float, max_partitions_contributed: int
-) -> "PartitionSelectionStrategy":
-    """
-    Creates a :class:`~PartitionSelectionStrategy` instance.
-
-    Parameters
-    --------------
-    strategy:
-        One of:
-            * **'truncated_geomteric'**: creates a `Truncated Geometric <https://arxiv.org/pdf/2006.03684.pdf>`_ Partition Strategy.
-            * **'laplace'**: creates a private partition strategy with Laplace mechanism.
-            * **'gaussian'**: creates a private partition strategy with Gaussian mechanism.
-
-    epsilon:
-        The :math:`\\varepsilon` of the partition mechanism
-    delta:
-        The :math:`\\delta` of the partition mechanism
-
-    max_partitions_contributed:
-        The maximum amount of partitions contributed by the strategy.
-    """
-    if strategy.lower() == "truncated_geometric":
-        return create_truncated_geometric_partition_strategy(
-            epsilon, delta, max_partitions_contributed
-        )
-    if strategy.lower() == "laplace":
-        return create_laplace_partition_strategy(
-            epsilon, delta, max_partitions_contributed
-        )
-    if strategy.lower() == "gaussian":
-        return create_gaussian_partition_strategy(
-            epsilon, delta, max_partitions_contributed
-        )
-
-    raise ValueError(f"Strategy '{strategy}' is not supported.")
+import typing
+
+from .._pydp._partition_selection import (
+    create_truncated_geometric_partition_strategy,  # type: ignore
+    create_laplace_partition_strategy,  # type: ignore
+    create_gaussian_partition_strategy,  # type: ignore
+    create_pre_thresholding_partition_strategy,  # type: ignore
+    PartitionSelectionStrategyType,  # type: ignore
+)
+
+__all__ = [
+    "PartitionSelectionStrategy",
+    "create_partition_strategy",
+    "create_truncated_geometric_partition_strategy",
+    "create_laplace_partition_strategy",
+    "create_gaussian_partition_strategy",
+]
+
+
+class PartitionSelectionStrategy:
+    """
+    Base class for all (Æ, ð›¿)-differenially private partition selection strategies.
+    """
+
+    def should_keep(self, num_users: int) -> bool:
+        """
+        Decides whether or not to keep a partition with `num_users` based on differential privacy parameters and strategy.
+        """
+        raise NotImplementedError("PartitionSelectionStrategy is an abstract class.")
+
+
+def create_partition_strategy(
+    strategy: str,
+    epsilon: float,
+    delta: float,
+    max_partitions_contributed: int,
+    pre_threshold: typing.Optional[int] = None,
+) -> "PartitionSelectionStrategy":
+    """
+    Creates a :class:`~PartitionSelectionStrategy` instance.
+
+    Parameters
+    --------------
+    strategy:
+        One of:
+            * **'truncated_geomteric'**: creates a `Truncated Geometric <https://arxiv.org/pdf/2006.03684.pdf>`_ Partition Strategy.
+            * **'laplace'**: creates a private partition strategy with Laplace mechanism.
+            * **'gaussian'**: creates a private partition strategy with Gaussian mechanism.
+
+    epsilon:
+        The :math:`\\varepsilon` of the partition mechanism
+    delta:
+        The :math:`\\delta` of the partition mechanism
+
+    max_partitions_contributed:
+        The maximum amount of partitions contributed by the strategy.
+
+    pre_threshold:
+        The minimum amount of privacy units which require for keeping dataset.
+        More details on pre-thresholding are in
+        https://github.com/google/differential-privacy/blob/main/common_docs/pre_thresholding.md
+    """
+    if pre_threshold is not None:
+        strategy_type = _to_partition_selection_strategy_type(strategy)
+        return create_pre_thresholding_partition_strategy(
+            epsilon, delta, max_partitions_contributed, pre_threshold, strategy_type
+        )
+    if strategy.lower() == "truncated_geometric":
+        return create_truncated_geometric_partition_strategy(
+            epsilon, delta, max_partitions_contributed
+        )
+    if strategy.lower() == "laplace":
+        return create_laplace_partition_strategy(
+            epsilon, delta, max_partitions_contributed
+        )
+    if strategy.lower() == "gaussian":
+        return create_gaussian_partition_strategy(
+            epsilon, delta, max_partitions_contributed
+        )
+
+    raise ValueError(f"Strategy '{strategy}' is not supported.")
+
+
+def _to_partition_selection_strategy_type(s: str) -> PartitionSelectionStrategyType:
+    if s.lower() == "truncated_geometric":
+        return PartitionSelectionStrategyType.NEAR_TRUNCATED_GEOMETRIC
+    if s.lower() == "laplace":
+        return PartitionSelectionStrategyType.LAPLACE
+    if s.lower() == "gaussian":
+        return PartitionSelectionStrategyType.GAUSSIAN
+    raise ValueError(f"Strategy '{s}' is not supported.")
```

## pydp/algorithms/quantile_tree.py

 * *Ordering differences only*

```diff
@@ -1,3 +1,3 @@
-from pydp._pydp._algorithms import QuantileTree
-
-__all__ = ["QuantileTree"]
+from pydp._pydp._algorithms import QuantileTree
+
+__all__ = ["QuantileTree"]
```

## pydp/algorithms/laplacian/__init__.py

 * *Ordering differences only*

```diff
@@ -1,22 +1,22 @@
-# pydp relative
-from ._bounded_algorithms import BoundedMean
-from ._bounded_algorithms import BoundedStandardDeviation
-from ._bounded_algorithms import BoundedSum
-from ._bounded_algorithms import BoundedVariance
-from ._bounded_algorithms import Max
-from ._bounded_algorithms import Median
-from ._bounded_algorithms import Min
-from ._count import Count
-from ._percentile import Percentile
-
-__all__ = [
-    "BoundedMean",
-    "BoundedStandardDeviation",
-    "BoundedSum",
-    "BoundedVariance",
-    "Count",
-    "Max",
-    "Min",
-    "Median",
-    "Percentile",
-]
+# pydp relative
+from ._bounded_algorithms import BoundedMean
+from ._bounded_algorithms import BoundedStandardDeviation
+from ._bounded_algorithms import BoundedSum
+from ._bounded_algorithms import BoundedVariance
+from ._bounded_algorithms import Max
+from ._bounded_algorithms import Median
+from ._bounded_algorithms import Min
+from ._count import Count
+from ._percentile import Percentile
+
+__all__ = [
+    "BoundedMean",
+    "BoundedStandardDeviation",
+    "BoundedSum",
+    "BoundedVariance",
+    "Count",
+    "Max",
+    "Min",
+    "Median",
+    "Percentile",
+]
```

## pydp/algorithms/laplacian/_bounded_algorithms.py

 * *Ordering differences only*

```diff
@@ -1,95 +1,95 @@
-# pydp relative
-from .._algorithm import BoundedAlgorithm
-
-
-class BoundedMean(BoundedAlgorithm):
-    """
-    BoundedMean computes the average of values in a dataset, in a differentially private manner.
-
-    Incrementally provides a differentially private average.
-    All input vales are normalized to be their difference from the middle of the
-    input range. That allows us to calculate the sum of all input values with
-    half the sensitivity it would otherwise take for better accuracy (as compared
-    to doing noisy sum / noisy count). This algorithm is taken from section 2.5.5
-    of the following book (algorithm 2.4):
-    https://books.google.com/books?id=WFttDQAAQBAJ&pg=PA24#v=onepage&q&f=false
-
-    """
-
-    pass
-
-
-class BoundedSum(BoundedAlgorithm):
-    """
-    BoundedSum computes the sum of values in a dataset, in a differentially private manner.
-
-    Incrementally provides a differentially private sum, clamped between upper
-    and lower values. Bounds can be manually set or privately inferred.
-    """
-
-    pass
-
-
-class BoundedStandardDeviation(BoundedAlgorithm):
-    """
-    BoundedStandardDeviation computes the standard deviation of values in a dataset, in a differentially private manner.
-
-    Incrementally provides a differentially private standard deviation for values
-    in the range [lower..upper]. Values outside of this range will be clamped so
-    they lie in the range. The output will also be clamped between 0 and (upper -
-    lower).
-
-    The implementation simply computes the bounded variance and takes the square
-    root, which is differentially private by the post-processing theorem. It
-    relies on the fact that the bounded variance algorithm guarantees that the
-    output is non-negative.
-    """
-
-    pass
-
-
-class BoundedVariance(BoundedAlgorithm):
-    """
-    BoundedVariance computes the variance of values in a dataset, in a differentially private manner.
-
-    Incrementally provides a differentially private variance for values in the
-    range [lower..upper]. Values outside of this range will be clamped so they
-    lie in the range. The output will also be clamped between 0 and (upper -
-    lower)^2. Since the result is guaranteed to be positive, this algorithm can
-    be used to compute a differentially private standard deviation.
-
-    The algorithm uses O(1) memory and runs in O(n) time where n is the size of
-    the dataset, making it a fast and efficient. The amount of noise added grows
-    quadratically in (upper - lower) and decreases linearly in n, so it might not
-    produce good results unless n >> (upper - lower)^2.
-
-    The algorithm is a variation of the algorithm for differentially private mean
-    from "Differential Privacy: From Theory to Practice", section 2.5.5:
-    https://books.google.com/books?id=WFttDQAAQBAJ&pg=PA24#v=onepage&q&f=false
-    """
-
-    pass
-
-
-class Max(BoundedAlgorithm):
-    """
-    Max computes the Max value in the dataset, in a differentially private manner.
-    """
-
-    pass
-
-
-class Min(BoundedAlgorithm):
-    """
-    Min computes the minium value in the dataset, in a differentially private manner.
-    """
-
-    pass
-
-
-class Median(BoundedAlgorithm):
-    """
-    Median computes the Median value in the dataset, in a differentially private manner.
-    """
-
-    pass
+# pydp relative
+from .._algorithm import BoundedAlgorithm
+
+
+class BoundedMean(BoundedAlgorithm):
+    """
+    BoundedMean computes the average of values in a dataset, in a differentially private manner.
+
+    Incrementally provides a differentially private average.
+    All input vales are normalized to be their difference from the middle of the
+    input range. That allows us to calculate the sum of all input values with
+    half the sensitivity it would otherwise take for better accuracy (as compared
+    to doing noisy sum / noisy count). This algorithm is taken from section 2.5.5
+    of the following book (algorithm 2.4):
+    https://books.google.com/books?id=WFttDQAAQBAJ&pg=PA24#v=onepage&q&f=false
+
+    """
+
+    pass
+
+
+class BoundedSum(BoundedAlgorithm):
+    """
+    BoundedSum computes the sum of values in a dataset, in a differentially private manner.
+
+    Incrementally provides a differentially private sum, clamped between upper
+    and lower values. Bounds can be manually set or privately inferred.
+    """
+
+    pass
+
+
+class BoundedStandardDeviation(BoundedAlgorithm):
+    """
+    BoundedStandardDeviation computes the standard deviation of values in a dataset, in a differentially private manner.
+
+    Incrementally provides a differentially private standard deviation for values
+    in the range [lower..upper]. Values outside of this range will be clamped so
+    they lie in the range. The output will also be clamped between 0 and (upper -
+    lower).
+
+    The implementation simply computes the bounded variance and takes the square
+    root, which is differentially private by the post-processing theorem. It
+    relies on the fact that the bounded variance algorithm guarantees that the
+    output is non-negative.
+    """
+
+    pass
+
+
+class BoundedVariance(BoundedAlgorithm):
+    """
+    BoundedVariance computes the variance of values in a dataset, in a differentially private manner.
+
+    Incrementally provides a differentially private variance for values in the
+    range [lower..upper]. Values outside of this range will be clamped so they
+    lie in the range. The output will also be clamped between 0 and (upper -
+    lower)^2. Since the result is guaranteed to be positive, this algorithm can
+    be used to compute a differentially private standard deviation.
+
+    The algorithm uses O(1) memory and runs in O(n) time where n is the size of
+    the dataset, making it a fast and efficient. The amount of noise added grows
+    quadratically in (upper - lower) and decreases linearly in n, so it might not
+    produce good results unless n >> (upper - lower)^2.
+
+    The algorithm is a variation of the algorithm for differentially private mean
+    from "Differential Privacy: From Theory to Practice", section 2.5.5:
+    https://books.google.com/books?id=WFttDQAAQBAJ&pg=PA24#v=onepage&q&f=false
+    """
+
+    pass
+
+
+class Max(BoundedAlgorithm):
+    """
+    Max computes the Max value in the dataset, in a differentially private manner.
+    """
+
+    pass
+
+
+class Min(BoundedAlgorithm):
+    """
+    Min computes the minium value in the dataset, in a differentially private manner.
+    """
+
+    pass
+
+
+class Median(BoundedAlgorithm):
+    """
+    Median computes the Median value in the dataset, in a differentially private manner.
+    """
+
+    pass
```

## pydp/algorithms/laplacian/_count.py

 * *Ordering differences only*

```diff
@@ -1,25 +1,25 @@
-# stdlib
-from typing import Union
-
-# pydp relative
-from .._algorithm import MetaAlgorithm
-
-
-class Count(MetaAlgorithm):
-    """
-    Count computes the Count of number of items in the dataset, in a differentially private manner.
-    """
-
-    def __init__(
-        self,
-        epsilon: float = 1.0,
-        l0_sensitivity: int = 1,
-        linf_sensitivity: int = 1,
-        dtype: str = "int",
-    ):
-        super().__init__(
-            epsilon=epsilon,
-            l0_sensitivity=l0_sensitivity,
-            linf_sensitivity=linf_sensitivity,
-            dtype=dtype,
-        )
+# stdlib
+from typing import Union
+
+# pydp relative
+from .._algorithm import MetaAlgorithm
+
+
+class Count(MetaAlgorithm):
+    """
+    Count computes the Count of number of items in the dataset, in a differentially private manner.
+    """
+
+    def __init__(
+        self,
+        epsilon: float = 1.0,
+        l0_sensitivity: int = 1,
+        linf_sensitivity: int = 1,
+        dtype: str = "int",
+    ):
+        super().__init__(
+            epsilon=epsilon,
+            l0_sensitivity=l0_sensitivity,
+            linf_sensitivity=linf_sensitivity,
+            dtype=dtype,
+        )
```

## pydp/algorithms/laplacian/_percentile.py

 * *Ordering differences only*

```diff
@@ -1,34 +1,34 @@
-# stdlib
-from typing import Union
-
-# pydp relative
-from .._algorithm import MetaAlgorithm
-
-
-class Percentile(MetaAlgorithm):
-    """
-    Perencetile finds the value in the dataset with that percentile, in a differentially private manner.
-    """
-
-    def __init__(
-        self,
-        epsilon: float = 1.0,
-        percentile: float = 0.0,
-        lower_bound: Union[int, float, None] = None,
-        upper_bound: Union[int, float, None] = None,
-        dtype: str = "int",
-    ):
-        super().__init__(
-            epsilon=epsilon,
-            percentile=percentile,
-            lower_bound=lower_bound,
-            upper_bound=upper_bound,
-            dtype=dtype,
-        )
-
-    @property
-    def percentile(self) -> float:
-        """
-        percentile Gets the value that was set in the constructor.
-        """
-        return self._MetaAlgorithm__algorithm.percentile  # type: ignore
+# stdlib
+from typing import Union
+
+# pydp relative
+from .._algorithm import MetaAlgorithm
+
+
+class Percentile(MetaAlgorithm):
+    """
+    Perencetile finds the value in the dataset with that percentile, in a differentially private manner.
+    """
+
+    def __init__(
+        self,
+        epsilon: float = 1.0,
+        percentile: float = 0.0,
+        lower_bound: Union[int, float, None] = None,
+        upper_bound: Union[int, float, None] = None,
+        dtype: str = "int",
+    ):
+        super().__init__(
+            epsilon=epsilon,
+            percentile=percentile,
+            lower_bound=lower_bound,
+            upper_bound=upper_bound,
+            dtype=dtype,
+        )
+
+    @property
+    def percentile(self) -> float:
+        """
+        percentile Gets the value that was set in the constructor.
+        """
+        return self._MetaAlgorithm__algorithm.percentile  # type: ignore
```

## pydp/distributions/__init__.py

 * *Ordering differences only*

```diff
@@ -1,2 +1,2 @@
-# pydp relative
-from .._pydp._distributions import *
+# pydp relative
+from .._pydp._distributions import *
```

## pydp/ml/__init__.py

 * *Ordering differences only*

```diff
@@ -1 +1 @@
-# from . import util
+# from . import util
```

## pydp/ml/naive_bayes.py

 * *Ordering differences only*

```diff
@@ -1,358 +1,358 @@
-# MIT License
-#
-# Copyright (C) IBM Corporation 2019
-#
-# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
-# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
-# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
-# persons to whom the Software is furnished to do so, subject to the following conditions:
-#
-# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
-# Software.
-#
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
-# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
-# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-# Source:
-# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/models/naive_bayes.py
-
-# stdlib
-import warnings
-
-# third party
-import numpy as np
-import sklearn.naive_bayes as sk_nb
-from sklearn.utils import check_X_y
-from sklearn.utils.multiclass import _check_partial_fit_first_call
-
-# pydp relative
-from .mechanisms.geometric import GeometricTruncated
-from .mechanisms.laplace import LaplaceBoundedDomain
-from .mechanisms.laplace import LaplaceTruncated
-from .util.accountant import BudgetAccountant
-from .util.utils import PrivacyLeakWarning
-from .util.utils import warn_unused_args
-from .util.validation import check_bounds
-from .util.validation import clip_to_bounds
-
-
-class GaussianNB(sk_nb.GaussianNB):
-    r"""Gaussian Naive Bayes (GaussianNB) with differential privacy
-    Inherits the :class:`sklearn.naive_bayes.GaussianNB` class from Scikit Learn and adds noise to satisfy differential
-    privacy to the learned means and variances.  Adapted from the work presented in [VSB13]_.
-    Parameters
-    ----------
-    epsilon : float, default: 1.0
-        Privacy parameter :math:`\epsilon` for the model.
-    bounds:  tuple, optional
-        Bounds of the data, provided as a tuple of the form (min, max).  `min` and `max` can either be scalars, covering
-        the min/max of the entire data, or vectors with one entry per feature.  If not provided, the bounds are computed
-        on the data when ``.fit()`` is first called, resulting in a :class:`.PrivacyLeakWarning`.
-    priors : array-like, shape (n_classes,)
-        Prior probabilities of the classes.  If specified the priors are not adjusted according to the data.
-    var_smoothing : float, default: 1e-9
-        Portion of the largest variance of all features that is added to variances for calculation stability.
-    accountant : BudgetAccountant, optional
-        Accountant to keep track of privacy budget.
-    Attributes
-    ----------
-    class_prior_ : array, shape (n_classes,)
-        probability of each class.
-    class_count_ : array, shape (n_classes,)
-        number of training samples observed in each class.
-    theta_ : array, shape (n_classes, n_features)
-        mean of each feature per class
-    sigma_ : array, shape (n_classes, n_features)
-        variance of each feature per class
-    epsilon_ : float
-        absolute additive value to variances (unrelated to ``epsilon`` parameter for differential privacy)
-    References
-    ----------
-    .. [VSB13] Vaidya, Jaideep, Basit Shafiq, Anirban Basu, and Yuan Hong. "Differentially private naive bayes
-        classification." In 2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent
-        Agent Technologies (IAT), vol. 1, pp. 571-576. IEEE, 2013.
-    """
-
-    def __init__(
-        self,
-        epsilon=1.0,
-        probability=1e-2,
-        bounds=None,
-        priors=None,
-        var_smoothing=1e-9,
-        accountant=None,
-    ):
-        super().__init__(priors=priors, var_smoothing=var_smoothing)
-
-        self.epsilon = epsilon
-        self.bounds = bounds
-        self.probability = probability
-        self.accountant = BudgetAccountant.load_default(accountant)
-
-    def _partial_fit(self, X, y, classes=None, _refit=False, sample_weight=None):
-
-        """Incremental fit on a batch of samples.
-        This method is expected to be called several times consecutively on different chunks of a dataset so as toimplement out-of-core or online learning.
-        This is especially useful when the whole dataset is too big to fit in memory at once.
-        Parameters
-        ----------
-        X : array-like, shape (n_samples, n_features)
-            Training vectors
-        y : array-like, shape (n_samples,)
-            Target values
-        classes : array-like, shape (n_classes,), optional (default=None)
-            List of all classes that can possibly appear in the y vector. Must be provided at the first call to partial_fit, can be omitted in subsequent calls.
-        sample_weight : array-like, shape (n_samples,), optional (default=None)
-            Weights applied to individual samples(1. for unweighted).
-        """
-
-        # Checks if the provided epsilon, delta values can be spent without exceeding the accountant's budget.
-        self.accountant.check(self.epsilon, 0)
-
-        if sample_weight is not None:
-            warn_unused_args("sample_weight")
-
-        # Checks X and y for consistent length, enforces X to be 2D and y 1D.
-        # By default, X is checked to be non-empty and containing only finite values.
-        # Standard input checks are also applied to y, such as checking that y does not have np.nan or np.inf targets.
-        X, y = check_X_y(X, y)
-
-        if self.bounds is None:
-            warnings.warn(
-                "Bounds have not been specified and will be calculated on the data provided. This will "
-                "result in additional privacy leakage. To ensure differential privacy and no additional "
-                "privacy leakage, specify bounds for each dimension.",
-                PrivacyLeakWarning,
-            )
-            self.bounds = (np.min(X, axis=0), np.max(X, axis=0))
-
-        # Checks ``bounds`` is a list of tuples as (lower, upper), where lower<=upper and both numeric.
-        # Checks for appropriate number of dimensions in ``bounds``.
-        self.bounds = check_bounds(self.bounds, shape=X.shape[1])
-        # Clips a 2-D array to given bounds.
-        X = clip_to_bounds(X, self.bounds)
-
-        self.epsilon_ = self.var_smoothing
-
-        if _refit:
-            self.classes_ = None
-
-        # Checks if number of classes is assigned to ``n_classes`` for first call to partial_fit.
-        if _check_partial_fit_first_call(self, classes):
-            n_features = X.shape[1]
-            n_classes = len(self.classes_)
-            self.theta_ = np.zeros((n_classes, n_features))
-            self.sigma_ = np.zeros((n_classes, n_features))
-
-            self.class_count_ = np.zeros(n_classes, dtype=np.float64)
-
-            if self.priors is not None:
-                priors = np.asarray(self.priors)
-
-                if len(priors) != n_classes:
-                    raise ValueError("Number of priors must match number of classes.")
-                if not np.isclose(priors.sum(), 1.0):
-                    raise ValueError("The sum of the priors should be 1.")
-                if (priors < 0).any():
-                    raise ValueError("Priors must be non-negative.")
-                self.class_prior_ = priors
-            else:
-                # Initialize the priors to zeros for each class
-                self.class_prior_ = np.zeros(len(self.classes_), dtype=np.float64)
-        else:
-            if X.shape[1] != self.theta_.shape[1]:
-                raise ValueError(
-                    "Number of features %d does not match previous data %d."
-                    % (X.shape[1], self.theta_.shape[1])
-                )
-            # Put epsilon back in each time
-            self.sigma_[:, :] -= self.epsilon_
-
-        classes = self.classes_
-
-        # Finds unique target values
-        unique_y = np.unique(y)
-        # Checks if each element of 1-D array is also present in the first instance of ``classes``
-        unique_y_in_classes = np.in1d(unique_y, classes)
-
-        if not np.all(unique_y_in_classes):
-            raise ValueError(
-                "The target label(s) %s in y do not exist in the initial classes %s"
-                % (unique_y[~unique_y_in_classes], classes)
-            )
-
-        # Adds noise to number of training samples observed in each class
-        noisy_class_counts = self._noisy_class_counts(y)
-
-        # Updates mean, variance after adding noise to ``class_counts``
-        for _i, y_i in enumerate(unique_y):
-            i = classes.searchsorted(y_i)
-            X_i = X[y == y_i, :]
-
-            n_i = noisy_class_counts[_i]
-
-            new_theta, new_sigma = self._update_mean_variance(
-                self.class_count_[i],
-                self.theta_[i, :],
-                self.sigma_[i, :],
-                X_i,
-                n_noisy=n_i,
-            )
-
-            self.theta_[i, :] = new_theta
-            self.sigma_[i, :] = new_sigma
-            self.class_count_[i] += n_i
-
-        self.sigma_[:, :] += self.epsilon_
-
-        # Update if only no priors is provided
-        if self.priors is None:
-            # Empirical prior, with sample_weight taken into account
-            self.class_prior_ = self.class_count_ / self.class_count_.sum()
-
-        # Instructs the accountant to spend given epsilon, delta privacy budget
-        self.accountant.spend(self.epsilon, 0)
-
-        return self
-
-    def _update_mean_variance(
-        self, n_past, mu, var, X, sample_weight=None, n_noisy=None
-    ):
-        """Compute online update of Gaussian mean and variance.
-        Given starting sample count, mean, and variance, a new set of points X return the updated mean and variance.
-        (NB - each dimension (column) in X is treated as independent -- you get variance, not covariance).
-        Can take scalar mean and variance, or vector mean and variance to simultaneously update a number of
-        independent Gaussians.
-        See Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque:
-        http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf
-        Parameters
-        ----------
-        n_past : int
-            Number of samples represented in old mean and variance.  If sample weights were given, this should contain
-            the sum of sample weights represented in old mean and variance.
-        mu : array-like, shape (number of Gaussians,)
-            Means for Gaussians in original set.
-        var : array-like, shape (number of Gaussians,)
-            Variances for Gaussians in original set.
-        sample_weight : ignored
-            Ignored in diffprivlib.
-        n_noisy : int, optional
-            Noisy count of the given class, satisfying differential privacy.
-        Returns
-        -------
-        total_mu : array-like, shape (number of Gaussians,)
-            Updated mean for each Gaussian over the combined set.
-        total_var : array-like, shape (number of Gaussians,)
-            Updated variance for each Gaussian over the combined set.
-        """
-        if n_noisy is None:
-            warnings.warn(
-                "Noisy class count has not been specified and will be read from the data. To use this "
-                "method correctly, make sure it is run by the parent GaussianNB class.",
-                PrivacyLeakWarning,
-            )
-            n_noisy = X.shape[0]
-
-        if not n_noisy:
-            return mu, var
-
-        if sample_weight is not None:
-            warn_unused_args("sample_weight")
-
-        # Split epsilon between each feature, using 1/3 of total budget for each of mean and variance
-        n_features = X.shape[1]
-        local_epsilon = self.epsilon / 3 / n_features
-
-        new_mu = np.zeros((n_features,))
-        new_var = np.zeros((n_features,))
-
-        for feature in range(n_features):
-            _X = X[:, feature]
-            lower, upper = self.bounds[0][feature], self.bounds[1][feature]
-
-            local_diameter = upper - lower
-
-            mech_mu = (
-                LaplaceTruncated()
-                .set_bounds(lower * n_noisy, upper * n_noisy)
-                .set_epsilon(local_epsilon)
-                .set_sensitivity(local_diameter)
-            )
-            _mu = mech_mu.randomise(_X.sum()) / n_noisy
-
-            local_sq_sens = max(_mu - lower, upper - _mu) ** 2
-            mech_var = (
-                LaplaceBoundedDomain()
-                .set_epsilon(local_epsilon)
-                .set_sensitivity(local_sq_sens)
-                .set_bounds(0, local_sq_sens * n_noisy)
-            )
-            _var = mech_var.randomise(((_X - _mu) ** 2).sum()) / n_noisy
-
-            new_mu[feature] = _mu
-            new_var[feature] = _var
-
-        if n_past == 0:
-            return new_mu, new_var
-
-        n_total = float(n_past + n_noisy)
-
-        # Combine mean of old and new data, taking into consideration
-        # (weighted) number of observations
-        total_mu = (n_noisy * new_mu + n_past * mu) / n_total
-
-        # Combine variance of old and new data, taking into consideration
-        # (weighted) number of observations. This is achieved by combining
-        # the sum-of-squared-differences (ssd)
-        old_ssd = n_past * var
-        new_ssd = n_noisy * new_var
-        total_ssd = (
-            old_ssd
-            + new_ssd
-            + (n_past / float(n_noisy * n_total))
-            * (n_noisy * mu - n_noisy * new_mu) ** 2
-        )
-        total_var = total_ssd / n_total
-
-        return total_mu, total_var
-
-    def _noisy_class_counts(self, y):
-
-        """Adds noise to the number of training samples observed in each class.
-        Parameters
-        ----------
-        y : array-like, shape (n_samples,)
-            Target values
-        Returns
-        -------
-        noisy_counts : array-like
-            Returns after adding geometric noise to number of training samples
-        """
-
-        unique_y = np.unique(y)
-        n_total = y.shape[0]
-
-        # Use 1/3 of total epsilon budget for getting noisy class counts
-        mech = (
-            GeometricTruncated()
-            .set_epsilon(self.epsilon / 3)
-            .set_sensitivity(1)
-            .set_bounds(1, n_total)
-            .set_probability(self.probability)
-        )
-        noisy_counts = np.array([mech.randomise((y == y_i).sum()) for y_i in unique_y])
-
-        argsort = np.argsort(noisy_counts)
-        i = 0 if noisy_counts.sum() > n_total else len(unique_y) - 1
-
-        while np.sum(noisy_counts) != n_total:
-            _i = argsort[i]
-            sgn = np.sign(n_total - noisy_counts.sum())
-            noisy_counts[_i] = np.clip(noisy_counts[_i] + sgn, 1, n_total)
-
-            i = (i - sgn) % len(unique_y)
-
-        return noisy_counts
+# MIT License
+#
+# Copyright (C) IBM Corporation 2019
+#
+# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
+# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
+# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
+# persons to whom the Software is furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
+# Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
+# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+# Source:
+# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/models/naive_bayes.py
+
+# stdlib
+import warnings
+
+# third party
+import numpy as np
+import sklearn.naive_bayes as sk_nb
+from sklearn.utils import check_X_y
+from sklearn.utils.multiclass import _check_partial_fit_first_call
+
+# pydp relative
+from .mechanisms.geometric import GeometricTruncated
+from .mechanisms.laplace import LaplaceBoundedDomain
+from .mechanisms.laplace import LaplaceTruncated
+from .util.accountant import BudgetAccountant
+from .util.utils import PrivacyLeakWarning
+from .util.utils import warn_unused_args
+from .util.validation import check_bounds
+from .util.validation import clip_to_bounds
+
+
+class GaussianNB(sk_nb.GaussianNB):
+    r"""Gaussian Naive Bayes (GaussianNB) with differential privacy
+    Inherits the :class:`sklearn.naive_bayes.GaussianNB` class from Scikit Learn and adds noise to satisfy differential
+    privacy to the learned means and variances.  Adapted from the work presented in [VSB13]_.
+    Parameters
+    ----------
+    epsilon : float, default: 1.0
+        Privacy parameter :math:`\epsilon` for the model.
+    bounds:  tuple, optional
+        Bounds of the data, provided as a tuple of the form (min, max).  `min` and `max` can either be scalars, covering
+        the min/max of the entire data, or vectors with one entry per feature.  If not provided, the bounds are computed
+        on the data when ``.fit()`` is first called, resulting in a :class:`.PrivacyLeakWarning`.
+    priors : array-like, shape (n_classes,)
+        Prior probabilities of the classes.  If specified the priors are not adjusted according to the data.
+    var_smoothing : float, default: 1e-9
+        Portion of the largest variance of all features that is added to variances for calculation stability.
+    accountant : BudgetAccountant, optional
+        Accountant to keep track of privacy budget.
+    Attributes
+    ----------
+    class_prior_ : array, shape (n_classes,)
+        probability of each class.
+    class_count_ : array, shape (n_classes,)
+        number of training samples observed in each class.
+    theta_ : array, shape (n_classes, n_features)
+        mean of each feature per class
+    sigma_ : array, shape (n_classes, n_features)
+        variance of each feature per class
+    epsilon_ : float
+        absolute additive value to variances (unrelated to ``epsilon`` parameter for differential privacy)
+    References
+    ----------
+    .. [VSB13] Vaidya, Jaideep, Basit Shafiq, Anirban Basu, and Yuan Hong. "Differentially private naive bayes
+        classification." In 2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent
+        Agent Technologies (IAT), vol. 1, pp. 571-576. IEEE, 2013.
+    """
+
+    def __init__(
+        self,
+        epsilon=1.0,
+        probability=1e-2,
+        bounds=None,
+        priors=None,
+        var_smoothing=1e-9,
+        accountant=None,
+    ):
+        super().__init__(priors=priors, var_smoothing=var_smoothing)
+
+        self.epsilon = epsilon
+        self.bounds = bounds
+        self.probability = probability
+        self.accountant = BudgetAccountant.load_default(accountant)
+
+    def _partial_fit(self, X, y, classes=None, _refit=False, sample_weight=None):
+
+        """Incremental fit on a batch of samples.
+        This method is expected to be called several times consecutively on different chunks of a dataset so as toimplement out-of-core or online learning.
+        This is especially useful when the whole dataset is too big to fit in memory at once.
+        Parameters
+        ----------
+        X : array-like, shape (n_samples, n_features)
+            Training vectors
+        y : array-like, shape (n_samples,)
+            Target values
+        classes : array-like, shape (n_classes,), optional (default=None)
+            List of all classes that can possibly appear in the y vector. Must be provided at the first call to partial_fit, can be omitted in subsequent calls.
+        sample_weight : array-like, shape (n_samples,), optional (default=None)
+            Weights applied to individual samples(1. for unweighted).
+        """
+
+        # Checks if the provided epsilon, delta values can be spent without exceeding the accountant's budget.
+        self.accountant.check(self.epsilon, 0)
+
+        if sample_weight is not None:
+            warn_unused_args("sample_weight")
+
+        # Checks X and y for consistent length, enforces X to be 2D and y 1D.
+        # By default, X is checked to be non-empty and containing only finite values.
+        # Standard input checks are also applied to y, such as checking that y does not have np.nan or np.inf targets.
+        X, y = check_X_y(X, y)
+
+        if self.bounds is None:
+            warnings.warn(
+                "Bounds have not been specified and will be calculated on the data provided. This will "
+                "result in additional privacy leakage. To ensure differential privacy and no additional "
+                "privacy leakage, specify bounds for each dimension.",
+                PrivacyLeakWarning,
+            )
+            self.bounds = (np.min(X, axis=0), np.max(X, axis=0))
+
+        # Checks ``bounds`` is a list of tuples as (lower, upper), where lower<=upper and both numeric.
+        # Checks for appropriate number of dimensions in ``bounds``.
+        self.bounds = check_bounds(self.bounds, shape=X.shape[1])
+        # Clips a 2-D array to given bounds.
+        X = clip_to_bounds(X, self.bounds)
+
+        self.epsilon_ = self.var_smoothing
+
+        if _refit:
+            self.classes_ = None
+
+        # Checks if number of classes is assigned to ``n_classes`` for first call to partial_fit.
+        if _check_partial_fit_first_call(self, classes):
+            n_features = X.shape[1]
+            n_classes = len(self.classes_)
+            self.theta_ = np.zeros((n_classes, n_features))
+            self.sigma_ = np.zeros((n_classes, n_features))
+
+            self.class_count_ = np.zeros(n_classes, dtype=np.float64)
+
+            if self.priors is not None:
+                priors = np.asarray(self.priors)
+
+                if len(priors) != n_classes:
+                    raise ValueError("Number of priors must match number of classes.")
+                if not np.isclose(priors.sum(), 1.0):
+                    raise ValueError("The sum of the priors should be 1.")
+                if (priors < 0).any():
+                    raise ValueError("Priors must be non-negative.")
+                self.class_prior_ = priors
+            else:
+                # Initialize the priors to zeros for each class
+                self.class_prior_ = np.zeros(len(self.classes_), dtype=np.float64)
+        else:
+            if X.shape[1] != self.theta_.shape[1]:
+                raise ValueError(
+                    "Number of features %d does not match previous data %d."
+                    % (X.shape[1], self.theta_.shape[1])
+                )
+            # Put epsilon back in each time
+            self.sigma_[:, :] -= self.epsilon_
+
+        classes = self.classes_
+
+        # Finds unique target values
+        unique_y = np.unique(y)
+        # Checks if each element of 1-D array is also present in the first instance of ``classes``
+        unique_y_in_classes = np.in1d(unique_y, classes)
+
+        if not np.all(unique_y_in_classes):
+            raise ValueError(
+                "The target label(s) %s in y do not exist in the initial classes %s"
+                % (unique_y[~unique_y_in_classes], classes)
+            )
+
+        # Adds noise to number of training samples observed in each class
+        noisy_class_counts = self._noisy_class_counts(y)
+
+        # Updates mean, variance after adding noise to ``class_counts``
+        for _i, y_i in enumerate(unique_y):
+            i = classes.searchsorted(y_i)
+            X_i = X[y == y_i, :]
+
+            n_i = noisy_class_counts[_i]
+
+            new_theta, new_sigma = self._update_mean_variance(
+                self.class_count_[i],
+                self.theta_[i, :],
+                self.sigma_[i, :],
+                X_i,
+                n_noisy=n_i,
+            )
+
+            self.theta_[i, :] = new_theta
+            self.sigma_[i, :] = new_sigma
+            self.class_count_[i] += n_i
+
+        self.sigma_[:, :] += self.epsilon_
+
+        # Update if only no priors is provided
+        if self.priors is None:
+            # Empirical prior, with sample_weight taken into account
+            self.class_prior_ = self.class_count_ / self.class_count_.sum()
+
+        # Instructs the accountant to spend given epsilon, delta privacy budget
+        self.accountant.spend(self.epsilon, 0)
+
+        return self
+
+    def _update_mean_variance(
+        self, n_past, mu, var, X, sample_weight=None, n_noisy=None
+    ):
+        """Compute online update of Gaussian mean and variance.
+        Given starting sample count, mean, and variance, a new set of points X return the updated mean and variance.
+        (NB - each dimension (column) in X is treated as independent -- you get variance, not covariance).
+        Can take scalar mean and variance, or vector mean and variance to simultaneously update a number of
+        independent Gaussians.
+        See Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque:
+        http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf
+        Parameters
+        ----------
+        n_past : int
+            Number of samples represented in old mean and variance.  If sample weights were given, this should contain
+            the sum of sample weights represented in old mean and variance.
+        mu : array-like, shape (number of Gaussians,)
+            Means for Gaussians in original set.
+        var : array-like, shape (number of Gaussians,)
+            Variances for Gaussians in original set.
+        sample_weight : ignored
+            Ignored in diffprivlib.
+        n_noisy : int, optional
+            Noisy count of the given class, satisfying differential privacy.
+        Returns
+        -------
+        total_mu : array-like, shape (number of Gaussians,)
+            Updated mean for each Gaussian over the combined set.
+        total_var : array-like, shape (number of Gaussians,)
+            Updated variance for each Gaussian over the combined set.
+        """
+        if n_noisy is None:
+            warnings.warn(
+                "Noisy class count has not been specified and will be read from the data. To use this "
+                "method correctly, make sure it is run by the parent GaussianNB class.",
+                PrivacyLeakWarning,
+            )
+            n_noisy = X.shape[0]
+
+        if not n_noisy:
+            return mu, var
+
+        if sample_weight is not None:
+            warn_unused_args("sample_weight")
+
+        # Split epsilon between each feature, using 1/3 of total budget for each of mean and variance
+        n_features = X.shape[1]
+        local_epsilon = self.epsilon / 3 / n_features
+
+        new_mu = np.zeros((n_features,))
+        new_var = np.zeros((n_features,))
+
+        for feature in range(n_features):
+            _X = X[:, feature]
+            lower, upper = self.bounds[0][feature], self.bounds[1][feature]
+
+            local_diameter = upper - lower
+
+            mech_mu = (
+                LaplaceTruncated()
+                .set_bounds(lower * n_noisy, upper * n_noisy)
+                .set_epsilon(local_epsilon)
+                .set_sensitivity(local_diameter)
+            )
+            _mu = mech_mu.randomise(_X.sum()) / n_noisy
+
+            local_sq_sens = max(_mu - lower, upper - _mu) ** 2
+            mech_var = (
+                LaplaceBoundedDomain()
+                .set_epsilon(local_epsilon)
+                .set_sensitivity(local_sq_sens)
+                .set_bounds(0, local_sq_sens * n_noisy)
+            )
+            _var = mech_var.randomise(((_X - _mu) ** 2).sum()) / n_noisy
+
+            new_mu[feature] = _mu
+            new_var[feature] = _var
+
+        if n_past == 0:
+            return new_mu, new_var
+
+        n_total = float(n_past + n_noisy)
+
+        # Combine mean of old and new data, taking into consideration
+        # (weighted) number of observations
+        total_mu = (n_noisy * new_mu + n_past * mu) / n_total
+
+        # Combine variance of old and new data, taking into consideration
+        # (weighted) number of observations. This is achieved by combining
+        # the sum-of-squared-differences (ssd)
+        old_ssd = n_past * var
+        new_ssd = n_noisy * new_var
+        total_ssd = (
+            old_ssd
+            + new_ssd
+            + (n_past / float(n_noisy * n_total))
+            * (n_noisy * mu - n_noisy * new_mu) ** 2
+        )
+        total_var = total_ssd / n_total
+
+        return total_mu, total_var
+
+    def _noisy_class_counts(self, y):
+
+        """Adds noise to the number of training samples observed in each class.
+        Parameters
+        ----------
+        y : array-like, shape (n_samples,)
+            Target values
+        Returns
+        -------
+        noisy_counts : array-like
+            Returns after adding geometric noise to number of training samples
+        """
+
+        unique_y = np.unique(y)
+        n_total = y.shape[0]
+
+        # Use 1/3 of total epsilon budget for getting noisy class counts
+        mech = (
+            GeometricTruncated()
+            .set_epsilon(self.epsilon / 3)
+            .set_sensitivity(1)
+            .set_bounds(1, n_total)
+            .set_probability(self.probability)
+        )
+        noisy_counts = np.array([mech.randomise((y == y_i).sum()) for y_i in unique_y])
+
+        argsort = np.argsort(noisy_counts)
+        i = 0 if noisy_counts.sum() > n_total else len(unique_y) - 1
+
+        while np.sum(noisy_counts) != n_total:
+            _i = argsort[i]
+            sgn = np.sign(n_total - noisy_counts.sum())
+            noisy_counts[_i] = np.clip(noisy_counts[_i] + sgn, 1, n_total)
+
+            i = (i - sgn) % len(unique_y)
+
+        return noisy_counts
```

## pydp/ml/mechanisms/base.py

 * *Ordering differences only*

```diff
@@ -1,321 +1,321 @@
-# MIT License
-#
-# Copyright (C) IBM Corporation 2019
-#
-# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
-# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
-# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
-# persons to whom the Software is furnished to do so, subject to the following conditions:
-#
-# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
-# Software.
-#
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
-# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
-# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-# stdlib
-# Source:
-# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/mechanisms/base.py
-import abc
-from copy import copy
-from copy import deepcopy
-from numbers import Real
-
-
-class DPMachine(abc.ABC):
-    """
-    Parent class for :class:`.DPMechanism` and :class:`.DPTransformer`, providing and specifying basic functionality.
-    """
-
-    @abc.abstractmethod
-    def randomise(self, value):
-        """Randomise `value` with the mechanism.
-        Parameters
-        ----------
-        value : int or float or str or method
-            The value to be randomised.
-        Returns
-        -------
-        int or float or str or method
-            The randomised value, same type as `value`.
-        """
-
-    def copy(self):
-        """Produces a copy of the class.
-        Returns
-        -------
-        self : class
-            Returns the copy.
-        """
-        return copy(self)
-
-    def deepcopy(self):
-        """Produces a deep copy of the class.
-        Returns
-        -------
-        self : class
-            Returns the deep copy.
-        """
-        return deepcopy(self)
-
-    def set_epsilon(self, epsilon):
-        r"""Sets the value of epsilon to be used by the mechanism.
-        Parameters
-        ----------
-        epsilon : float
-            The value of epsilon for achieving :math:`\epsilon`-differential privacy with the mechanism.  Must have
-            `epsilon > 0`.
-        Returns
-        -------
-        self : class
-        """
-        return self.set_epsilon_delta(epsilon, 0.0)
-
-    @abc.abstractmethod
-    def set_epsilon_delta(self, epsilon, delta):
-        r"""Sets the value of epsilon and delta to be used by the mechanism.
-        `epsilon` and `delta` cannot both be zero.
-        Parameters
-        ----------
-        epsilon : float
-            The value of epsilon for achieving :math:`(\epsilon,\delta)`-differential privacy with the mechanism.  Must
-            have `epsilon >= 0`.
-        delta : float
-            The value of delta for achieving :math:`(\epsilon,\delta)`-differential privacy with the mechanism.
-            Must have `0 <= delta <= 1`.
-            `delta=0` gives strict (pure) differential privacy (:math:`\epsilon`-differential privacy).  `delta > 0`
-            gives relaxed (approximate) differential privacy.
-        Returns
-        -------
-        self : class
-        """
-
-
-class DPMechanism(DPMachine, abc.ABC):
-    r"""
-    Base class for all mechanisms.  Instantiated from :class:`.DPMachine`.
-    Notes
-    -----
-    * Each `DPMechanism` must define a `randomise` method, to handle the application of differential privacy
-    * Mechanisms that only operate in a limited window of :math:`\epsilon` or :math:`\delta` must define a
-      `set_epsilon_delta` method.  Error-checking, for example for non-zero :math:`\delta` should be done in
-      `set_epsilon_delta`; `set_epsilon` should be left unchanged.
-    * When new methods are added, `__repr__` should be updated accordingly in the mechanism.
-    * Each mechanism's
-    """
-
-    def __init__(self):
-        self._epsilon = None
-        self._delta = None
-
-    def __repr__(self):
-        output = str(self.__module__) + "." + str(self.__class__.__name__) + "()"
-
-        if self._epsilon is not None and self._delta is not None and self._delta > 0.0:
-            output += (
-                ".set_epsilon_delta("
-                + str(self._epsilon)
-                + ","
-                + str(self._delta)
-                + ")"
-            )
-        elif self._epsilon is not None:
-            output += ".set_epsilon(" + str(self._epsilon) + ")"
-
-        return output
-
-    @abc.abstractmethod
-    def randomise(self, value):
-        """Randomise `value` with the mechanism.
-        Parameters
-        ----------
-        value : int or float or str or method
-            The value to be randomised.
-        Returns
-        -------
-        int or float or str or method
-            The randomised value, same type as `value`.
-        """
-
-    def get_bias(self, value):
-        """Returns the bias of the mechanism at a given `value`.
-        Parameters
-        ----------
-        value : int or float
-            The value at which the bias of the mechanism is sought.
-        Returns
-        -------
-        bias : float or None
-            The bias of the mechanism at `value` if defined, `None` otherwise.
-        """
-        raise NotImplementedError
-
-    def get_variance(self, value):
-        """Returns the variance of the mechanism at a given `value`.
-        Parameters
-        ----------
-        value : int or float
-            The value at which the variance of the mechanism is sought.
-        Returns
-        -------
-        bias : float or None
-            The variance of the mechanism at `value` if defined, `None` otherwise.
-        """
-        raise NotImplementedError
-
-    def get_mse(self, value):
-        """Returns the mean squared error (MSE) of the mechanism at a given `value`.
-        Parameters
-        ----------
-        value : int or float
-            The value at which the MSE of the mechanism is sought.
-        Returns
-        -------
-        bias : float or None
-            The MSE of the mechanism at `value` if defined, `None` otherwise.
-        """
-        return self.get_variance(value) + (self.get_bias(value)) ** 2
-
-    def set_epsilon_delta(self, epsilon, delta):
-        r"""Sets the value of epsilon and delta to be used by the mechanism.
-        `epsilon` and `delta` cannot both be zero.
-        Parameters
-        ----------
-        epsilon : float
-            The value of epsilon for achieving :math:`(\epsilon,\delta)`-differential privacy with the mechanism.  Must
-            have `epsilon >= 0`.
-        delta : float
-            The value of delta for achieving :math:`(\epsilon,\delta)`-differential privacy with the mechanism.
-            Must have `0 <= delta <= 1`.
-            `delta=0` gives strict (pure) differential privacy (:math:`\epsilon`-differential privacy).  `delta > 0`
-            gives relaxed (approximate) differential privacy.
-        Returns
-        -------
-        self : class
-        Raises
-        ------
-        ValueError
-            If `epsilon` is negative, or if `delta` falls outside [0,1], or if `epsilon` and `delta` are both zero.
-        """
-        if not isinstance(epsilon, Real) or not isinstance(delta, Real):
-            raise TypeError("Epsilon and delta must be numeric")
-
-        if epsilon < 0:
-            raise ValueError("Epsilon must be non-negative")
-
-        if not 0 <= delta <= 1:
-            raise ValueError("Delta must be in [0, 1]")
-
-        if epsilon + delta == 0:
-            raise ValueError("Epsilon and Delta cannot both be zero")
-
-        self._epsilon = float(epsilon)
-        self._delta = float(delta)
-
-        return self
-
-    def check_inputs(self, value):
-        """Checks that all parameters of the mechanism have been initialised correctly, and that the mechanism is ready
-        to be used.
-        Parameters
-        ----------
-        value : int or float or str or method
-            The value to be checked.
-        Returns
-        -------
-        True if the mechanism is ready to be used.
-        Raises
-        ------
-        Exception
-            If parameters have not been set correctly, or if `value` falls outside the domain of the mechanism.
-        """
-        del value
-        if self._epsilon is None:
-            raise ValueError("Epsilon must be set")
-        return True
-
-
-class TruncationAndFoldingMixin:
-    """
-    Mixin for truncating or folding the outputs of a mechanism.  Must be instantiated with a :class:`.DPMechanism`.
-    """
-
-    def __init__(self):
-        if not isinstance(self, DPMechanism):
-            raise TypeError(
-                "TruncationAndFoldingMachine must be implemented alongside a :class:`.DPMechanism`"
-            )
-
-        self._lower_bound = None
-        self._upper_bound = None
-
-    def __repr__(self):
-        output = (
-            ".set_bounds("
-            + str(self._lower_bound)
-            + ", "
-            + str(self._upper_bound)
-            + ")"
-            if self._lower_bound is not None
-            else ""
-        )
-
-        return output
-
-    def set_bounds(self, lower, upper):
-        """Sets the lower and upper bounds of the mechanism.
-        Must have lower <= upper.
-        Parameters
-        ----------
-        lower : float
-            The lower bound of the mechanism.
-        upper : float
-            The upper bound of the mechanism.
-        Returns
-        -------
-        self : class
-        """
-        if not isinstance(lower, Real) or not isinstance(upper, Real):
-            raise TypeError("Bounds must be numeric")
-
-        if lower > upper:
-            raise ValueError("Lower bound must not be greater than upper bound")
-
-        self._lower_bound = float(lower)
-        self._upper_bound = float(upper)
-
-        return self
-
-    def check_inputs(self, value):
-        """Checks that all parameters of the mechanism have been initialised correctly, and that the mechanism is ready
-        to be used.
-        Parameters
-        ----------
-        value : float
-        Returns
-        -------
-        True if the mechanism is ready to be used.
-        """
-        del value
-        if (self._lower_bound is None) or (self._upper_bound is None):
-            raise ValueError("Upper and lower bounds must be set")
-        return True
-
-    def _truncate(self, value):
-        if value > self._upper_bound:
-            return self._upper_bound
-        if value < self._lower_bound:
-            return self._lower_bound
-
-        return value
-
-    def _fold(self, value):
-        if value < self._lower_bound:
-            return self._fold(2 * self._lower_bound - value)
-        if value > self._upper_bound:
-            return self._fold(2 * self._upper_bound - value)
-
-        return value
+# MIT License
+#
+# Copyright (C) IBM Corporation 2019
+#
+# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
+# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
+# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
+# persons to whom the Software is furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
+# Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
+# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+# stdlib
+# Source:
+# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/mechanisms/base.py
+import abc
+from copy import copy
+from copy import deepcopy
+from numbers import Real
+
+
+class DPMachine(abc.ABC):
+    """
+    Parent class for :class:`.DPMechanism` and :class:`.DPTransformer`, providing and specifying basic functionality.
+    """
+
+    @abc.abstractmethod
+    def randomise(self, value):
+        """Randomise `value` with the mechanism.
+        Parameters
+        ----------
+        value : int or float or str or method
+            The value to be randomised.
+        Returns
+        -------
+        int or float or str or method
+            The randomised value, same type as `value`.
+        """
+
+    def copy(self):
+        """Produces a copy of the class.
+        Returns
+        -------
+        self : class
+            Returns the copy.
+        """
+        return copy(self)
+
+    def deepcopy(self):
+        """Produces a deep copy of the class.
+        Returns
+        -------
+        self : class
+            Returns the deep copy.
+        """
+        return deepcopy(self)
+
+    def set_epsilon(self, epsilon):
+        r"""Sets the value of epsilon to be used by the mechanism.
+        Parameters
+        ----------
+        epsilon : float
+            The value of epsilon for achieving :math:`\epsilon`-differential privacy with the mechanism.  Must have
+            `epsilon > 0`.
+        Returns
+        -------
+        self : class
+        """
+        return self.set_epsilon_delta(epsilon, 0.0)
+
+    @abc.abstractmethod
+    def set_epsilon_delta(self, epsilon, delta):
+        r"""Sets the value of epsilon and delta to be used by the mechanism.
+        `epsilon` and `delta` cannot both be zero.
+        Parameters
+        ----------
+        epsilon : float
+            The value of epsilon for achieving :math:`(\epsilon,\delta)`-differential privacy with the mechanism.  Must
+            have `epsilon >= 0`.
+        delta : float
+            The value of delta for achieving :math:`(\epsilon,\delta)`-differential privacy with the mechanism.
+            Must have `0 <= delta <= 1`.
+            `delta=0` gives strict (pure) differential privacy (:math:`\epsilon`-differential privacy).  `delta > 0`
+            gives relaxed (approximate) differential privacy.
+        Returns
+        -------
+        self : class
+        """
+
+
+class DPMechanism(DPMachine, abc.ABC):
+    r"""
+    Base class for all mechanisms.  Instantiated from :class:`.DPMachine`.
+    Notes
+    -----
+    * Each `DPMechanism` must define a `randomise` method, to handle the application of differential privacy
+    * Mechanisms that only operate in a limited window of :math:`\epsilon` or :math:`\delta` must define a
+      `set_epsilon_delta` method.  Error-checking, for example for non-zero :math:`\delta` should be done in
+      `set_epsilon_delta`; `set_epsilon` should be left unchanged.
+    * When new methods are added, `__repr__` should be updated accordingly in the mechanism.
+    * Each mechanism's
+    """
+
+    def __init__(self):
+        self._epsilon = None
+        self._delta = None
+
+    def __repr__(self):
+        output = str(self.__module__) + "." + str(self.__class__.__name__) + "()"
+
+        if self._epsilon is not None and self._delta is not None and self._delta > 0.0:
+            output += (
+                ".set_epsilon_delta("
+                + str(self._epsilon)
+                + ","
+                + str(self._delta)
+                + ")"
+            )
+        elif self._epsilon is not None:
+            output += ".set_epsilon(" + str(self._epsilon) + ")"
+
+        return output
+
+    @abc.abstractmethod
+    def randomise(self, value):
+        """Randomise `value` with the mechanism.
+        Parameters
+        ----------
+        value : int or float or str or method
+            The value to be randomised.
+        Returns
+        -------
+        int or float or str or method
+            The randomised value, same type as `value`.
+        """
+
+    def get_bias(self, value):
+        """Returns the bias of the mechanism at a given `value`.
+        Parameters
+        ----------
+        value : int or float
+            The value at which the bias of the mechanism is sought.
+        Returns
+        -------
+        bias : float or None
+            The bias of the mechanism at `value` if defined, `None` otherwise.
+        """
+        raise NotImplementedError
+
+    def get_variance(self, value):
+        """Returns the variance of the mechanism at a given `value`.
+        Parameters
+        ----------
+        value : int or float
+            The value at which the variance of the mechanism is sought.
+        Returns
+        -------
+        bias : float or None
+            The variance of the mechanism at `value` if defined, `None` otherwise.
+        """
+        raise NotImplementedError
+
+    def get_mse(self, value):
+        """Returns the mean squared error (MSE) of the mechanism at a given `value`.
+        Parameters
+        ----------
+        value : int or float
+            The value at which the MSE of the mechanism is sought.
+        Returns
+        -------
+        bias : float or None
+            The MSE of the mechanism at `value` if defined, `None` otherwise.
+        """
+        return self.get_variance(value) + (self.get_bias(value)) ** 2
+
+    def set_epsilon_delta(self, epsilon, delta):
+        r"""Sets the value of epsilon and delta to be used by the mechanism.
+        `epsilon` and `delta` cannot both be zero.
+        Parameters
+        ----------
+        epsilon : float
+            The value of epsilon for achieving :math:`(\epsilon,\delta)`-differential privacy with the mechanism.  Must
+            have `epsilon >= 0`.
+        delta : float
+            The value of delta for achieving :math:`(\epsilon,\delta)`-differential privacy with the mechanism.
+            Must have `0 <= delta <= 1`.
+            `delta=0` gives strict (pure) differential privacy (:math:`\epsilon`-differential privacy).  `delta > 0`
+            gives relaxed (approximate) differential privacy.
+        Returns
+        -------
+        self : class
+        Raises
+        ------
+        ValueError
+            If `epsilon` is negative, or if `delta` falls outside [0,1], or if `epsilon` and `delta` are both zero.
+        """
+        if not isinstance(epsilon, Real) or not isinstance(delta, Real):
+            raise TypeError("Epsilon and delta must be numeric")
+
+        if epsilon < 0:
+            raise ValueError("Epsilon must be non-negative")
+
+        if not 0 <= delta <= 1:
+            raise ValueError("Delta must be in [0, 1]")
+
+        if epsilon + delta == 0:
+            raise ValueError("Epsilon and Delta cannot both be zero")
+
+        self._epsilon = float(epsilon)
+        self._delta = float(delta)
+
+        return self
+
+    def check_inputs(self, value):
+        """Checks that all parameters of the mechanism have been initialised correctly, and that the mechanism is ready
+        to be used.
+        Parameters
+        ----------
+        value : int or float or str or method
+            The value to be checked.
+        Returns
+        -------
+        True if the mechanism is ready to be used.
+        Raises
+        ------
+        Exception
+            If parameters have not been set correctly, or if `value` falls outside the domain of the mechanism.
+        """
+        del value
+        if self._epsilon is None:
+            raise ValueError("Epsilon must be set")
+        return True
+
+
+class TruncationAndFoldingMixin:
+    """
+    Mixin for truncating or folding the outputs of a mechanism.  Must be instantiated with a :class:`.DPMechanism`.
+    """
+
+    def __init__(self):
+        if not isinstance(self, DPMechanism):
+            raise TypeError(
+                "TruncationAndFoldingMachine must be implemented alongside a :class:`.DPMechanism`"
+            )
+
+        self._lower_bound = None
+        self._upper_bound = None
+
+    def __repr__(self):
+        output = (
+            ".set_bounds("
+            + str(self._lower_bound)
+            + ", "
+            + str(self._upper_bound)
+            + ")"
+            if self._lower_bound is not None
+            else ""
+        )
+
+        return output
+
+    def set_bounds(self, lower, upper):
+        """Sets the lower and upper bounds of the mechanism.
+        Must have lower <= upper.
+        Parameters
+        ----------
+        lower : float
+            The lower bound of the mechanism.
+        upper : float
+            The upper bound of the mechanism.
+        Returns
+        -------
+        self : class
+        """
+        if not isinstance(lower, Real) or not isinstance(upper, Real):
+            raise TypeError("Bounds must be numeric")
+
+        if lower > upper:
+            raise ValueError("Lower bound must not be greater than upper bound")
+
+        self._lower_bound = float(lower)
+        self._upper_bound = float(upper)
+
+        return self
+
+    def check_inputs(self, value):
+        """Checks that all parameters of the mechanism have been initialised correctly, and that the mechanism is ready
+        to be used.
+        Parameters
+        ----------
+        value : float
+        Returns
+        -------
+        True if the mechanism is ready to be used.
+        """
+        del value
+        if (self._lower_bound is None) or (self._upper_bound is None):
+            raise ValueError("Upper and lower bounds must be set")
+        return True
+
+    def _truncate(self, value):
+        if value > self._upper_bound:
+            return self._upper_bound
+        if value < self._lower_bound:
+            return self._lower_bound
+
+        return value
+
+    def _fold(self, value):
+        if value < self._lower_bound:
+            return self._fold(2 * self._lower_bound - value)
+        if value > self._upper_bound:
+            return self._fold(2 * self._upper_bound - value)
+
+        return value
```

## pydp/ml/mechanisms/geometric.py

 * *Ordering differences only*

```diff
@@ -1,212 +1,212 @@
-# MIT License
-#
-# Copyright (C) IBM Corporation 2019
-#
-# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
-# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
-# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
-# persons to whom the Software is furnished to do so, subject to the following conditions:
-#
-# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
-# Software.
-#
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
-# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
-# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-# Source:
-# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/mechanisms/geometric.py
-
-# stdlib
-import math
-from numbers import Integral
-
-# third party
-import numpy as np
-from numpy.random import random
-
-# pydp absolute
-from pydp.distributions import GeometricDistribution  # type: ignore
-
-# pydp relative
-from ..util.utils import copy_docstring
-from .base import DPMechanism
-from .base import TruncationAndFoldingMixin
-
-
-class Geometric(DPMechanism):
-    """
-    The classic geometric mechanism for differential privacy, as first proposed by Ghosh, Roughgarden and Sundararajan.
-    Extended to allow for non-unity sensitivity.
-    Paper link: https://arxiv.org/pdf/0811.2841.pdf
-    """
-
-    def __init__(self):
-        super().__init__()
-        self._sensitivity = 1
-        self._scale = None
-        self._probability = None
-
-    def __repr__(self):
-        output = super().__repr__()
-        output += (
-            ".set_sensitivity(" + str(self._sensitivity) + ")"
-            if self._sensitivity is not None
-            else ""
-        )
-
-        return output
-
-    def set_probability(self, probability):
-        if probability == 0:
-            raise ValueError("Probability cannot be zero")
-
-        if not 0 <= probability <= 1:
-            raise ValueError("Porbability must be in [0, 1]")
-
-        if probability < 0:
-            raise ValueError("Porbability must be non-negative")
-
-        self._probability = probability
-        return self
-
-    def set_sensitivity(self, sensitivity):
-        """Sets the sensitivity of the mechanism.
-        Parameters
-        ----------
-        sensitivity : int
-            The sensitivity of the mechanism.  Must satisfy `sensitivity` > 0.
-        Returns
-        -------
-        self : class
-        """
-        if not isinstance(sensitivity, Integral):
-            raise TypeError("Sensitivity must be an integer")
-
-        if sensitivity < 0:
-            raise ValueError("Sensitivity must be non-negative")
-
-        self._sensitivity = sensitivity
-        self._scale = None
-        return self
-
-    def check_inputs(self, value):
-        """Checks that all parameters of the mechanism have been initialised correctly, and that the mechanism is ready
-        to be used.
-        Parameters
-        ----------
-        value : int
-            The value to be checked.
-        Returns
-        -------
-        True if the mechanism is ready to be used.
-        Raises
-        ------
-        Exception
-            If parameters have not been set correctly, or if `value` falls outside the domain of the mechanism.
-        """
-        super().check_inputs(value)
-
-        if not isinstance(value, Integral):
-            raise TypeError("Value to be randomised must be an integer")
-
-        if self._scale is None:
-            self._scale = (
-                -self._epsilon / self._sensitivity
-                if self._sensitivity > 0
-                else -float("inf")
-            )
-
-    @copy_docstring(DPMechanism.get_bias)
-    def get_bias(self, value):
-        return 0.0
-
-    @copy_docstring(DPMechanism.get_variance)
-    def get_variance(self, value):
-        self.check_inputs(value)
-
-        leading_factor = (1 - np.exp(self._scale)) / (1 + np.exp(self._scale))
-        geom_series = np.exp(self._scale) / (1 - np.exp(self._scale))
-
-        return (
-            2
-            * leading_factor
-            * (geom_series + 3 * (geom_series**2) + 2 * (geom_series**3))
-        )
-
-    def randomise(self, value):
-        """Randomise `value` with the mechanism.
-        Parameters
-        ----------
-        value : int
-            The value to be randomised.
-        Returns
-        -------
-        int
-            The randomised value.
-        """
-        self.check_inputs(value)
-
-        #         # Need to account for overlap of 0-value between distributions of different sign
-        #         unif_rv = random() - 0.5
-        #         unif_rv *= 1 + np.exp(self._scale)
-
-        #         # Use formula for geometric distribution, with ratio of exp(-epsilon/sensitivity)
-        #         return int(np.round(value + sgn * np.floor(np.log(sgn * unif_rv) / self._scale)))
-        lambda_ = -1.0 * math.log(1 - self._probability)
-        dist = GeometricDistribution(lambda_=lambda_)
-        sample = dist.sample(-self._scale)
-        return value + sample
-
-
-class GeometricTruncated(Geometric, TruncationAndFoldingMixin):
-    """
-    The truncated geometric mechanism, where values that fall outside a pre-described range are mapped back to the
-    closest point within the range.
-    """
-
-    def __init__(self):
-        super().__init__()
-        TruncationAndFoldingMixin.__init__(self)
-
-    def __repr__(self):
-        output = super().__repr__()
-        output += TruncationAndFoldingMixin.__repr__(self)
-
-        return output
-
-    def set_bounds(self, lower, upper):
-        """Sets the lower and upper bounds of the mechanism.
-        For the truncated geometric mechanism, `lower` and `upper` must be integer-valued.  Must have
-        `lower` <= `upper`.
-        Parameters
-        ----------
-        lower : int
-            The lower bound of the mechanism.
-        upper : int
-            The upper bound of the mechanism.
-        Returns
-        -------
-        self : class
-        """
-        if not isinstance(lower, Integral) or not isinstance(upper, Integral):
-            raise TypeError("Bounds must be integers")
-
-        return super().set_bounds(lower, upper)
-
-    @copy_docstring(DPMechanism.get_bias)
-    def get_bias(self, value):
-        raise NotImplementedError
-
-    @copy_docstring(DPMechanism.get_bias)
-    def get_variance(self, value):
-        raise NotImplementedError
-
-    @copy_docstring(Geometric.randomise)
-    def randomise(self, value):
-        TruncationAndFoldingMixin.check_inputs(self, value)
-
-        noisy_value = super().randomise(value)
-        return int(np.round(self._truncate(noisy_value)))
+# MIT License
+#
+# Copyright (C) IBM Corporation 2019
+#
+# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
+# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
+# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
+# persons to whom the Software is furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
+# Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
+# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+# Source:
+# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/mechanisms/geometric.py
+
+# stdlib
+import math
+from numbers import Integral
+
+# third party
+import numpy as np
+from numpy.random import random
+
+# pydp absolute
+from pydp.distributions import GeometricDistribution  # type: ignore
+
+# pydp relative
+from ..util.utils import copy_docstring
+from .base import DPMechanism
+from .base import TruncationAndFoldingMixin
+
+
+class Geometric(DPMechanism):
+    """
+    The classic geometric mechanism for differential privacy, as first proposed by Ghosh, Roughgarden and Sundararajan.
+    Extended to allow for non-unity sensitivity.
+    Paper link: https://arxiv.org/pdf/0811.2841.pdf
+    """
+
+    def __init__(self):
+        super().__init__()
+        self._sensitivity = 1
+        self._scale = None
+        self._probability = None
+
+    def __repr__(self):
+        output = super().__repr__()
+        output += (
+            ".set_sensitivity(" + str(self._sensitivity) + ")"
+            if self._sensitivity is not None
+            else ""
+        )
+
+        return output
+
+    def set_probability(self, probability):
+        if probability == 0:
+            raise ValueError("Probability cannot be zero")
+
+        if not 0 <= probability <= 1:
+            raise ValueError("Porbability must be in [0, 1]")
+
+        if probability < 0:
+            raise ValueError("Porbability must be non-negative")
+
+        self._probability = probability
+        return self
+
+    def set_sensitivity(self, sensitivity):
+        """Sets the sensitivity of the mechanism.
+        Parameters
+        ----------
+        sensitivity : int
+            The sensitivity of the mechanism.  Must satisfy `sensitivity` > 0.
+        Returns
+        -------
+        self : class
+        """
+        if not isinstance(sensitivity, Integral):
+            raise TypeError("Sensitivity must be an integer")
+
+        if sensitivity < 0:
+            raise ValueError("Sensitivity must be non-negative")
+
+        self._sensitivity = sensitivity
+        self._scale = None
+        return self
+
+    def check_inputs(self, value):
+        """Checks that all parameters of the mechanism have been initialised correctly, and that the mechanism is ready
+        to be used.
+        Parameters
+        ----------
+        value : int
+            The value to be checked.
+        Returns
+        -------
+        True if the mechanism is ready to be used.
+        Raises
+        ------
+        Exception
+            If parameters have not been set correctly, or if `value` falls outside the domain of the mechanism.
+        """
+        super().check_inputs(value)
+
+        if not isinstance(value, Integral):
+            raise TypeError("Value to be randomised must be an integer")
+
+        if self._scale is None:
+            self._scale = (
+                -self._epsilon / self._sensitivity
+                if self._sensitivity > 0
+                else -float("inf")
+            )
+
+    @copy_docstring(DPMechanism.get_bias)
+    def get_bias(self, value):
+        return 0.0
+
+    @copy_docstring(DPMechanism.get_variance)
+    def get_variance(self, value):
+        self.check_inputs(value)
+
+        leading_factor = (1 - np.exp(self._scale)) / (1 + np.exp(self._scale))
+        geom_series = np.exp(self._scale) / (1 - np.exp(self._scale))
+
+        return (
+            2
+            * leading_factor
+            * (geom_series + 3 * (geom_series**2) + 2 * (geom_series**3))
+        )
+
+    def randomise(self, value):
+        """Randomise `value` with the mechanism.
+        Parameters
+        ----------
+        value : int
+            The value to be randomised.
+        Returns
+        -------
+        int
+            The randomised value.
+        """
+        self.check_inputs(value)
+
+        #         # Need to account for overlap of 0-value between distributions of different sign
+        #         unif_rv = random() - 0.5
+        #         unif_rv *= 1 + np.exp(self._scale)
+
+        #         # Use formula for geometric distribution, with ratio of exp(-epsilon/sensitivity)
+        #         return int(np.round(value + sgn * np.floor(np.log(sgn * unif_rv) / self._scale)))
+        lambda_ = -1.0 * math.log(1 - self._probability)
+        dist = GeometricDistribution(lambda_=lambda_)
+        sample = dist.sample(-self._scale)
+        return value + sample
+
+
+class GeometricTruncated(Geometric, TruncationAndFoldingMixin):
+    """
+    The truncated geometric mechanism, where values that fall outside a pre-described range are mapped back to the
+    closest point within the range.
+    """
+
+    def __init__(self):
+        super().__init__()
+        TruncationAndFoldingMixin.__init__(self)
+
+    def __repr__(self):
+        output = super().__repr__()
+        output += TruncationAndFoldingMixin.__repr__(self)
+
+        return output
+
+    def set_bounds(self, lower, upper):
+        """Sets the lower and upper bounds of the mechanism.
+        For the truncated geometric mechanism, `lower` and `upper` must be integer-valued.  Must have
+        `lower` <= `upper`.
+        Parameters
+        ----------
+        lower : int
+            The lower bound of the mechanism.
+        upper : int
+            The upper bound of the mechanism.
+        Returns
+        -------
+        self : class
+        """
+        if not isinstance(lower, Integral) or not isinstance(upper, Integral):
+            raise TypeError("Bounds must be integers")
+
+        return super().set_bounds(lower, upper)
+
+    @copy_docstring(DPMechanism.get_bias)
+    def get_bias(self, value):
+        raise NotImplementedError
+
+    @copy_docstring(DPMechanism.get_bias)
+    def get_variance(self, value):
+        raise NotImplementedError
+
+    @copy_docstring(Geometric.randomise)
+    def randomise(self, value):
+        TruncationAndFoldingMixin.check_inputs(self, value)
+
+        noisy_value = super().randomise(value)
+        return int(np.round(self._truncate(noisy_value)))
```

## pydp/ml/mechanisms/laplace.py

 * *Ordering differences only*

```diff
@@ -1,423 +1,423 @@
-# MIT License
-#
-# Copyright (C) IBM Corporation 2019
-#
-# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
-# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
-# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
-# persons to whom the Software is furnished to do so, subject to the following conditions:
-#
-# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
-# Software.
-#
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
-# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
-# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-# Source:
-# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/mechanisms/laplace.py
-
-# stdlib
-from numbers import Real
-
-# third party
-import numpy as np
-from numpy.random import random
-
-# pydp absolute
-from pydp.distributions import LaplaceDistribution  # type: ignore
-from pydp.util import UniformDouble  # type: ignore
-
-# pydp relative
-from ..util.utils import copy_docstring
-from .base import DPMechanism
-from .base import TruncationAndFoldingMixin
-
-
-class Laplace(DPMechanism):
-    r"""
-    The classic Laplace mechanism in differential privacy, as first proposed by Dwork, McSherry, Nissim and Smith.
-    Paper link: https://link.springer.com/content/pdf/10.1007/11681878_14.pdf
-    Includes extension to (relaxed) :math:`(\epsilon,\delta)`-differential privacy, as proposed by Holohan et al.
-    Paper link: https://arxiv.org/pdf/1402.6124.pdf
-    """
-
-    def __init__(self):
-        super().__init__()
-        self._sensitivity = None
-
-    def __repr__(self):
-        output = super().__repr__()
-        output += (
-            ".set_sensitivity(" + str(self._sensitivity) + ")"
-            if self._sensitivity is not None
-            else ""
-        )
-
-        return output
-
-    def set_sensitivity(self, sensitivity):
-        """Sets the sensitivity of the mechanism.
-        Parameters
-        ----------
-        sensitivity : float
-            The sensitivity of the mechanism.  Must satisfy `sensitivity` > 0.
-        Returns
-        -------
-        self : class
-        """
-        if not isinstance(sensitivity, Real):
-            raise TypeError("Sensitivity must be numeric")
-
-        if sensitivity < 0:
-            raise ValueError("Sensitivity must be non-negative")
-
-        self._sensitivity = float(sensitivity)
-        return self
-
-    def check_inputs(self, value):
-        """Checks that all parameters of the mechanism have been initialised correctly, and that the mechanism is ready
-        to be used.
-        Parameters
-        ----------
-        value : float
-            The value to be checked
-        Returns
-        -------
-        True if the mechanism is ready to be used.
-        Raises
-        ------
-        Exception
-            If parameters have not been set correctly, or if `value` falls outside the domain of the mechanism.
-        """
-        super().check_inputs(value)
-
-        if not isinstance(value, Real):
-            raise TypeError("Value to be randomised must be a number")
-
-        if self._sensitivity is None:
-            raise ValueError("Sensitivity must be set")
-
-        return True
-
-    def get_bias(self, value):
-        """Returns the bias of the mechanism at a given `value`.
-        Parameters
-        ----------
-        value : int or float
-            The value at which the bias of the mechanism is sought.
-        Returns
-        -------
-        bias : float or None
-            The bias of the mechanism at `value`.
-        """
-        return 0.0
-
-    def get_variance(self, value):
-        """Returns the variance of the mechanism at a given `value`.
-        Parameters
-        ----------
-        value : float
-            The value at which the variance of the mechanism is sought.
-        Returns
-        -------
-        bias : float
-            The variance of the mechanism at `value`.
-        """
-        self.check_inputs(0)
-
-        return 2 * (self._sensitivity / (self._epsilon - np.log(1 - self._delta))) ** 2
-
-    def randomise(self, value):
-        """Randomise `value` with the mechanism.
-        Parameters
-        ----------
-        value : float
-            The value to be randomised.
-        Returns
-        -------
-        float
-            The randomised value.
-        """
-        self.check_inputs(value)
-
-        #         scale = self._sensitivity / (self._epsilon - np.log(1 - self._delta))
-
-        #         unif_rv = random() - 0.5
-
-        #         return value - scale * np.sign(unif_rv) * np.log(1 - 2 * np.abs(unif_rv))
-
-        scale = self._sensitivity / (self._epsilon - np.log(1 - self._delta))
-
-        dist = LaplaceDistribution(epsilon=self._epsilon, sensitivity=self._sensitivity)
-
-        sample = dist.sample(scale=scale)
-
-        return value - sample
-
-
-class LaplaceTruncated(Laplace, TruncationAndFoldingMixin):
-    """
-    The truncated Laplace mechanism, where values outside a pre-described domain are mapped to the closest point
-    within the domain.
-    """
-
-    def __init__(self):
-        super().__init__()
-        TruncationAndFoldingMixin.__init__(self)
-
-    def __repr__(self):
-        output = super().__repr__()
-        output += TruncationAndFoldingMixin.__repr__(self)
-
-        return output
-
-    @copy_docstring(Laplace.get_bias)
-    def get_bias(self, value):
-        self.check_inputs(value)
-
-        shape = self._sensitivity / self._epsilon
-
-        return (
-            shape
-            / 2
-            * (
-                np.exp((self._lower_bound - value) / shape)
-                - np.exp((value - self._upper_bound) / shape)
-            )
-        )
-
-    @copy_docstring(Laplace.get_variance)
-    def get_variance(self, value):
-        self.check_inputs(value)
-
-        shape = self._sensitivity / self._epsilon
-
-        variance = value**2 + shape * (
-            self._lower_bound * np.exp((self._lower_bound - value) / shape)
-            - self._upper_bound * np.exp((value - self._upper_bound) / shape)
-        )
-        variance += (shape**2) * (
-            2
-            - np.exp((self._lower_bound - value) / shape)
-            - np.exp((value - self._upper_bound) / shape)
-        )
-
-        variance -= (self.get_bias(value) + value) ** 2
-
-        return variance
-
-    @copy_docstring(Laplace.check_inputs)
-    def check_inputs(self, value):
-        super().check_inputs(value)
-        TruncationAndFoldingMixin.check_inputs(self, value)
-
-        return True
-
-    @copy_docstring(Laplace.randomise)
-    def randomise(self, value):
-        TruncationAndFoldingMixin.check_inputs(self, value)
-
-        noisy_value = super().randomise(value)
-        return self._truncate(noisy_value)
-
-
-class LaplaceFolded(Laplace, TruncationAndFoldingMixin):
-    """
-    The folded Laplace mechanism, where values outside a pre-described domain are folded around the domain until they
-    fall within.
-    """
-
-    def __init__(self):
-        super().__init__()
-        TruncationAndFoldingMixin.__init__(self)
-
-    def __repr__(self):
-        output = super().__repr__()
-        output += TruncationAndFoldingMixin.__repr__(self)
-
-        return output
-
-    @copy_docstring(Laplace.get_bias)
-    def get_bias(self, value):
-        self.check_inputs(value)
-
-        shape = self._sensitivity / self._epsilon
-
-        bias = shape * (
-            np.exp((self._lower_bound + self._upper_bound - 2 * value) / shape) - 1
-        )
-        bias /= np.exp((self._lower_bound - value) / shape) + np.exp(
-            (self._upper_bound - value) / shape
-        )
-
-        return bias
-
-    @copy_docstring(DPMechanism.get_variance)
-    def get_variance(self, value):
-        raise NotImplementedError
-
-    @copy_docstring(Laplace.check_inputs)
-    def check_inputs(self, value):
-        super().check_inputs(value)
-        TruncationAndFoldingMixin.check_inputs(self, value)
-
-        return True
-
-    @copy_docstring(Laplace.randomise)
-    def randomise(self, value):
-        TruncationAndFoldingMixin.check_inputs(self, value)
-
-        noisy_value = super().randomise(value)
-        return self._fold(noisy_value)
-
-
-class LaplaceBoundedDomain(LaplaceTruncated):
-    """
-    The bounded Laplace mechanism on a bounded domain.  The mechanism draws values directly from the domain, without any
-    post-processing.
-    """
-
-    def __init__(self):
-        super().__init__()
-        self._scale = None
-
-    def _find_scale(self):
-        if self._epsilon is None or self._delta is None:
-            raise ValueError(
-                "Epsilon and Delta must be set before calling _find_scale()."
-            )
-
-        eps = self._epsilon
-        delta = self._delta
-        diam = self._upper_bound - self._lower_bound
-        delta_q = self._sensitivity
-
-        def _delta_c(shape):
-            if shape == 0:
-                return 2.0
-            return (
-                2 - np.exp(-delta_q / shape) - np.exp(-(diam - delta_q) / shape)
-            ) / (1 - np.exp(-diam / shape))
-
-        def _f(shape):
-            return delta_q / (eps - np.log(_delta_c(shape)) - np.log(1 - delta))
-
-        left = delta_q / (eps - np.log(1 - delta))
-        right = _f(left)
-        old_interval_size = (right - left) * 2
-
-        while old_interval_size > right - left:
-            old_interval_size = right - left
-            middle = (right + left) / 2
-
-            if _f(middle) >= middle:
-                left = middle
-            if _f(middle) <= middle:
-                right = middle
-
-        return (right + left) / 2
-
-    def _cdf(self, value):
-        # Allow for infinite epsilon
-        if self._scale == 0:
-            return 0 if value < 0 else 1
-
-        if value < 0:
-            return 0.5 * np.exp(value / self._scale)
-
-        return 1 - 0.5 * np.exp(-value / self._scale)
-
-    def get_effective_epsilon(self):
-        r"""Gets the effective epsilon of the mechanism, only for strict :math:`\epsilon`-differential privacy.  Returns
-        ``None`` if :math:`\delta` is non-zero.
-        Returns
-        -------
-        float
-            The effective :math:`\epsilon` parameter of the mechanism.  Returns ``None`` if `delta` is non-zero.
-        """
-        if self._scale is None:
-            self._scale = self._find_scale()
-
-        if self._delta > 0.0:
-            return None
-
-        return self._sensitivity / self._scale
-
-    @copy_docstring(Laplace.get_bias)
-    def get_bias(self, value):
-        self.check_inputs(value)
-
-        if self._scale is None:
-            self._scale = self._find_scale()
-
-        bias = (self._scale - self._lower_bound + value) / 2 * np.exp(
-            (self._lower_bound - value) / self._scale
-        ) - (self._scale + self._upper_bound - value) / 2 * np.exp(
-            (value - self._upper_bound) / self._scale
-        )
-        bias /= (
-            1
-            - np.exp((self._lower_bound - value) / self._scale) / 2
-            - np.exp((value - self._upper_bound) / self._scale) / 2
-        )
-
-        return bias
-
-    @copy_docstring(Laplace.get_variance)
-    def get_variance(self, value):
-        self.check_inputs(value)
-
-        if self._scale is None:
-            self._scale = self._find_scale()
-
-        variance = value**2
-        variance -= (
-            np.exp((self._lower_bound - value) / self._scale) * (self._lower_bound**2)
-            + np.exp((value - self._upper_bound) / self._scale)
-            * (self._upper_bound**2)
-        ) / 2
-        variance += self._scale * (
-            self._lower_bound * np.exp((self._lower_bound - value) / self._scale)
-            - self._upper_bound * np.exp((value - self._upper_bound) / self._scale)
-        )
-        variance += (self._scale**2) * (
-            2
-            - np.exp((self._lower_bound - value) / self._scale)
-            - np.exp((value - self._upper_bound) / self._scale)
-        )
-        variance /= (
-            1
-            - (
-                np.exp(-(value - self._lower_bound) / self._scale)
-                + np.exp(-(self._upper_bound - value) / self._scale)
-            )
-            / 2
-        )
-
-        variance -= (self.get_bias(value) + value) ** 2
-
-        return variance
-
-    @copy_docstring(Laplace.randomise)
-    def randomise(self, value):
-        self.check_inputs(value)
-
-        if self._scale is None:
-            self._scale = self._find_scale()
-
-        value = min(value, self._upper_bound)
-        value = max(value, self._lower_bound)
-
-        unif_rv = UniformDouble()
-        unif_rv *= self._cdf(self._upper_bound - value) - self._cdf(
-            self._lower_bound - value
-        )
-        unif_rv += self._cdf(self._lower_bound - value)
-        unif_rv -= 0.5
-
-        unif_rv = min(unif_rv, 0.5 - 1e-10)
-
-        return value - self._scale * np.sign(unif_rv) * np.log(1 - 2 * np.abs(unif_rv))
+# MIT License
+#
+# Copyright (C) IBM Corporation 2019
+#
+# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
+# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
+# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
+# persons to whom the Software is furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
+# Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
+# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+# Source:
+# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/mechanisms/laplace.py
+
+# stdlib
+from numbers import Real
+
+# third party
+import numpy as np
+from numpy.random import random
+
+# pydp absolute
+from pydp.distributions import LaplaceDistribution  # type: ignore
+from pydp.util import UniformDouble  # type: ignore
+
+# pydp relative
+from ..util.utils import copy_docstring
+from .base import DPMechanism
+from .base import TruncationAndFoldingMixin
+
+
+class Laplace(DPMechanism):
+    r"""
+    The classic Laplace mechanism in differential privacy, as first proposed by Dwork, McSherry, Nissim and Smith.
+    Paper link: https://link.springer.com/content/pdf/10.1007/11681878_14.pdf
+    Includes extension to (relaxed) :math:`(\epsilon,\delta)`-differential privacy, as proposed by Holohan et al.
+    Paper link: https://arxiv.org/pdf/1402.6124.pdf
+    """
+
+    def __init__(self):
+        super().__init__()
+        self._sensitivity = None
+
+    def __repr__(self):
+        output = super().__repr__()
+        output += (
+            ".set_sensitivity(" + str(self._sensitivity) + ")"
+            if self._sensitivity is not None
+            else ""
+        )
+
+        return output
+
+    def set_sensitivity(self, sensitivity):
+        """Sets the sensitivity of the mechanism.
+        Parameters
+        ----------
+        sensitivity : float
+            The sensitivity of the mechanism.  Must satisfy `sensitivity` > 0.
+        Returns
+        -------
+        self : class
+        """
+        if not isinstance(sensitivity, Real):
+            raise TypeError("Sensitivity must be numeric")
+
+        if sensitivity < 0:
+            raise ValueError("Sensitivity must be non-negative")
+
+        self._sensitivity = float(sensitivity)
+        return self
+
+    def check_inputs(self, value):
+        """Checks that all parameters of the mechanism have been initialised correctly, and that the mechanism is ready
+        to be used.
+        Parameters
+        ----------
+        value : float
+            The value to be checked
+        Returns
+        -------
+        True if the mechanism is ready to be used.
+        Raises
+        ------
+        Exception
+            If parameters have not been set correctly, or if `value` falls outside the domain of the mechanism.
+        """
+        super().check_inputs(value)
+
+        if not isinstance(value, Real):
+            raise TypeError("Value to be randomised must be a number")
+
+        if self._sensitivity is None:
+            raise ValueError("Sensitivity must be set")
+
+        return True
+
+    def get_bias(self, value):
+        """Returns the bias of the mechanism at a given `value`.
+        Parameters
+        ----------
+        value : int or float
+            The value at which the bias of the mechanism is sought.
+        Returns
+        -------
+        bias : float or None
+            The bias of the mechanism at `value`.
+        """
+        return 0.0
+
+    def get_variance(self, value):
+        """Returns the variance of the mechanism at a given `value`.
+        Parameters
+        ----------
+        value : float
+            The value at which the variance of the mechanism is sought.
+        Returns
+        -------
+        bias : float
+            The variance of the mechanism at `value`.
+        """
+        self.check_inputs(0)
+
+        return 2 * (self._sensitivity / (self._epsilon - np.log(1 - self._delta))) ** 2
+
+    def randomise(self, value):
+        """Randomise `value` with the mechanism.
+        Parameters
+        ----------
+        value : float
+            The value to be randomised.
+        Returns
+        -------
+        float
+            The randomised value.
+        """
+        self.check_inputs(value)
+
+        #         scale = self._sensitivity / (self._epsilon - np.log(1 - self._delta))
+
+        #         unif_rv = random() - 0.5
+
+        #         return value - scale * np.sign(unif_rv) * np.log(1 - 2 * np.abs(unif_rv))
+
+        scale = self._sensitivity / (self._epsilon - np.log(1 - self._delta))
+
+        dist = LaplaceDistribution(epsilon=self._epsilon, sensitivity=self._sensitivity)
+
+        sample = dist.sample(scale=scale)
+
+        return value - sample
+
+
+class LaplaceTruncated(Laplace, TruncationAndFoldingMixin):
+    """
+    The truncated Laplace mechanism, where values outside a pre-described domain are mapped to the closest point
+    within the domain.
+    """
+
+    def __init__(self):
+        super().__init__()
+        TruncationAndFoldingMixin.__init__(self)
+
+    def __repr__(self):
+        output = super().__repr__()
+        output += TruncationAndFoldingMixin.__repr__(self)
+
+        return output
+
+    @copy_docstring(Laplace.get_bias)
+    def get_bias(self, value):
+        self.check_inputs(value)
+
+        shape = self._sensitivity / self._epsilon
+
+        return (
+            shape
+            / 2
+            * (
+                np.exp((self._lower_bound - value) / shape)
+                - np.exp((value - self._upper_bound) / shape)
+            )
+        )
+
+    @copy_docstring(Laplace.get_variance)
+    def get_variance(self, value):
+        self.check_inputs(value)
+
+        shape = self._sensitivity / self._epsilon
+
+        variance = value**2 + shape * (
+            self._lower_bound * np.exp((self._lower_bound - value) / shape)
+            - self._upper_bound * np.exp((value - self._upper_bound) / shape)
+        )
+        variance += (shape**2) * (
+            2
+            - np.exp((self._lower_bound - value) / shape)
+            - np.exp((value - self._upper_bound) / shape)
+        )
+
+        variance -= (self.get_bias(value) + value) ** 2
+
+        return variance
+
+    @copy_docstring(Laplace.check_inputs)
+    def check_inputs(self, value):
+        super().check_inputs(value)
+        TruncationAndFoldingMixin.check_inputs(self, value)
+
+        return True
+
+    @copy_docstring(Laplace.randomise)
+    def randomise(self, value):
+        TruncationAndFoldingMixin.check_inputs(self, value)
+
+        noisy_value = super().randomise(value)
+        return self._truncate(noisy_value)
+
+
+class LaplaceFolded(Laplace, TruncationAndFoldingMixin):
+    """
+    The folded Laplace mechanism, where values outside a pre-described domain are folded around the domain until they
+    fall within.
+    """
+
+    def __init__(self):
+        super().__init__()
+        TruncationAndFoldingMixin.__init__(self)
+
+    def __repr__(self):
+        output = super().__repr__()
+        output += TruncationAndFoldingMixin.__repr__(self)
+
+        return output
+
+    @copy_docstring(Laplace.get_bias)
+    def get_bias(self, value):
+        self.check_inputs(value)
+
+        shape = self._sensitivity / self._epsilon
+
+        bias = shape * (
+            np.exp((self._lower_bound + self._upper_bound - 2 * value) / shape) - 1
+        )
+        bias /= np.exp((self._lower_bound - value) / shape) + np.exp(
+            (self._upper_bound - value) / shape
+        )
+
+        return bias
+
+    @copy_docstring(DPMechanism.get_variance)
+    def get_variance(self, value):
+        raise NotImplementedError
+
+    @copy_docstring(Laplace.check_inputs)
+    def check_inputs(self, value):
+        super().check_inputs(value)
+        TruncationAndFoldingMixin.check_inputs(self, value)
+
+        return True
+
+    @copy_docstring(Laplace.randomise)
+    def randomise(self, value):
+        TruncationAndFoldingMixin.check_inputs(self, value)
+
+        noisy_value = super().randomise(value)
+        return self._fold(noisy_value)
+
+
+class LaplaceBoundedDomain(LaplaceTruncated):
+    """
+    The bounded Laplace mechanism on a bounded domain.  The mechanism draws values directly from the domain, without any
+    post-processing.
+    """
+
+    def __init__(self):
+        super().__init__()
+        self._scale = None
+
+    def _find_scale(self):
+        if self._epsilon is None or self._delta is None:
+            raise ValueError(
+                "Epsilon and Delta must be set before calling _find_scale()."
+            )
+
+        eps = self._epsilon
+        delta = self._delta
+        diam = self._upper_bound - self._lower_bound
+        delta_q = self._sensitivity
+
+        def _delta_c(shape):
+            if shape == 0:
+                return 2.0
+            return (
+                2 - np.exp(-delta_q / shape) - np.exp(-(diam - delta_q) / shape)
+            ) / (1 - np.exp(-diam / shape))
+
+        def _f(shape):
+            return delta_q / (eps - np.log(_delta_c(shape)) - np.log(1 - delta))
+
+        left = delta_q / (eps - np.log(1 - delta))
+        right = _f(left)
+        old_interval_size = (right - left) * 2
+
+        while old_interval_size > right - left:
+            old_interval_size = right - left
+            middle = (right + left) / 2
+
+            if _f(middle) >= middle:
+                left = middle
+            if _f(middle) <= middle:
+                right = middle
+
+        return (right + left) / 2
+
+    def _cdf(self, value):
+        # Allow for infinite epsilon
+        if self._scale == 0:
+            return 0 if value < 0 else 1
+
+        if value < 0:
+            return 0.5 * np.exp(value / self._scale)
+
+        return 1 - 0.5 * np.exp(-value / self._scale)
+
+    def get_effective_epsilon(self):
+        r"""Gets the effective epsilon of the mechanism, only for strict :math:`\epsilon`-differential privacy.  Returns
+        ``None`` if :math:`\delta` is non-zero.
+        Returns
+        -------
+        float
+            The effective :math:`\epsilon` parameter of the mechanism.  Returns ``None`` if `delta` is non-zero.
+        """
+        if self._scale is None:
+            self._scale = self._find_scale()
+
+        if self._delta > 0.0:
+            return None
+
+        return self._sensitivity / self._scale
+
+    @copy_docstring(Laplace.get_bias)
+    def get_bias(self, value):
+        self.check_inputs(value)
+
+        if self._scale is None:
+            self._scale = self._find_scale()
+
+        bias = (self._scale - self._lower_bound + value) / 2 * np.exp(
+            (self._lower_bound - value) / self._scale
+        ) - (self._scale + self._upper_bound - value) / 2 * np.exp(
+            (value - self._upper_bound) / self._scale
+        )
+        bias /= (
+            1
+            - np.exp((self._lower_bound - value) / self._scale) / 2
+            - np.exp((value - self._upper_bound) / self._scale) / 2
+        )
+
+        return bias
+
+    @copy_docstring(Laplace.get_variance)
+    def get_variance(self, value):
+        self.check_inputs(value)
+
+        if self._scale is None:
+            self._scale = self._find_scale()
+
+        variance = value**2
+        variance -= (
+            np.exp((self._lower_bound - value) / self._scale) * (self._lower_bound**2)
+            + np.exp((value - self._upper_bound) / self._scale)
+            * (self._upper_bound**2)
+        ) / 2
+        variance += self._scale * (
+            self._lower_bound * np.exp((self._lower_bound - value) / self._scale)
+            - self._upper_bound * np.exp((value - self._upper_bound) / self._scale)
+        )
+        variance += (self._scale**2) * (
+            2
+            - np.exp((self._lower_bound - value) / self._scale)
+            - np.exp((value - self._upper_bound) / self._scale)
+        )
+        variance /= (
+            1
+            - (
+                np.exp(-(value - self._lower_bound) / self._scale)
+                + np.exp(-(self._upper_bound - value) / self._scale)
+            )
+            / 2
+        )
+
+        variance -= (self.get_bias(value) + value) ** 2
+
+        return variance
+
+    @copy_docstring(Laplace.randomise)
+    def randomise(self, value):
+        self.check_inputs(value)
+
+        if self._scale is None:
+            self._scale = self._find_scale()
+
+        value = min(value, self._upper_bound)
+        value = max(value, self._lower_bound)
+
+        unif_rv = UniformDouble()
+        unif_rv *= self._cdf(self._upper_bound - value) - self._cdf(
+            self._lower_bound - value
+        )
+        unif_rv += self._cdf(self._lower_bound - value)
+        unif_rv -= 0.5
+
+        unif_rv = min(unif_rv, 0.5 - 1e-10)
+
+        return value - self._scale * np.sign(unif_rv) * np.log(1 - 2 * np.abs(unif_rv))
```

## pydp/ml/util/accountant.py

 * *Ordering differences only*

```diff
@@ -1,393 +1,393 @@
-# MIT License
-#
-# Copyright (C) IBM Corporation 2019
-#
-# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
-# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
-# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
-# persons to whom the Software is furnished to do so, subject to the following conditions:
-#
-# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
-# Software.
-#
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
-# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
-# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-# Source:
-# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/accountant.py
-
-# stdlib
-from numbers import Integral
-
-# third party
-import numpy as np  # type: ignore
-
-# pydp relative
-from .utils import Budget  # type: ignore
-from .utils import BudgetError
-from .validation import check_epsilon_delta  # type: ignore
-
-
-class BudgetAccountant:
-    """Privacy budget accountant for differential privacy.
-    This class creates a privacy budget accountant to track privacy spend across queries and other data accesses.  Once
-    initialised, the BudgetAccountant stores each privacy spend and iteratively updates the total budget spend, raising
-    an error when the budget ceiling (if specified) is exceeded.  The accountant can be initialised without any maximum
-    budget, to enable users track the total privacy spend of their actions without hindrance.
-    Parameters
-    ----------
-    epsilon : float, default: infinity
-        Epsilon budget ceiling of the accountant.
-    delta : float, default: 1.0
-        Delta budget ceiling of the accountant.
-    slack : float, default: 0.0
-        Slack allowed in delta spend.  Greater slack may reduce the overall epsilon spend.
-    spent_budget : list of tuples of the form (epsilon, delta), optional
-        List of tuples of pre-existing budget spends.  Allows for a new accountant to be initialised with spends
-        extracted from a previous instance.
-    Attributes
-    ----------
-    epsilon : float
-        Epsilon budget ceiling of the accountant.
-    delta : float
-        Delta budget ceiling of the accountant.
-    slack : float
-        The accountant's slack.  Can be modified at runtime, subject to the privacy budget not being exceeded.
-    spent_budget : list of tuples of the form (epsilon, delta)
-        The list of privacy spends recorded by the accountant.  Can be used in the initialisation of a new accountant.
-    """
-
-    _default = None
-
-    def __init__(self, epsilon=float("inf"), delta=1.0, slack=0.0, spent_budget=None):
-        check_epsilon_delta(epsilon, delta)
-        self.__epsilon = epsilon
-        self.__min_epsilon = 0 if epsilon == float("inf") else epsilon * 1e-14
-        self.__delta = delta
-        self.__spent_budget = []
-        self.slack = slack
-
-        if spent_budget is not None:
-            if not isinstance(spent_budget, list):
-                raise TypeError("spent_budget must be a list")
-
-            for _epsilon, _delta in spent_budget:
-                self.spend(_epsilon, _delta)
-
-    def __repr__(self, n_budget_max=5):
-        params = []
-        if self.epsilon != float("inf"):
-            params.append(f"epsilon={self.epsilon:g}")
-
-        if self.delta != 1:
-            params.append(f"delta={self.delta:g}")
-
-        if self.slack > 0:
-            params.append(f"slack={self.slack:g}")
-
-        if self.spent_budget:
-            if len(self.spent_budget) > n_budget_max:
-                params.append(
-                    "spent_budget=%s"
-                    % str(self.spent_budget[:n_budget_max] + ["..."]).replace("'", "")
-                )
-            else:
-                params.append(f"spent_budget={str(self.spent_budget)}")
-
-        return "BudgetAccountant(" + ", ".join(params) + ")"
-
-    def __enter__(self):
-        self.old_default = self.pop_default()
-        self.set_default()
-        return self
-
-    def __exit__(self, exc_type, exc_val, exc_tb):
-        self.pop_default()
-
-        if self.old_default is not None:
-            self.old_default.set_default()
-        del self.old_default
-
-    def __len__(self):
-        return len(self.spent_budget)
-
-    @property
-    def slack(self):
-        """Slack parameter for composition."""
-        return self.__slack
-
-    @slack.setter
-    def slack(self, slack):
-        if not 0 <= slack <= self.delta:
-            raise ValueError(
-                "Slack must be between 0 and delta ({}), inclusive. Got {}.".format(
-                    self.delta, slack
-                )
-            )
-
-        epsilon_spent, delta_spent = self.total(slack=slack)
-
-        if self.epsilon < epsilon_spent or self.delta < delta_spent:
-            raise BudgetError(
-                f"Privacy budget will be exceeded by changing slack to {slack}."
-            )
-
-        self.__slack = slack
-
-    @property
-    def spent_budget(self):
-        """List of tuples of the form (epsilon, delta) of spent privacy budget."""
-        return self.__spent_budget.copy()
-
-    @property
-    def epsilon(self):
-        """Epsilon privacy ceiling of the accountant."""
-        return self.__epsilon
-
-    @property
-    def delta(self):
-        """Delta privacy ceiling of the accountant."""
-        return self.__delta
-
-    def total(self, spent_budget=None, slack=None):
-        """Returns the total current privacy spend.
-        `spent_budget` and `slack` can be specified as parameters, otherwise the class values will be used.
-        Parameters
-        ----------
-        spent_budget : list of tuples of the form (epsilon, delta), optional
-            List of tuples of budget spends.  If not provided, the accountant's spends will be used.
-        slack : float, optional
-            Slack in delta for composition.  If not provided, the accountant's slack will be used.
-        Returns
-        -------
-        epsilon : float
-            Total epsilon spend.
-        delta : float
-            Total delta spend.
-        """
-        if spent_budget is None:
-            spent_budget = self.spent_budget
-        else:
-            for epsilon, delta in spent_budget:
-                check_epsilon_delta(epsilon, delta)
-
-        if slack is None:
-            slack = self.slack
-        elif not 0 <= slack <= self.delta:
-            raise ValueError(
-                "Slack must be between 0 and delta ({}), inclusive. Got {}.".format(
-                    self.delta, slack
-                )
-            )
-
-        epsilon_sum, epsilon_exp_sum, epsilon_sq_sum = 0, 0, 0
-
-        for epsilon, _ in spent_budget:
-            epsilon_sum += epsilon
-            epsilon_exp_sum += (1 - np.exp(-epsilon)) * epsilon / (1 + np.exp(-epsilon))
-            epsilon_sq_sum += epsilon**2
-
-        total_epsilon_naive = epsilon_sum
-        total_delta = self.__total_delta_safe(spent_budget, slack)
-
-        if slack == 0:
-            return Budget(total_epsilon_naive, total_delta)
-
-        total_epsilon_drv = epsilon_exp_sum + np.sqrt(
-            2 * epsilon_sq_sum * np.log(1 / slack)
-        )
-        total_epsilon_kov = epsilon_exp_sum + np.sqrt(
-            2 * epsilon_sq_sum * np.log(np.exp(1) + np.sqrt(epsilon_sq_sum) / slack)
-        )
-
-        return Budget(
-            min(total_epsilon_naive, total_epsilon_drv, total_epsilon_kov), total_delta
-        )
-
-    def check(self, epsilon, delta):
-        """Checks if the provided (epsilon,delta) can be spent without exceeding the accountant's budget ceiling.
-        Parameters
-        ----------
-        epsilon : float
-            Epsilon budget spend to check.
-        delta : float
-            Delta budget spend to check.
-        Returns
-        -------
-        bool
-            True if the budget can be spent, otherwise a :class:`.BudgetError` is raised.
-        Raises
-        ------
-        BudgetError
-            If the specified budget spend will result in the budget ceiling being exceeded.
-        """
-        check_epsilon_delta(epsilon, delta)
-        if self.epsilon == float("inf") and self.delta == 1:
-            return True
-
-        if 0 < epsilon < self.__min_epsilon:
-            raise ValueError(
-                "Epsilon must be at least {} if non-zero, got {}.".format(
-                    self.__min_epsilon, epsilon
-                )
-            )
-
-        spent_budget = self.spent_budget + [(epsilon, delta)]
-
-        if Budget(self.epsilon, self.delta) >= self.total(spent_budget=spent_budget):
-            return True
-
-        raise BudgetError(
-            "Privacy spend of ({},{}) not permissible; will exceed remaining privacy budget. "
-            "Use {}.{}() to check remaining budget.".format(
-                epsilon, delta, self.__class__.__name__, self.remaining.__name__
-            )
-        )
-
-    def remaining(self, k=1):
-        """Calculates the budget that remains to be spent.
-        Calculates the privacy budget that can be spent on `k` queries.  Spending this budget on `k` queries will
-        match the budget ceiling, assuming no floating point errors.
-        Parameters
-        ----------
-        k : int, default: 1
-            The number of queries for which to calculate the remaining budget.
-        Returns
-        -------
-        epsilon : float
-            Total epsilon spend remaining for `k` queries.
-        delta : float
-            Total delta spend remaining for `k` queries.
-        """
-        if not isinstance(k, Integral):
-            raise TypeError("k must be integer-valued, got {}.".format(type(k)))
-        if k < 1:
-            raise ValueError(f"k must be at least 1, got {k}.")
-
-        _, spent_delta = self.total()
-        delta = (
-            1 - ((1 - self.delta) / (1 - spent_delta)) ** (1 / k)
-            if spent_delta < 1.0
-            else 1.0
-        )
-        # delta = 1 - np.exp((np.log(1 - self.delta) - np.log(1 - spent_delta)) / k)
-
-        lower = 0
-        upper = self.epsilon
-        old_interval_size = (upper - lower) * 2
-
-        while old_interval_size > upper - lower:
-            old_interval_size = upper - lower
-            mid = (upper + lower) / 2
-
-            spent_budget = self.spent_budget + [(mid, 0)] * k
-            x_0, _ = self.total(spent_budget=spent_budget)
-
-            if x_0 >= self.epsilon:
-                upper = mid
-            if x_0 <= self.epsilon:
-                lower = mid
-
-        epsilon = (upper + lower) / 2
-
-        return Budget(epsilon, delta)
-
-    def spend(self, epsilon, delta):
-        """Spend the given privacy budget.
-        Instructs the accountant to spend the given epsilon and delta privacy budget, while ensuring the target budget
-        is not exceeded.
-        Parameters
-        ----------
-        epsilon : float
-            Epsilon privacy budget to spend.
-        delta : float
-            Delta privacy budget to spend.
-        Returns
-        -------
-        self : BudgetAccountant
-        """
-        self.check(epsilon, delta)
-        self.__spent_budget.append((epsilon, delta))
-        return self
-
-    @staticmethod
-    def __total_delta_safe(spent_budget, slack):
-        """
-        Calculate total delta spend of `spent_budget`, with special consideration for floating point arithmetic.
-        Should yield greater precision, especially for a large number of budget spends with very small delta.
-        Parameters
-        ----------
-        spent_budget: list of tuples of the form (epsilon, delta)
-            List of budget spends, for which the total delta spend is to be calculated.
-        slack: float
-            Delta slack parameter for composition of spends.
-        Returns
-        -------
-        float
-            Total delta spend.
-        """
-        delta_spend = [slack]
-        for _, delta in spent_budget:
-            delta_spend.append(delta)
-        delta_spend.sort()
-
-        # (1 - a) * (1 - b) = 1 - (a + b - a * b)
-        prod = 0
-        for delta in delta_spend:
-            prod += delta - prod * delta
-
-        return prod
-
-    @staticmethod
-    def load_default(accountant):
-        """Loads the default privacy budget accountant if none is supplied, otherwise checks that the supplied
-        accountant is a BudgetAccountant class.
-        An accountant can be set as the default using the `set_default()` method.  If no default has been set, a default
-        is created.
-        Parameters
-        ----------
-        accountant : BudgetAccountant or None
-            The supplied budget accountant.  If None, the default accountant is returned.
-        Returns
-        -------
-        default : BudgetAccountant
-            Returns a working BudgetAccountant, either the supplied `accountant` or the existing default.
-        """
-        if accountant is None:
-            if BudgetAccountant._default is None:
-                BudgetAccountant._default = BudgetAccountant()
-
-            return BudgetAccountant._default
-
-        if not isinstance(accountant, BudgetAccountant):
-            raise TypeError(
-                "Accountant must be of type BudgetAccountant, got {}".format(
-                    type(accountant)
-                )
-            )
-
-        return accountant
-
-    def set_default(self):
-        """Sets the current accountant to be the default when running functions and queries with diffprivlib.
-        Returns
-        -------
-        self : BudgetAccountant
-        """
-        BudgetAccountant._default = self
-        return self
-
-    @staticmethod
-    def pop_default():
-        """Pops the default BudgetAccountant from the class and returns it to the user.
-        Returns
-        -------
-        default : BudgetAccountant
-            Returns the existing default BudgetAccountant.
-        """
-        default = BudgetAccountant._default
-        BudgetAccountant._default = None
-        return default
+# MIT License
+#
+# Copyright (C) IBM Corporation 2019
+#
+# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
+# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
+# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
+# persons to whom the Software is furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
+# Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
+# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+# Source:
+# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/accountant.py
+
+# stdlib
+from numbers import Integral
+
+# third party
+import numpy as np  # type: ignore
+
+# pydp relative
+from .utils import Budget  # type: ignore
+from .utils import BudgetError
+from .validation import check_epsilon_delta  # type: ignore
+
+
+class BudgetAccountant:
+    """Privacy budget accountant for differential privacy.
+    This class creates a privacy budget accountant to track privacy spend across queries and other data accesses.  Once
+    initialised, the BudgetAccountant stores each privacy spend and iteratively updates the total budget spend, raising
+    an error when the budget ceiling (if specified) is exceeded.  The accountant can be initialised without any maximum
+    budget, to enable users track the total privacy spend of their actions without hindrance.
+    Parameters
+    ----------
+    epsilon : float, default: infinity
+        Epsilon budget ceiling of the accountant.
+    delta : float, default: 1.0
+        Delta budget ceiling of the accountant.
+    slack : float, default: 0.0
+        Slack allowed in delta spend.  Greater slack may reduce the overall epsilon spend.
+    spent_budget : list of tuples of the form (epsilon, delta), optional
+        List of tuples of pre-existing budget spends.  Allows for a new accountant to be initialised with spends
+        extracted from a previous instance.
+    Attributes
+    ----------
+    epsilon : float
+        Epsilon budget ceiling of the accountant.
+    delta : float
+        Delta budget ceiling of the accountant.
+    slack : float
+        The accountant's slack.  Can be modified at runtime, subject to the privacy budget not being exceeded.
+    spent_budget : list of tuples of the form (epsilon, delta)
+        The list of privacy spends recorded by the accountant.  Can be used in the initialisation of a new accountant.
+    """
+
+    _default = None
+
+    def __init__(self, epsilon=float("inf"), delta=1.0, slack=0.0, spent_budget=None):
+        check_epsilon_delta(epsilon, delta)
+        self.__epsilon = epsilon
+        self.__min_epsilon = 0 if epsilon == float("inf") else epsilon * 1e-14
+        self.__delta = delta
+        self.__spent_budget = []
+        self.slack = slack
+
+        if spent_budget is not None:
+            if not isinstance(spent_budget, list):
+                raise TypeError("spent_budget must be a list")
+
+            for _epsilon, _delta in spent_budget:
+                self.spend(_epsilon, _delta)
+
+    def __repr__(self, n_budget_max=5):
+        params = []
+        if self.epsilon != float("inf"):
+            params.append(f"epsilon={self.epsilon:g}")
+
+        if self.delta != 1:
+            params.append(f"delta={self.delta:g}")
+
+        if self.slack > 0:
+            params.append(f"slack={self.slack:g}")
+
+        if self.spent_budget:
+            if len(self.spent_budget) > n_budget_max:
+                params.append(
+                    "spent_budget=%s"
+                    % str(self.spent_budget[:n_budget_max] + ["..."]).replace("'", "")
+                )
+            else:
+                params.append(f"spent_budget={str(self.spent_budget)}")
+
+        return "BudgetAccountant(" + ", ".join(params) + ")"
+
+    def __enter__(self):
+        self.old_default = self.pop_default()
+        self.set_default()
+        return self
+
+    def __exit__(self, exc_type, exc_val, exc_tb):
+        self.pop_default()
+
+        if self.old_default is not None:
+            self.old_default.set_default()
+        del self.old_default
+
+    def __len__(self):
+        return len(self.spent_budget)
+
+    @property
+    def slack(self):
+        """Slack parameter for composition."""
+        return self.__slack
+
+    @slack.setter
+    def slack(self, slack):
+        if not 0 <= slack <= self.delta:
+            raise ValueError(
+                "Slack must be between 0 and delta ({}), inclusive. Got {}.".format(
+                    self.delta, slack
+                )
+            )
+
+        epsilon_spent, delta_spent = self.total(slack=slack)
+
+        if self.epsilon < epsilon_spent or self.delta < delta_spent:
+            raise BudgetError(
+                f"Privacy budget will be exceeded by changing slack to {slack}."
+            )
+
+        self.__slack = slack
+
+    @property
+    def spent_budget(self):
+        """List of tuples of the form (epsilon, delta) of spent privacy budget."""
+        return self.__spent_budget.copy()
+
+    @property
+    def epsilon(self):
+        """Epsilon privacy ceiling of the accountant."""
+        return self.__epsilon
+
+    @property
+    def delta(self):
+        """Delta privacy ceiling of the accountant."""
+        return self.__delta
+
+    def total(self, spent_budget=None, slack=None):
+        """Returns the total current privacy spend.
+        `spent_budget` and `slack` can be specified as parameters, otherwise the class values will be used.
+        Parameters
+        ----------
+        spent_budget : list of tuples of the form (epsilon, delta), optional
+            List of tuples of budget spends.  If not provided, the accountant's spends will be used.
+        slack : float, optional
+            Slack in delta for composition.  If not provided, the accountant's slack will be used.
+        Returns
+        -------
+        epsilon : float
+            Total epsilon spend.
+        delta : float
+            Total delta spend.
+        """
+        if spent_budget is None:
+            spent_budget = self.spent_budget
+        else:
+            for epsilon, delta in spent_budget:
+                check_epsilon_delta(epsilon, delta)
+
+        if slack is None:
+            slack = self.slack
+        elif not 0 <= slack <= self.delta:
+            raise ValueError(
+                "Slack must be between 0 and delta ({}), inclusive. Got {}.".format(
+                    self.delta, slack
+                )
+            )
+
+        epsilon_sum, epsilon_exp_sum, epsilon_sq_sum = 0, 0, 0
+
+        for epsilon, _ in spent_budget:
+            epsilon_sum += epsilon
+            epsilon_exp_sum += (1 - np.exp(-epsilon)) * epsilon / (1 + np.exp(-epsilon))
+            epsilon_sq_sum += epsilon**2
+
+        total_epsilon_naive = epsilon_sum
+        total_delta = self.__total_delta_safe(spent_budget, slack)
+
+        if slack == 0:
+            return Budget(total_epsilon_naive, total_delta)
+
+        total_epsilon_drv = epsilon_exp_sum + np.sqrt(
+            2 * epsilon_sq_sum * np.log(1 / slack)
+        )
+        total_epsilon_kov = epsilon_exp_sum + np.sqrt(
+            2 * epsilon_sq_sum * np.log(np.exp(1) + np.sqrt(epsilon_sq_sum) / slack)
+        )
+
+        return Budget(
+            min(total_epsilon_naive, total_epsilon_drv, total_epsilon_kov), total_delta
+        )
+
+    def check(self, epsilon, delta):
+        """Checks if the provided (epsilon,delta) can be spent without exceeding the accountant's budget ceiling.
+        Parameters
+        ----------
+        epsilon : float
+            Epsilon budget spend to check.
+        delta : float
+            Delta budget spend to check.
+        Returns
+        -------
+        bool
+            True if the budget can be spent, otherwise a :class:`.BudgetError` is raised.
+        Raises
+        ------
+        BudgetError
+            If the specified budget spend will result in the budget ceiling being exceeded.
+        """
+        check_epsilon_delta(epsilon, delta)
+        if self.epsilon == float("inf") and self.delta == 1:
+            return True
+
+        if 0 < epsilon < self.__min_epsilon:
+            raise ValueError(
+                "Epsilon must be at least {} if non-zero, got {}.".format(
+                    self.__min_epsilon, epsilon
+                )
+            )
+
+        spent_budget = self.spent_budget + [(epsilon, delta)]
+
+        if Budget(self.epsilon, self.delta) >= self.total(spent_budget=spent_budget):
+            return True
+
+        raise BudgetError(
+            "Privacy spend of ({},{}) not permissible; will exceed remaining privacy budget. "
+            "Use {}.{}() to check remaining budget.".format(
+                epsilon, delta, self.__class__.__name__, self.remaining.__name__
+            )
+        )
+
+    def remaining(self, k=1):
+        """Calculates the budget that remains to be spent.
+        Calculates the privacy budget that can be spent on `k` queries.  Spending this budget on `k` queries will
+        match the budget ceiling, assuming no floating point errors.
+        Parameters
+        ----------
+        k : int, default: 1
+            The number of queries for which to calculate the remaining budget.
+        Returns
+        -------
+        epsilon : float
+            Total epsilon spend remaining for `k` queries.
+        delta : float
+            Total delta spend remaining for `k` queries.
+        """
+        if not isinstance(k, Integral):
+            raise TypeError("k must be integer-valued, got {}.".format(type(k)))
+        if k < 1:
+            raise ValueError(f"k must be at least 1, got {k}.")
+
+        _, spent_delta = self.total()
+        delta = (
+            1 - ((1 - self.delta) / (1 - spent_delta)) ** (1 / k)
+            if spent_delta < 1.0
+            else 1.0
+        )
+        # delta = 1 - np.exp((np.log(1 - self.delta) - np.log(1 - spent_delta)) / k)
+
+        lower = 0
+        upper = self.epsilon
+        old_interval_size = (upper - lower) * 2
+
+        while old_interval_size > upper - lower:
+            old_interval_size = upper - lower
+            mid = (upper + lower) / 2
+
+            spent_budget = self.spent_budget + [(mid, 0)] * k
+            x_0, _ = self.total(spent_budget=spent_budget)
+
+            if x_0 >= self.epsilon:
+                upper = mid
+            if x_0 <= self.epsilon:
+                lower = mid
+
+        epsilon = (upper + lower) / 2
+
+        return Budget(epsilon, delta)
+
+    def spend(self, epsilon, delta):
+        """Spend the given privacy budget.
+        Instructs the accountant to spend the given epsilon and delta privacy budget, while ensuring the target budget
+        is not exceeded.
+        Parameters
+        ----------
+        epsilon : float
+            Epsilon privacy budget to spend.
+        delta : float
+            Delta privacy budget to spend.
+        Returns
+        -------
+        self : BudgetAccountant
+        """
+        self.check(epsilon, delta)
+        self.__spent_budget.append((epsilon, delta))
+        return self
+
+    @staticmethod
+    def __total_delta_safe(spent_budget, slack):
+        """
+        Calculate total delta spend of `spent_budget`, with special consideration for floating point arithmetic.
+        Should yield greater precision, especially for a large number of budget spends with very small delta.
+        Parameters
+        ----------
+        spent_budget: list of tuples of the form (epsilon, delta)
+            List of budget spends, for which the total delta spend is to be calculated.
+        slack: float
+            Delta slack parameter for composition of spends.
+        Returns
+        -------
+        float
+            Total delta spend.
+        """
+        delta_spend = [slack]
+        for _, delta in spent_budget:
+            delta_spend.append(delta)
+        delta_spend.sort()
+
+        # (1 - a) * (1 - b) = 1 - (a + b - a * b)
+        prod = 0
+        for delta in delta_spend:
+            prod += delta - prod * delta
+
+        return prod
+
+    @staticmethod
+    def load_default(accountant):
+        """Loads the default privacy budget accountant if none is supplied, otherwise checks that the supplied
+        accountant is a BudgetAccountant class.
+        An accountant can be set as the default using the `set_default()` method.  If no default has been set, a default
+        is created.
+        Parameters
+        ----------
+        accountant : BudgetAccountant or None
+            The supplied budget accountant.  If None, the default accountant is returned.
+        Returns
+        -------
+        default : BudgetAccountant
+            Returns a working BudgetAccountant, either the supplied `accountant` or the existing default.
+        """
+        if accountant is None:
+            if BudgetAccountant._default is None:
+                BudgetAccountant._default = BudgetAccountant()
+
+            return BudgetAccountant._default
+
+        if not isinstance(accountant, BudgetAccountant):
+            raise TypeError(
+                "Accountant must be of type BudgetAccountant, got {}".format(
+                    type(accountant)
+                )
+            )
+
+        return accountant
+
+    def set_default(self):
+        """Sets the current accountant to be the default when running functions and queries with diffprivlib.
+        Returns
+        -------
+        self : BudgetAccountant
+        """
+        BudgetAccountant._default = self
+        return self
+
+    @staticmethod
+    def pop_default():
+        """Pops the default BudgetAccountant from the class and returns it to the user.
+        Returns
+        -------
+        default : BudgetAccountant
+            Returns the existing default BudgetAccountant.
+        """
+        default = BudgetAccountant._default
+        BudgetAccountant._default = None
+        return default
```

## pydp/ml/util/utils.py

 * *Ordering differences only*

```diff
@@ -1,162 +1,162 @@
-# MIT License
-#
-# Copyright (C) IBM Corporation 2019
-#
-# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
-# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
-# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
-# persons to whom the Software is furnished to do so, subject to the following conditions:
-#
-# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
-# Software.
-#
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
-# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
-# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-# Source:
-# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/utils.py
-
-# stdlib
-import warnings
-
-# third party
-import numpy as np  # type: ignore
-
-# pydp relative
-from .validation import check_epsilon_delta  # type: ignore
-
-
-def global_seed(seed):
-    """Sets the seed for all random number generators, to guarantee reproducibility in experiments.
-    Parameters
-    ----------
-    seed : int
-        The seed value for the random number generators.
-    Returns
-    -------
-    None
-    """
-    np.random.seed(seed)
-
-
-def copy_docstring(source):
-    """Decorator function to copy a docstring from a `source` function to a `target` function.
-    The docstring is only copied if a docstring is present in `source`, and if none is present in `target`.  Takes
-    inspiration from similar in `matplotlib`.
-    Parameters
-    ----------
-    source : method
-        Source function from which to copy the docstring.  If ``source.__doc__`` is empty, do nothing.
-    Returns
-    -------
-    target : method
-        Target function with new docstring.
-    """
-
-    def copy_func(target):
-        if source.__doc__ and not target.__doc__:
-            target.__doc__ = source.__doc__
-        return target
-
-    return copy_func
-
-
-def warn_unused_args(args):
-    """Warn the user about supplying unused `args` to a pydp model.
-    Arguments can be supplied as a string, a list of strings, or a dictionary as supplied to kwargs.
-    Parameters
-    ----------
-    args : str or list or dict
-        Arguments for which warnings should be thrown.
-    Returns
-    -------
-    None
-    """
-    if isinstance(args, str):
-        args = [args]
-
-    if not isinstance(args, (dict, list)):
-        raise ValueError(
-            "args must be a string, a list of strings or a dictionary, got type '%s'."
-            % type(args)
-        )
-
-    for arg in args:
-        warnings.warn(
-            "Parameter '%s' is not functional in pydp.  Remove this parameter to suppress this "
-            "warning." % arg,
-            PyDPCompatibilityWarning,
-        )
-
-
-class Budget(tuple):
-    """Custom tuple subclass for privacy budgets of the form (epsilon, delta).
-    The ``Budget`` class allows for correct comparison/ordering of privacy budget, ensuring that both epsilon and delta
-    satisfy the comparison (tuples are compared lexicographically).  Additionally, tuples are represented with added
-    verbosity, labelling epsilon and delta appropriately.
-    Examples
-    --------
-    >>> from pydp.ml.util.utils import Budget
-    >>> Budget(1, 0.5)
-    (epsilon=1, delta=0.5)
-    >>> Budget(2, 0) >= Budget(1, 0.5)
-    False
-    >>> (2, 0) >= (1, 0.5) # Tuples are compared with lexicographic ordering
-    True
-    """
-
-    def __new__(cls, epsilon, delta):
-        check_epsilon_delta(epsilon, delta, allow_zero=True)
-        return tuple.__new__(cls, (epsilon, delta))
-
-    def __gt__(self, other):
-        if self.__ge__(other) and not self.__eq__(other):
-            return True
-        return False
-
-    def __ge__(self, other):
-        if self[0] >= other[0] and self[1] >= other[1]:
-            return True
-        return False
-
-    def __lt__(self, other):
-        if self.__le__(other) and not self.__eq__(other):
-            return True
-        return False
-
-    def __le__(self, other):
-        if self[0] <= other[0] and self[1] <= other[1]:
-            return True
-        return False
-
-    def __repr__(self):
-        return "(epsilon=%r, delta=%r)" % self
-
-
-class BudgetError(ValueError):
-    """Custom exception to capture the privacy budget being exceeded, typically controlled by a
-    :class:`.BudgetAccountant`.
-    For example, this exception may be raised when the user:
-        - Attempts to execute a query which would exceed the privacy budget of the accountant.
-        - Attempts to change the slack of the accountant in such a way that the existing budget spends would exceed the
-          accountant's budget.
-    """
-
-
-class PrivacyLeakWarning(RuntimeWarning):
-    """Custom warning to capture privacy leaks resulting from incorrect parameter setting.
-    For example, this warning may occur when the user:
-        - fails to specify the bounds or range of data to a model where required (e.g., `bounds=None` to
-          :class:`.GaussianNB`).
-        - inputs data to a model that falls outside the bounds or range originally specified.
-    """
-
-
-class PyDPWarning(RuntimeWarning):
-    """Custom warning to capture inherited class arguments that are not compatible with pydp.
-    The purpose of the warning is to alert the user of the incompatibility, but to continue execution having fixed the
-    incompatibility at runtime.
-    """
+# MIT License
+#
+# Copyright (C) IBM Corporation 2019
+#
+# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
+# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
+# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
+# persons to whom the Software is furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
+# Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
+# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+# Source:
+# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/utils.py
+
+# stdlib
+import warnings
+
+# third party
+import numpy as np  # type: ignore
+
+# pydp relative
+from .validation import check_epsilon_delta  # type: ignore
+
+
+def global_seed(seed):
+    """Sets the seed for all random number generators, to guarantee reproducibility in experiments.
+    Parameters
+    ----------
+    seed : int
+        The seed value for the random number generators.
+    Returns
+    -------
+    None
+    """
+    np.random.seed(seed)
+
+
+def copy_docstring(source):
+    """Decorator function to copy a docstring from a `source` function to a `target` function.
+    The docstring is only copied if a docstring is present in `source`, and if none is present in `target`.  Takes
+    inspiration from similar in `matplotlib`.
+    Parameters
+    ----------
+    source : method
+        Source function from which to copy the docstring.  If ``source.__doc__`` is empty, do nothing.
+    Returns
+    -------
+    target : method
+        Target function with new docstring.
+    """
+
+    def copy_func(target):
+        if source.__doc__ and not target.__doc__:
+            target.__doc__ = source.__doc__
+        return target
+
+    return copy_func
+
+
+def warn_unused_args(args):
+    """Warn the user about supplying unused `args` to a pydp model.
+    Arguments can be supplied as a string, a list of strings, or a dictionary as supplied to kwargs.
+    Parameters
+    ----------
+    args : str or list or dict
+        Arguments for which warnings should be thrown.
+    Returns
+    -------
+    None
+    """
+    if isinstance(args, str):
+        args = [args]
+
+    if not isinstance(args, (dict, list)):
+        raise ValueError(
+            "args must be a string, a list of strings or a dictionary, got type '%s'."
+            % type(args)
+        )
+
+    for arg in args:
+        warnings.warn(
+            "Parameter '%s' is not functional in pydp.  Remove this parameter to suppress this "
+            "warning." % arg,
+            PyDPCompatibilityWarning,
+        )
+
+
+class Budget(tuple):
+    """Custom tuple subclass for privacy budgets of the form (epsilon, delta).
+    The ``Budget`` class allows for correct comparison/ordering of privacy budget, ensuring that both epsilon and delta
+    satisfy the comparison (tuples are compared lexicographically).  Additionally, tuples are represented with added
+    verbosity, labelling epsilon and delta appropriately.
+    Examples
+    --------
+    >>> from pydp.ml.util.utils import Budget
+    >>> Budget(1, 0.5)
+    (epsilon=1, delta=0.5)
+    >>> Budget(2, 0) >= Budget(1, 0.5)
+    False
+    >>> (2, 0) >= (1, 0.5) # Tuples are compared with lexicographic ordering
+    True
+    """
+
+    def __new__(cls, epsilon, delta):
+        check_epsilon_delta(epsilon, delta, allow_zero=True)
+        return tuple.__new__(cls, (epsilon, delta))
+
+    def __gt__(self, other):
+        if self.__ge__(other) and not self.__eq__(other):
+            return True
+        return False
+
+    def __ge__(self, other):
+        if self[0] >= other[0] and self[1] >= other[1]:
+            return True
+        return False
+
+    def __lt__(self, other):
+        if self.__le__(other) and not self.__eq__(other):
+            return True
+        return False
+
+    def __le__(self, other):
+        if self[0] <= other[0] and self[1] <= other[1]:
+            return True
+        return False
+
+    def __repr__(self):
+        return "(epsilon=%r, delta=%r)" % self
+
+
+class BudgetError(ValueError):
+    """Custom exception to capture the privacy budget being exceeded, typically controlled by a
+    :class:`.BudgetAccountant`.
+    For example, this exception may be raised when the user:
+        - Attempts to execute a query which would exceed the privacy budget of the accountant.
+        - Attempts to change the slack of the accountant in such a way that the existing budget spends would exceed the
+          accountant's budget.
+    """
+
+
+class PrivacyLeakWarning(RuntimeWarning):
+    """Custom warning to capture privacy leaks resulting from incorrect parameter setting.
+    For example, this warning may occur when the user:
+        - fails to specify the bounds or range of data to a model where required (e.g., `bounds=None` to
+          :class:`.GaussianNB`).
+        - inputs data to a model that falls outside the bounds or range originally specified.
+    """
+
+
+class PyDPWarning(RuntimeWarning):
+    """Custom warning to capture inherited class arguments that are not compatible with pydp.
+    The purpose of the warning is to alert the user of the incompatibility, but to continue execution having fixed the
+    incompatibility at runtime.
+    """
```

## pydp/ml/util/validation.py

 * *Ordering differences only*

```diff
@@ -1,220 +1,220 @@
-# MIT License
-#
-# Copyright (C) IBM Corporation 2019
-#
-# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
-# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
-# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
-# persons to whom the Software is furnished to do so, subject to the following conditions:
-#
-# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
-# Software.
-#
-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
-# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
-# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
-# SOFTWARE.
-
-# Source:
-# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/validation.py
-
-# stdlib
-from numbers import Integral
-from numbers import Real
-
-# third party
-import numpy as np  # type: ignore
-
-
-def check_epsilon_delta(epsilon, delta, allow_zero=False):
-    """Checks that epsilon and delta are valid values for differential privacy.  Throws an error if checks fail,
-    otherwise returns nothing.
-    As well as the requirements of epsilon and delta separately, both cannot be simultaneously zero, unless
-    ``allow_zero`` is set to ``True``.
-    Parameters
-    ----------
-    epsilon : float
-        Epsilon parameter for differential privacy.  Must be non-negative.
-    delta : float
-        Delta parameter for differential privacy.  Must be on the unit interval, [0, 1].
-    allow_zero : bool, default: False
-        Allow epsilon and delta both be zero.
-    """
-    if not isinstance(epsilon, Real) or not isinstance(delta, Real):
-        raise TypeError("Epsilon and delta must be numeric")
-
-    if epsilon < 0:
-        raise ValueError("Epsilon must be non-negative")
-
-    if not 0 <= delta <= 1:
-        raise ValueError("Delta must be in [0, 1]")
-
-    if not allow_zero and epsilon + delta == 0:
-        raise ValueError("Epsilon and Delta cannot both be zero")
-
-
-def check_bounds(bounds, shape=0, min_separation=0.0, dtype=float):
-    """Input validation for the ``bounds`` parameter.
-    Checks that ``bounds`` is composed of a list of tuples of the form (lower, upper), where lower <= upper and both
-    are numeric.  Also checks that ``bounds`` contains the appropriate number of dimensions, and that there is a
-    ``min_separation`` between the bounds.
-    Parameters
-    ----------
-    bounds : tuple
-        Tuple of bounds of the form (min, max). `min` and `max` can either be scalars or 1-dimensional arrays.
-    shape : int, default: 0
-        Number of dimensions to be expected in ``bounds``.
-    min_separation : float, default: 0.0
-        The minimum separation between `lower` and `upper` of each dimension.  This separation is enforced if not
-        already satisfied.
-    dtype : data-type, default: float
-        Data type of the returned bounds.
-    Returns
-    -------
-    bounds : tuple
-    """
-    if not isinstance(bounds, tuple):
-        raise TypeError(
-            "Bounds must be specified as a tuple of (min, max), got {}.".format(
-                type(bounds)
-            )
-        )
-    if not isinstance(shape, Integral):
-        raise TypeError(
-            "shape parameter must be integer-valued, got {}.".format(type(shape))
-        )
-
-    lower, upper = bounds
-
-    if np.asarray(lower).size == 1 or np.asarray(upper).size == 1:
-        lower = np.ravel(lower).astype(dtype)
-        upper = np.ravel(upper).astype(dtype)
-    else:
-        lower = np.asarray(lower, dtype=dtype)
-        upper = np.asarray(upper, dtype=dtype)
-
-    if lower.shape != upper.shape:
-        raise ValueError("lower and upper bounds must be the same shape array")
-    if lower.ndim > 1:
-        raise ValueError(
-            "lower and upper bounds must be scalar or a 1-dimensional array"
-        )
-    if lower.size != shape and lower.size != 1:
-        raise ValueError(
-            "lower and upper bounds must have {} element(s), got {}.".format(
-                shape or 1, lower.size
-            )
-        )
-
-    n_bounds = lower.shape[0]
-
-    for i in range(n_bounds):
-        _lower = lower[i]
-        _upper = upper[i]
-
-        if not isinstance(_lower, Real) or not isinstance(_upper, Real):
-            raise TypeError(
-                "Each bound must be numeric, got {} ({}) and {} ({}).".format(
-                    _lower, type(_lower), _upper, type(_upper)
-                )
-            )
-
-        if _lower > _upper:
-            raise ValueError(
-                "For each bound, lower bound must be smaller than upper bound, got {}, {})".format(
-                    lower, upper
-                )
-            )
-
-        if _upper - _lower < min_separation:
-            mid = (_upper + _lower) / 2
-            lower[i] = mid - min_separation / 2
-            upper[i] = mid + min_separation / 2
-
-    if shape == 0:
-        return lower.item(), upper.item()
-
-    if n_bounds == 1:
-        lower = np.ones(shape, dtype=dtype) * lower.item()
-        upper = np.ones(shape, dtype=dtype) * upper.item()
-
-    return lower, upper
-
-
-def clip_to_norm(array, clip):
-    """Clips the examples of a 2-dimensional array to a given maximum norm.
-    Parameters
-    ----------
-    array : np.ndarray
-        Array to be clipped.  After clipping, all examples have a 2-norm of at most `clip`.
-    clip : float
-        Norm at which to clip each example
-    Returns
-    -------
-    array : np.ndarray
-        The clipped array.
-    """
-    if not isinstance(array, np.ndarray):
-        raise TypeError(
-            "Input array must be a numpy array, got {}.".format(type(array))
-        )
-    if array.ndim != 2:
-        raise ValueError(
-            f"input array must be 2-dimensional, got {array.ndim} dimensions."
-        )
-    if not isinstance(clip, Real):
-        raise TypeError("Clip value must be numeric, got {}.".format(type(clip)))
-    if clip <= 0:
-        raise ValueError(f"Clip value must be strictly positive, got {clip}.")
-
-    norms = np.linalg.norm(array, axis=1) / clip
-    norms[norms < 1] = 1
-
-    return array / norms[:, np.newaxis]
-
-
-def clip_to_bounds(array, bounds):
-    """Clips the examples of a 2-dimensional array to given bounds.
-    Parameters
-    ----------
-    array : np.ndarray
-        Array to be clipped.  After clipping, all examples have a 2-norm of at most `clip`.
-    bounds : tuple
-        Tuple of bounds of the form (min, max) which the array is to be clipped to. `min` and `max` must be scalar,
-        unless array is 2-dimensional.
-    Returns
-    -------
-    array : np.ndarray
-        The clipped array.
-    """
-    if not isinstance(array, np.ndarray):
-        raise TypeError(
-            "Input array must be a numpy array, got {}.".format(type(array))
-        )
-
-    if np.shape(bounds[0]) != np.shape(bounds[1]):
-        raise ValueError(
-            "Bounds must be of the same shape, got {} and {}.".format(
-                np.shape(bounds[0]), np.shape(bounds[1])
-            )
-        )
-
-    lower, upper = check_bounds(bounds, np.size(bounds[0]), min_separation=0)
-    clipped_array = array.copy()
-
-    if np.allclose(lower, np.min(lower)) and np.allclose(upper, np.max(upper)):
-        clipped_array = np.clip(clipped_array, np.min(lower), np.max(upper))
-    else:
-        if array.ndim != 2:
-            raise ValueError(
-                "For non-scalar bounds, input array must be 2-dimensional. Got %d dimensions."
-                % array.ndim
-            )
-
-        for feature in range(array.shape[1]):
-            clipped_array[:, feature] = np.clip(
-                array[:, feature], lower[feature], upper[feature]
-            )
-
-    return clipped_array
+# MIT License
+#
+# Copyright (C) IBM Corporation 2019
+#
+# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
+# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
+# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
+# persons to whom the Software is furnished to do so, subject to the following conditions:
+#
+# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
+# Software.
+#
+# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
+# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+# SOFTWARE.
+
+# Source:
+# https://github.com/IBM/differential-privacy-library/blob/main/diffprivlib/validation.py
+
+# stdlib
+from numbers import Integral
+from numbers import Real
+
+# third party
+import numpy as np  # type: ignore
+
+
+def check_epsilon_delta(epsilon, delta, allow_zero=False):
+    """Checks that epsilon and delta are valid values for differential privacy.  Throws an error if checks fail,
+    otherwise returns nothing.
+    As well as the requirements of epsilon and delta separately, both cannot be simultaneously zero, unless
+    ``allow_zero`` is set to ``True``.
+    Parameters
+    ----------
+    epsilon : float
+        Epsilon parameter for differential privacy.  Must be non-negative.
+    delta : float
+        Delta parameter for differential privacy.  Must be on the unit interval, [0, 1].
+    allow_zero : bool, default: False
+        Allow epsilon and delta both be zero.
+    """
+    if not isinstance(epsilon, Real) or not isinstance(delta, Real):
+        raise TypeError("Epsilon and delta must be numeric")
+
+    if epsilon < 0:
+        raise ValueError("Epsilon must be non-negative")
+
+    if not 0 <= delta <= 1:
+        raise ValueError("Delta must be in [0, 1]")
+
+    if not allow_zero and epsilon + delta == 0:
+        raise ValueError("Epsilon and Delta cannot both be zero")
+
+
+def check_bounds(bounds, shape=0, min_separation=0.0, dtype=float):
+    """Input validation for the ``bounds`` parameter.
+    Checks that ``bounds`` is composed of a list of tuples of the form (lower, upper), where lower <= upper and both
+    are numeric.  Also checks that ``bounds`` contains the appropriate number of dimensions, and that there is a
+    ``min_separation`` between the bounds.
+    Parameters
+    ----------
+    bounds : tuple
+        Tuple of bounds of the form (min, max). `min` and `max` can either be scalars or 1-dimensional arrays.
+    shape : int, default: 0
+        Number of dimensions to be expected in ``bounds``.
+    min_separation : float, default: 0.0
+        The minimum separation between `lower` and `upper` of each dimension.  This separation is enforced if not
+        already satisfied.
+    dtype : data-type, default: float
+        Data type of the returned bounds.
+    Returns
+    -------
+    bounds : tuple
+    """
+    if not isinstance(bounds, tuple):
+        raise TypeError(
+            "Bounds must be specified as a tuple of (min, max), got {}.".format(
+                type(bounds)
+            )
+        )
+    if not isinstance(shape, Integral):
+        raise TypeError(
+            "shape parameter must be integer-valued, got {}.".format(type(shape))
+        )
+
+    lower, upper = bounds
+
+    if np.asarray(lower).size == 1 or np.asarray(upper).size == 1:
+        lower = np.ravel(lower).astype(dtype)
+        upper = np.ravel(upper).astype(dtype)
+    else:
+        lower = np.asarray(lower, dtype=dtype)
+        upper = np.asarray(upper, dtype=dtype)
+
+    if lower.shape != upper.shape:
+        raise ValueError("lower and upper bounds must be the same shape array")
+    if lower.ndim > 1:
+        raise ValueError(
+            "lower and upper bounds must be scalar or a 1-dimensional array"
+        )
+    if lower.size != shape and lower.size != 1:
+        raise ValueError(
+            "lower and upper bounds must have {} element(s), got {}.".format(
+                shape or 1, lower.size
+            )
+        )
+
+    n_bounds = lower.shape[0]
+
+    for i in range(n_bounds):
+        _lower = lower[i]
+        _upper = upper[i]
+
+        if not isinstance(_lower, Real) or not isinstance(_upper, Real):
+            raise TypeError(
+                "Each bound must be numeric, got {} ({}) and {} ({}).".format(
+                    _lower, type(_lower), _upper, type(_upper)
+                )
+            )
+
+        if _lower > _upper:
+            raise ValueError(
+                "For each bound, lower bound must be smaller than upper bound, got {}, {})".format(
+                    lower, upper
+                )
+            )
+
+        if _upper - _lower < min_separation:
+            mid = (_upper + _lower) / 2
+            lower[i] = mid - min_separation / 2
+            upper[i] = mid + min_separation / 2
+
+    if shape == 0:
+        return lower.item(), upper.item()
+
+    if n_bounds == 1:
+        lower = np.ones(shape, dtype=dtype) * lower.item()
+        upper = np.ones(shape, dtype=dtype) * upper.item()
+
+    return lower, upper
+
+
+def clip_to_norm(array, clip):
+    """Clips the examples of a 2-dimensional array to a given maximum norm.
+    Parameters
+    ----------
+    array : np.ndarray
+        Array to be clipped.  After clipping, all examples have a 2-norm of at most `clip`.
+    clip : float
+        Norm at which to clip each example
+    Returns
+    -------
+    array : np.ndarray
+        The clipped array.
+    """
+    if not isinstance(array, np.ndarray):
+        raise TypeError(
+            "Input array must be a numpy array, got {}.".format(type(array))
+        )
+    if array.ndim != 2:
+        raise ValueError(
+            f"input array must be 2-dimensional, got {array.ndim} dimensions."
+        )
+    if not isinstance(clip, Real):
+        raise TypeError("Clip value must be numeric, got {}.".format(type(clip)))
+    if clip <= 0:
+        raise ValueError(f"Clip value must be strictly positive, got {clip}.")
+
+    norms = np.linalg.norm(array, axis=1) / clip
+    norms[norms < 1] = 1
+
+    return array / norms[:, np.newaxis]
+
+
+def clip_to_bounds(array, bounds):
+    """Clips the examples of a 2-dimensional array to given bounds.
+    Parameters
+    ----------
+    array : np.ndarray
+        Array to be clipped.  After clipping, all examples have a 2-norm of at most `clip`.
+    bounds : tuple
+        Tuple of bounds of the form (min, max) which the array is to be clipped to. `min` and `max` must be scalar,
+        unless array is 2-dimensional.
+    Returns
+    -------
+    array : np.ndarray
+        The clipped array.
+    """
+    if not isinstance(array, np.ndarray):
+        raise TypeError(
+            "Input array must be a numpy array, got {}.".format(type(array))
+        )
+
+    if np.shape(bounds[0]) != np.shape(bounds[1]):
+        raise ValueError(
+            "Bounds must be of the same shape, got {} and {}.".format(
+                np.shape(bounds[0]), np.shape(bounds[1])
+            )
+        )
+
+    lower, upper = check_bounds(bounds, np.size(bounds[0]), min_separation=0)
+    clipped_array = array.copy()
+
+    if np.allclose(lower, np.min(lower)) and np.allclose(upper, np.max(upper)):
+        clipped_array = np.clip(clipped_array, np.min(lower), np.max(upper))
+    else:
+        if array.ndim != 2:
+            raise ValueError(
+                "For non-scalar bounds, input array must be 2-dimensional. Got %d dimensions."
+                % array.ndim
+            )
+
+        for feature in range(array.shape[1]):
+            clipped_array[:, feature] = np.clip(
+                array[:, feature], lower[feature], upper[feature]
+            )
+
+    return clipped_array
```

## pydp/util/__init__.py

 * *Ordering differences only*

```diff
@@ -1,2 +1,2 @@
-# pydp relative
-from .._pydp._util import *  # type: ignore
+# pydp relative
+from .._pydp._util import *  # type: ignore
```

## Comparing `python_dp-1.1.3rc5.dist-info/LICENSE` & `python_dp-1.1.3rc6.dist-info/LICENSE`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,201 +1,201 @@
-                                 Apache License
-                           Version 2.0, January 2004
-                        http://www.apache.org/licenses/
-
-   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
-
-   1. Definitions.
-
-      "License" shall mean the terms and conditions for use, reproduction,
-      and distribution as defined by Sections 1 through 9 of this document.
-
-      "Licensor" shall mean the copyright owner or entity authorized by
-      the copyright owner that is granting the License.
-
-      "Legal Entity" shall mean the union of the acting entity and all
-      other entities that control, are controlled by, or are under common
-      control with that entity. For the purposes of this definition,
-      "control" means (i) the power, direct or indirect, to cause the
-      direction or management of such entity, whether by contract or
-      otherwise, or (ii) ownership of fifty percent (50%) or more of the
-      outstanding shares, or (iii) beneficial ownership of such entity.
-
-      "You" (or "Your") shall mean an individual or Legal Entity
-      exercising permissions granted by this License.
-
-      "Source" form shall mean the preferred form for making modifications,
-      including but not limited to software source code, documentation
-      source, and configuration files.
-
-      "Object" form shall mean any form resulting from mechanical
-      transformation or translation of a Source form, including but
-      not limited to compiled object code, generated documentation,
-      and conversions to other media types.
-
-      "Work" shall mean the work of authorship, whether in Source or
-      Object form, made available under the License, as indicated by a
-      copyright notice that is included in or attached to the work
-      (an example is provided in the Appendix below).
-
-      "Derivative Works" shall mean any work, whether in Source or Object
-      form, that is based on (or derived from) the Work and for which the
-      editorial revisions, annotations, elaborations, or other modifications
-      represent, as a whole, an original work of authorship. For the purposes
-      of this License, Derivative Works shall not include works that remain
-      separable from, or merely link (or bind by name) to the interfaces of,
-      the Work and Derivative Works thereof.
-
-      "Contribution" shall mean any work of authorship, including
-      the original version of the Work and any modifications or additions
-      to that Work or Derivative Works thereof, that is intentionally
-      submitted to Licensor for inclusion in the Work by the copyright owner
-      or by an individual or Legal Entity authorized to submit on behalf of
-      the copyright owner. For the purposes of this definition, "submitted"
-      means any form of electronic, verbal, or written communication sent
-      to the Licensor or its representatives, including but not limited to
-      communication on electronic mailing lists, source code control systems,
-      and issue tracking systems that are managed by, or on behalf of, the
-      Licensor for the purpose of discussing and improving the Work, but
-      excluding communication that is conspicuously marked or otherwise
-      designated in writing by the copyright owner as "Not a Contribution."
-
-      "Contributor" shall mean Licensor and any individual or Legal Entity
-      on behalf of whom a Contribution has been received by Licensor and
-      subsequently incorporated within the Work.
-
-   2. Grant of Copyright License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      copyright license to reproduce, prepare Derivative Works of,
-      publicly display, publicly perform, sublicense, and distribute the
-      Work and such Derivative Works in Source or Object form.
-
-   3. Grant of Patent License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      (except as stated in this section) patent license to make, have made,
-      use, offer to sell, sell, import, and otherwise transfer the Work,
-      where such license applies only to those patent claims licensable
-      by such Contributor that are necessarily infringed by their
-      Contribution(s) alone or by combination of their Contribution(s)
-      with the Work to which such Contribution(s) was submitted. If You
-      institute patent litigation against any entity (including a
-      cross-claim or counterclaim in a lawsuit) alleging that the Work
-      or a Contribution incorporated within the Work constitutes direct
-      or contributory patent infringement, then any patent licenses
-      granted to You under this License for that Work shall terminate
-      as of the date such litigation is filed.
-
-   4. Redistribution. You may reproduce and distribute copies of the
-      Work or Derivative Works thereof in any medium, with or without
-      modifications, and in Source or Object form, provided that You
-      meet the following conditions:
-
-      (a) You must give any other recipients of the Work or
-          Derivative Works a copy of this License; and
-
-      (b) You must cause any modified files to carry prominent notices
-          stating that You changed the files; and
-
-      (c) You must retain, in the Source form of any Derivative Works
-          that You distribute, all copyright, patent, trademark, and
-          attribution notices from the Source form of the Work,
-          excluding those notices that do not pertain to any part of
-          the Derivative Works; and
-
-      (d) If the Work includes a "NOTICE" text file as part of its
-          distribution, then any Derivative Works that You distribute must
-          include a readable copy of the attribution notices contained
-          within such NOTICE file, excluding those notices that do not
-          pertain to any part of the Derivative Works, in at least one
-          of the following places: within a NOTICE text file distributed
-          as part of the Derivative Works; within the Source form or
-          documentation, if provided along with the Derivative Works; or,
-          within a display generated by the Derivative Works, if and
-          wherever such third-party notices normally appear. The contents
-          of the NOTICE file are for informational purposes only and
-          do not modify the License. You may add Your own attribution
-          notices within Derivative Works that You distribute, alongside
-          or as an addendum to the NOTICE text from the Work, provided
-          that such additional attribution notices cannot be construed
-          as modifying the License.
-
-      You may add Your own copyright statement to Your modifications and
-      may provide additional or different license terms and conditions
-      for use, reproduction, or distribution of Your modifications, or
-      for any such Derivative Works as a whole, provided Your use,
-      reproduction, and distribution of the Work otherwise complies with
-      the conditions stated in this License.
-
-   5. Submission of Contributions. Unless You explicitly state otherwise,
-      any Contribution intentionally submitted for inclusion in the Work
-      by You to the Licensor shall be under the terms and conditions of
-      this License, without any additional terms or conditions.
-      Notwithstanding the above, nothing herein shall supersede or modify
-      the terms of any separate license agreement you may have executed
-      with Licensor regarding such Contributions.
-
-   6. Trademarks. This License does not grant permission to use the trade
-      names, trademarks, service marks, or product names of the Licensor,
-      except as required for reasonable and customary use in describing the
-      origin of the Work and reproducing the content of the NOTICE file.
-
-   7. Disclaimer of Warranty. Unless required by applicable law or
-      agreed to in writing, Licensor provides the Work (and each
-      Contributor provides its Contributions) on an "AS IS" BASIS,
-      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-      implied, including, without limitation, any warranties or conditions
-      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-      PARTICULAR PURPOSE. You are solely responsible for determining the
-      appropriateness of using or redistributing the Work and assume any
-      risks associated with Your exercise of permissions under this License.
-
-   8. Limitation of Liability. In no event and under no legal theory,
-      whether in tort (including negligence), contract, or otherwise,
-      unless required by applicable law (such as deliberate and grossly
-      negligent acts) or agreed to in writing, shall any Contributor be
-      liable to You for damages, including any direct, indirect, special,
-      incidental, or consequential damages of any character arising as a
-      result of this License or out of the use or inability to use the
-      Work (including but not limited to damages for loss of goodwill,
-      work stoppage, computer failure or malfunction, or any and all
-      other commercial damages or losses), even if such Contributor
-      has been advised of the possibility of such damages.
-
-   9. Accepting Warranty or Additional Liability. While redistributing
-      the Work or Derivative Works thereof, You may choose to offer,
-      and charge a fee for, acceptance of support, warranty, indemnity,
-      or other liability obligations and/or rights consistent with this
-      License. However, in accepting such obligations, You may act only
-      on Your own behalf and on Your sole responsibility, not on behalf
-      of any other Contributor, and only if You agree to indemnify,
-      defend, and hold each Contributor harmless for any liability
-      incurred by, or claims asserted against, such Contributor by reason
-      of your accepting any such warranty or additional liability.
-
-   END OF TERMS AND CONDITIONS
-
-   APPENDIX: How to apply the Apache License to your work.
-
-      To apply the Apache License to your work, attach the following
-      boilerplate notice, with the fields enclosed by brackets "[]"
-      replaced with your own identifying information. (Don't include
-      the brackets!)  The text should be enclosed in the appropriate
-      comment syntax for the file format. We also recommend that a
-      file or class name and description of purpose be included on the
-      same "printed page" as the copyright notice for easier
-      identification within third-party archives.
-
-   Copyright [yyyy] [name of copyright owner]
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets "[]"
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same "printed page" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
```

## Comparing `python_dp-1.1.3rc5.dist-info/METADATA` & `python_dp-1.1.3rc6.dist-info/METADATA`

 * *Files 12% similar despite different names*

```diff
@@ -1,132 +1,131 @@
-Metadata-Version: 2.1
-Name: python-dp
-Version: 1.1.3rc5
-Summary: Python API for Google's Differential Privacy library
-Home-page: https://github.com/OpenMined/PyDP
-Author: Chinmay Shah
-Author-email: chinmayshah3899@gmail.com
-License: Apache-2.0
-Keywords: pydp
-Classifier: Development Status :: 5 - Production/Stable
-Classifier: Intended Audience :: Developers
-Classifier: Natural Language :: English
-Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Python :: 3.10
-Requires-Python: >=3.7
-Description-Content-Type: text/x-rst
-License-File: LICENSE
-
-| |Tests| |Version| |License|
-
-Introduction to PyDP
-====================
-
-In today's data-driven world, more and more researchers and data
-scientists use machine learning to create better models or more innovative
-solutions for a better future.
-
-These models often tend to handle sensitive or personal data, which
-can cause privacy issues. For example, some AI models can memorize details about the data they've been trained on and could potentially leak these
-details later on.
-
-To help measure sensitive data leakage and reduce the possibility of
-it happening, there is a mathematical framework called differential
-privacy.
-
-In 2020, OpenMined created a Python wrapper for Google's `Differential
-Privacy <https://github.com/google/differential-privacy>`_ project
-called PyDP. The library provides a set of Îµ-differentially private algorithms,
-which can be used to produce aggregate statistics over numeric data sets containing
-private or sensitive information. Therefore, with PyDP you can control the
-privacy guarantee and accuracy of your model written in Python.
-
-**Things to remember about PyDP:**
-
--  ::rocket: Features differentially private algorithms including: BoundedMean, BoundedSum, Max, Count Above, Percentile, Min, Median, etc.
-
-  -  All the computation methods mentioned above use Laplace noise only (other noise mechanisms will be added soon! :smiley:).
-
--  ::fire: Currently supports Linux and macOS (Windows support coming soon :smiley:)
--  ::star: Use Python 3.6+. Support for Python 3.5 and below is deprecated.
-
-Installation
-------------
-
-To install PyDP, use the `PiPy <https://pip.pypa.io/en/stable/>`__
-package manager:
-
-.. code:: bash
-
-    pip install python-dp
-
-(If you have ``pip3`` separately for Python 3.x, use ``pip3 install python-dp``.)
-
-Examples
---------
-
-Refer to the `curated list <https://github.com/OpenMined/PyDP/tree/dev/examples>`__ of tutorials and sample code to learn more about the PyDP library.
-
-You can also get started with `an introduction to
-PyDP <https://github.com/OpenMined/PyDP/blob/dev/examples/Tutorial_1-carrots_demo/carrots_demo.ipynb>`__ (a Jupyter notebook) and `the carrots demo <https://github.com/OpenMined/PyDP/blob/dev/examples/Tutorial_1-carrots_demo/carrots.py>`__ (a Python file).
-
-Example: calculate the Bounded Mean
-
-.. code:: python
-
-    # Import PyDP
-    import pydp as dp
-    # Import the Bounded Mean algorithm
-    from pydp.algorithms.laplacian import BoundedMean
-
-    # Calculate the Bounded Mean
-    # Structure: `BoundedMean(epsilon: double, lower: int, upper: int)`
-    # `epsilon`: a Double, between 0 and 1, denoting the privacy threshold,
-    #            measures the acceptable loss of privacy (with 0 meaning no loss is acceptable)
-    # `lower` and `upper`: Integers, representing lower and upper bounds, respectively
-    x = BoundedMean(0.6, 1, 10)
-
-    # If the lower and upper bounds are not specified,
-    # PyDP automatically calculates these bounds
-    # x = BoundedMean(epsilon: double)
-    x = BoundedMean(0.6)
-
-    # Calculate the result
-    # Currently supported data types are integers and floats
-    # Future versions will support additional data types
-    # (Refer to https://github.com/OpenMined/PyDP/blob/dev/examples/carrots.py)
-    x.quick_result(input_data: list)
-
-Learning Resources
-------------------
-
-Go to `resources <https://github.com/OpenMined/PyDP/blob/dev/resources.md>`__ to learn more about differential privacy.
-
-Support and Community on Slack
-------------------------------
-
-If you have questions about the PyDP library, join `OpenMined's Slack <https://slack.openmined.org>`__ and check the **#lib\_pydp** channel. To follow the code source changes, join **#code\_dp\_python**.
-
-Contributing
-------------
-
-To contribute to the PyDP project, read the `guidelines <https://github.com/OpenMined/PyDP/blob/dev/contributing.md>`__.
-
-Pull requests are welcome. If you want to introduce major changes,
-please open an issue first to discuss what you would like to change.
-
-Please make sure to update tests as appropriate.
-
-
-   <!-- ## Contributors -->
-
-License
--------
-
-`Apache License 2.0 <https://choosealicense.com/licenses/apache-2.0/>`__
-
-.. |Tests| image:: https://img.shields.io/github/workflow/status/OpenMined/PyDP/Tests
-.. |Version| image:: https://img.shields.io/github/v/tag/OpenMined/PyDP?color=green&label=pypi
-.. |License| image:: https://img.shields.io/github/license/OpenMined/PyDP
+Metadata-Version: 2.1
+Name: python-dp
+Version: 1.1.3rc6
+Summary: Python API for Google's Differential Privacy library
+Home-page: https://github.com/OpenMined/PyDP
+Author: Chinmay Shah
+Author-email: chinmayshah3899@gmail.com
+License: Apache-2.0
+Keywords: pydp
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Intended Audience :: Developers
+Classifier: Natural Language :: English
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Requires-Python: >=3.7
+Description-Content-Type: text/x-rst
+License-File: LICENSE
+
+| |Tests| |Version| |License|
+
+Introduction to PyDP
+====================
+
+In today's data-driven world, more and more researchers and data
+scientists use machine learning to create better models or more innovative
+solutions for a better future.
+
+These models often tend to handle sensitive or personal data, which
+can cause privacy issues. For example, some AI models can memorize details about the data they've been trained on and could potentially leak these
+details later on.
+
+To help measure sensitive data leakage and reduce the possibility of
+it happening, there is a mathematical framework called differential
+privacy.
+
+In 2020, OpenMined created a Python wrapper for Google's `Differential
+Privacy <https://github.com/google/differential-privacy>`_ project
+called PyDP. The library provides a set of Îµ-differentially private algorithms,
+which can be used to produce aggregate statistics over numeric data sets containing
+private or sensitive information. Therefore, with PyDP you can control the
+privacy guarantee and accuracy of your model written in Python.
+
+**Things to remember about PyDP:**
+
+-  ::rocket: Features differentially private algorithms including: BoundedMean, BoundedSum, Max, Count Above, Percentile, Min, Median, etc.
+
+  -  All the computation methods mentioned above use Laplace noise only (other noise mechanisms will be added soon! :smiley:).
+
+-  ::fire: Currently supports Linux and macOS (Windows support coming soon :smiley:)
+-  ::star: Use Python 3.6+. Support for Python 3.5 and below is deprecated.
+
+Installation
+------------
+
+To install PyDP, use the `PiPy <https://pip.pypa.io/en/stable/>`__
+package manager:
+
+.. code:: bash
+
+    pip install python-dp
+
+(If you have ``pip3`` separately for Python 3.x, use ``pip3 install python-dp``.)
+
+Examples
+--------
+
+Refer to the `curated list <https://github.com/OpenMined/PyDP/tree/dev/examples>`__ of tutorials and sample code to learn more about the PyDP library.
+
+You can also get started with `an introduction to
+PyDP <https://github.com/OpenMined/PyDP/blob/dev/examples/Tutorial_1-carrots_demo/carrots_demo.ipynb>`__ (a Jupyter notebook) and `the carrots demo <https://github.com/OpenMined/PyDP/blob/dev/examples/Tutorial_1-carrots_demo/carrots.py>`__ (a Python file).
+
+Example: calculate the Bounded Mean
+
+.. code:: python
+
+    # Import PyDP
+    import pydp as dp
+    # Import the Bounded Mean algorithm
+    from pydp.algorithms.laplacian import BoundedMean
+
+    # Calculate the Bounded Mean
+    # Basic Structure: `BoundedMean(epsilon: float, lower_bound: Union[int, float, None], upper_bound: Union[int, float, None])`
+    # `epsilon`: a Double, between 0 and 1, denoting the privacy threshold,
+    #            measures the acceptable loss of privacy (with 0 meaning no loss is acceptable)
+    x = BoundedMean(epsilon=0.6, lower_bound=1, upper_bound=10)
+
+    # If the lower and upper bounds are not specified,
+    # PyDP automatically calculates these bounds
+    # x = BoundedMean(epsilon: float)
+    x = BoundedMean(0.6)
+
+    # Calculate the result
+    # Currently supported data types are integers and floats
+    # Future versions will support additional data types
+    # (Refer to https://github.com/OpenMined/PyDP/blob/dev/examples/carrots.py)
+    x.quick_result(input_data: list)
+
+Learning Resources
+------------------
+
+Go to `resources <https://github.com/OpenMined/PyDP/blob/dev/resources.md>`__ to learn more about differential privacy.
+
+Support and Community on Slack
+------------------------------
+
+If you have questions about the PyDP library, join `OpenMined's Slack <https://slack.openmined.org>`__ and check the **#lib\_pydp** channel. To follow the code source changes, join **#code\_dp\_python**.
+
+Contributing
+------------
+
+To contribute to the PyDP project, read the `guidelines <https://github.com/OpenMined/PyDP/blob/dev/contributing.md>`__.
+
+Pull requests are welcome. If you want to introduce major changes,
+please open an issue first to discuss what you would like to change.
+
+Please make sure to update tests as appropriate.
+
+
+   <!-- ## Contributors -->
+
+License
+-------
+
+`Apache License 2.0 <https://choosealicense.com/licenses/apache-2.0/>`__
+
+.. |Tests| image:: https://img.shields.io/github/workflow/status/OpenMined/PyDP/Tests
+.. |Version| image:: https://img.shields.io/github/v/tag/OpenMined/PyDP?color=green&label=pypi
+.. |License| image:: https://img.shields.io/github/license/OpenMined/PyDP
```

## Comparing `python_dp-1.1.3rc5.dist-info/RECORD` & `python_dp-1.1.3rc6.dist-info/RECORD`

 * *Files 17% similar despite different names*

```diff
@@ -1,31 +1,29 @@
-pydp/BUILD,sha256=_GjqspQjq6n33FXTTQIKYArKoXK0mNA5aCXvqhKAjeE,326
-pydp/__init__.py,sha256=3oGhBehKibMm45-6orXis_fPnd2bGflMmk5O4_T1fOE,164
-pydp/_pydp.so,sha256=3rEjKUMi-lwbx0udF9Q9JjoeAzi_5xjhHMbDFYjvoLM,21545544
-pydp/algorithms/__init__.py,sha256=PVOrGVwR4Y_cOKdLL6BRpfJt1qmiqVyMkThCyCXcJTM,198
-pydp/algorithms/_algorithm.py,sha256=W3IaWgWsQmNjE9ufH5n7hDp08-Db-TSdwIs52ZzoZB0,6381
-pydp/algorithms/numerical_mechanisms.py,sha256=-CmjlHxwPeETgcsA4Rhb6BRzpj6Zrv5U9m32YAea8XY,193
-pydp/algorithms/partition_selection.py,sha256=4YyFvY9vmfpIjSXz-w5P21ZL-jf4DkzInn9ifcXrAV8,2266
-pydp/algorithms/quantile_tree.py,sha256=oDVxOfPZ-QhAjEQfJF4Nv3sh1GEfokHbp4ri0yQmDdU,76
-pydp/algorithms/laplacian/__init__.py,sha256=Sco-LmSYS3GRL4Z6jPH07k7vYH9asxhiWYThqIhj8EQ,562
-pydp/algorithms/laplacian/_bounded_algorithms.py,sha256=enX_6ztq4rgzj_WdCLiGrSl-qaDMQOCHfjSH9BFR9VA,3281
-pydp/algorithms/laplacian/_count.py,sha256=l_YcPt55gybwhN0IFOIj6hiZAR5nGMwCbUOPrwQCMzg,582
-pydp/algorithms/laplacian/_percentile.py,sha256=kZoic3gcYUE6uxFpMb5eQRDUCE4Bxeo2aaFlMbttD94,896
-pydp/distributions/__init__.py,sha256=QvVxu2vzwLenz8iTil06s4ZuohcS6bnesp6_Oof2ZUs,53
-pydp/ml/__init__.py,sha256=9GtTlFpnYEbSnGRVcqQX2NuKKaI63boRxmJgg08CRgA,21
-pydp/ml/naive_bayes.py,sha256=jB3rf6Ve1LtYRmW0Gbx4vGiM8NurvfCFKjxohjvpcKs,15075
+pydp/__init__.py,sha256=TfP1aRM6DX8M0ibLeD1Wwy-mNrco5LxdccvNhen6kJE,174
+pydp/_pydp.pyd,sha256=O9-deP__JIAtuabG8S8WRNgbf-43IxvNrLR7O2UbcKE,8383488
+pydp/algorithms/__init__.py,sha256=ygqWOAbxbxCDiqwm0mTi3kFed261eD1jFq2NYjgIOyg,204
+pydp/algorithms/_algorithm.py,sha256=qceE2y7leUWhEn5Z06fS37GDyzhi5sYVNKsF1Cicdgs,6560
+pydp/algorithms/numerical_mechanisms.py,sha256=w5jO8a482UutZ7xEuuO7G-U08QAZhDJxclmEh2Od194,199
+pydp/algorithms/partition_selection.py,sha256=9AknwFkf6RBBQyHihP03tT_Sd2AWa07JBR5VF1mUlcw,3484
+pydp/algorithms/quantile_tree.py,sha256=FtewbdgdAc1g6MOx9r_JzNapcH1ryBDc5rr8c0TXczA,79
+pydp/algorithms/laplacian/__init__.py,sha256=o7TYtN1Cr9BuK9SLX61EZFgN30Jz8DzIqtvuV_c0DmY,584
+pydp/algorithms/laplacian/_bounded_algorithms.py,sha256=NACXYd5Cm5uzGgH3yrVNFScaYqN0gm62_9T_-TaCbD4,3376
+pydp/algorithms/laplacian/_count.py,sha256=q0knTShJtd7-QvtKdYZr5dky5Iq7W7tDZqWHdlAnTMQ,607
+pydp/algorithms/laplacian/_percentile.py,sha256=U_RqGqmYF-yhl01lIP0xKc0gbPsXy91_L9oqT9TrE0o,930
+pydp/distributions/__init__.py,sha256=hT-E8WPXVxjrV-N30qCNadkVNiaANCSdWlETitxDVSk,55
+pydp/ml/__init__.py,sha256=0EYQ8AC1xJw4y-Rpqqqs26fLki0CQTbxVURf2dFRLA8,22
+pydp/ml/naive_bayes.py,sha256=FYSSK21V_CemDtqPHTtx_lJ1oqp43eguLaw0vC0sJi8,15433
 pydp/ml/mechanisms/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pydp/ml/mechanisms/base.py,sha256=L6rLC2wAz7gfeD43eACARso7i11KkZyRdDgJrhiSrvY,10993
-pydp/ml/mechanisms/geometric.py,sha256=gQblgNV3DM-Q5OaHPMehOfLy5Ic-8-fiSKOP-aANMB4,7042
-pydp/ml/mechanisms/laplace.py,sha256=VeVLmm2UsrOC9o3G3mREe4Z8nK6GpmDJCBws1ZyVkgU,13236
+pydp/ml/mechanisms/base.py,sha256=PAo-l6q9ge6MpJ6ldAXIsN2ITfDvOsPFKbqpjIYQvBo,11314
+pydp/ml/mechanisms/geometric.py,sha256=k6u-n1nsTqlf9ARdNfg_eoc8V1-4AbuLe9FjTjWjalA,7254
+pydp/ml/mechanisms/laplace.py,sha256=PjkBXEOFJ7clfC2wbbU1Z_szGWlO96cf_70epWd5MZg,13659
 pydp/ml/util/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pydp/ml/util/accountant.py,sha256=GUoTKCzHkM0AqZIioeGfvnZobT6IpPbkThSWqcoGgNo,14298
-pydp/ml/util/utils.py,sha256=qtYlqwI79AZlHGlInsiUdTbhNWxAYDLcGnJEyfBdtLY,5775
-pydp/ml/util/validation.py,sha256=UR-MuXYTifwC7bZfI8qXedNe-rbzw6BiW7xkVST1ER4,8078
-pydp/util/__init__.py,sha256=L7ZzsCRLusmfeTz4nbhJmFLh3WKxHk-S0BawnS9eNlc,60
-python/BUILD,sha256=U7w81IgCzYXlLENijqRfw7tGBZLDjmuRpMhQJzsyYXE,217
+pydp/ml/util/accountant.py,sha256=LalbO3BBDnZ1iuaNUbaOHg6bn27jKOyn6a2KVe5BRHY,14691
+pydp/ml/util/utils.py,sha256=OqJ4K5yS4D4engreTMs_aHbheTCbUWujavNLnOXNeI8,5937
+pydp/ml/util/validation.py,sha256=NRM01QthDnUJKI3uYvvagTdPYoLWHpY86-HV4G6pneo,8298
+pydp/util/__init__.py,sha256=pIdEB23_rFkfEk7gXpj7NmIVDh5EfwRFdazoyoBRVH4,62
 python/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-python_dp-1.1.3rc5.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-python_dp-1.1.3rc5.dist-info/METADATA,sha256=S2HPBokYy-h-51Kjjh1iiDIIKfHwsjBgLjkFfzOjUOw,5144
-python_dp-1.1.3rc5.dist-info/WHEEL,sha256=hgZvrlQ16Hzt5qiSLL09qJyqip_-uMS7-HY4MCTupqU,110
-python_dp-1.1.3rc5.dist-info/top_level.txt,sha256=JzxGXAEJKX8Wb_stHZZN5vp4zqGxi-nOo027P-2vihQ,12
-python_dp-1.1.3rc5.dist-info/RECORD,,
+python_dp-1.1.3rc6.dist-info/LICENSE,sha256=HrhfyXIkWY2tGFK11kg7vPCqhgh5DcxleloqdhrpyMY,11558
+python_dp-1.1.3rc6.dist-info/METADATA,sha256=8XPIAKRrJTdTxkayGKliGWvexn0RWOkVN0RwS5EPsKU,5276
+python_dp-1.1.3rc6.dist-info/WHEEL,sha256=eep6QWEFiQfg2wcclssb_WY-D33AnLYLnEKGA9Rn-VU,100
+python_dp-1.1.3rc6.dist-info/top_level.txt,sha256=JzxGXAEJKX8Wb_stHZZN5vp4zqGxi-nOo027P-2vihQ,12
+python_dp-1.1.3rc6.dist-info/RECORD,,
```

