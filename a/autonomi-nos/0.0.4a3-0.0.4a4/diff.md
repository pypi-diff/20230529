# Comparing `tmp/autonomi_nos-0.0.4a3-py3-none-any.whl.zip` & `tmp/autonomi_nos-0.0.4a4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,60 +1,60 @@
-Zip file size: 55673 bytes, number of entries: 58
+Zip file size: 55908 bytes, number of entries: 58
 -rw-rw-r--  2.0 unx       50 b- defN 23-May-21 21:25 nos/__init__.py
 -rw-rw-r--  2.0 unx      561 b- defN 23-May-16 21:26 nos/constants.py
 -rw-rw-r--  2.0 unx       93 b- defN 23-May-11 04:43 nos/exceptions.py
 -rw-rw-r--  2.0 unx      940 b- defN 23-May-09 22:15 nos/logging.py
 -rw-rw-r--  2.0 unx     2778 b- defN 23-May-19 22:25 nos/protoc.py
--rw-rw-r--  2.0 unx       24 b- defN 23-May-28 06:15 nos/version.py
+-rw-rw-r--  2.0 unx       24 b- defN 23-May-29 00:52 nos/version.py
 -rw-rw-r--  2.0 unx      110 b- defN 23-May-05 08:07 nos/cli/benchmark.py
--rw-rw-r--  2.0 unx      455 b- defN 23-May-15 21:47 nos/cli/cli.py
+-rw-rw-r--  2.0 unx      446 b- defN 23-May-28 17:18 nos/cli/cli.py
 -rw-rw-r--  2.0 unx     1983 b- defN 23-May-15 21:47 nos/cli/docker.py
 -rw-rw-r--  2.0 unx     1294 b- defN 23-May-05 08:07 nos/cli/hub.py
--rw-rw-r--  2.0 unx     6202 b- defN 23-May-26 22:01 nos/cli/serve_grpc.py
+-rw-rw-r--  2.0 unx     6182 b- defN 23-May-28 17:18 nos/cli/predict.py
 -rw-rw-r--  2.0 unx     5962 b- defN 23-May-15 21:47 nos/cli/serve_http.py
 -rw-rw-r--  2.0 unx     3479 b- defN 23-May-15 21:47 nos/cli/system.py
 -rw-rw-r--  2.0 unx      425 b- defN 23-May-09 22:15 nos/cli/utils.py
--rw-rw-r--  2.0 unx      372 b- defN 23-May-26 22:01 nos/client/__init__.py
+-rw-rw-r--  2.0 unx      396 b- defN 23-May-29 00:49 nos/client/__init__.py
 -rw-rw-r--  2.0 unx       92 b- defN 23-May-11 04:42 nos/client/exceptions.py
--rw-rw-r--  2.0 unx    12429 b- defN 23-May-28 06:15 nos/client/grpc.py
--rw-rw-r--  2.0 unx      235 b- defN 23-May-28 01:27 nos/common/__init__.py
+-rw-rw-r--  2.0 unx    12429 b- defN 23-May-28 17:18 nos/client/grpc.py
+-rw-rw-r--  2.0 unx      259 b- defN 23-May-29 00:49 nos/common/__init__.py
 -rw-rw-r--  2.0 unx      204 b- defN 23-May-28 04:11 nos/common/cloudpickle.py
--rw-rw-r--  2.0 unx     3694 b- defN 23-May-28 04:01 nos/common/spec.py
+-rw-rw-r--  2.0 unx     3701 b- defN 23-May-29 00:56 nos/common/spec.py
 -rw-rw-r--  2.0 unx      518 b- defN 23-May-26 22:01 nos/common/tasks.py
--rw-rw-r--  2.0 unx     4555 b- defN 23-May-28 05:36 nos/common/types.py
+-rw-rw-r--  2.0 unx     5725 b- defN 23-May-29 00:48 nos/common/types.py
 -rw-rw-r--  2.0 unx     3470 b- defN 23-May-08 23:12 nos/examples/vid2bbox.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-May-18 17:00 nos/executors/__init__.py
 -rw-rw-r--  2.0 unx     7401 b- defN 23-May-26 22:01 nos/executors/ray.py
 -rw-rw-r--  2.0 unx     1246 b- defN 23-May-15 21:47 nos/experimental/conversion_flows/openmmlab/tensorrt/run_model.py
 -rw-rw-r--  2.0 unx     4559 b- defN 23-May-15 21:47 nos/experimental/http/__init__.py
 -rw-rw-r--  2.0 unx     1153 b- defN 23-May-15 21:47 nos/experimental/http/client.py
 -rw-rw-r--  2.0 unx     2605 b- defN 23-May-26 22:01 nos/experimental/http/ingress.py
 -rw-rw-r--  2.0 unx     2688 b- defN 23-May-15 21:47 nos/experimental/http/service.py
--rw-rw-r--  2.0 unx     3436 b- defN 23-May-26 22:01 nos/hub/__init__.py
+-rw-rw-r--  2.0 unx     3445 b- defN 23-May-28 17:29 nos/hub/__init__.py
 -rw-rw-r--  2.0 unx     2195 b- defN 23-May-19 04:30 nos/hub/config.py
 -rw-rw-r--  2.0 unx      242 b- defN 23-May-12 00:37 nos/models/__init__.py
 -rw-rw-r--  2.0 unx     3460 b- defN 23-May-27 23:33 nos/models/clip.py
--rw-rw-r--  2.0 unx     2804 b- defN 23-May-27 23:33 nos/models/faster_rcnn.py
+-rw-rw-r--  2.0 unx     2869 b- defN 23-May-28 17:18 nos/models/faster_rcnn.py
 -rw-rw-r--  2.0 unx     3150 b- defN 23-May-27 23:29 nos/models/stable_diffusion.py
 -rw-rw-r--  2.0 unx     2628 b- defN 23-May-26 22:01 nos/models/openmmlab/mmdetection/mmdetection.py
 -rw-rw-r--  2.0 unx      370 b- defN 23-May-09 22:15 nos/models/openmmlab/mmdetection/configs/_base_/default_runtime.py
 -rw-rw-r--  2.0 unx     3187 b- defN 23-May-09 22:15 nos/models/openmmlab/mmdetection/configs/_base_/datasets/coco_detection.py
 -rw-rw-r--  2.0 unx     1765 b- defN 23-May-09 22:15 nos/models/openmmlab/mmdetection/configs/_base_/datasets/coco_instance.py
 -rw-rw-r--  2.0 unx     3828 b- defN 23-May-10 02:43 nos/models/openmmlab/mmdetection/configs/_base_/models/faster-rcnn_r50_fpn.py
 -rw-rw-r--  2.0 unx      304 b- defN 23-May-09 22:15 nos/models/openmmlab/mmdetection/configs/_base_/schedules/schedule_1x.py
 -rw-rw-r--  2.0 unx     5340 b- defN 23-May-09 22:15 nos/models/openmmlab/mmdetection/configs/efficientdet/efficientdet_effb3_bifpn_8xb16-crop896-300e_coco.py
 -rw-rw-r--  2.0 unx      177 b- defN 23-May-10 02:43 nos/models/openmmlab/mmdetection/configs/faster-rcnn/faster-rcnn_r50_fpn_1x_coco.py
 -rw-rw-r--  2.0 unx     2437 b- defN 23-May-26 22:01 nos/proto/nos_service.proto
 -rw-rw-r--  2.0 unx        0 b- defN 23-May-23 17:24 nos/server/__init__.py
 -rw-rw-r--  2.0 unx     6229 b- defN 23-May-19 03:42 nos/server/docker.py
 -rw-rw-r--  2.0 unx     2976 b- defN 23-May-22 17:53 nos/server/runtime.py
--rw-rw-r--  2.0 unx    10065 b- defN 23-May-28 04:10 nos/server/service.py
+-rw-rw-r--  2.0 unx    10133 b- defN 23-May-28 17:19 nos/server/service.py
 -rw-rw-r--  2.0 unx      373 b- defN 23-May-05 08:07 nos/test/benchmark.py
 -rw-rw-r--  2.0 unx     5764 b- defN 23-May-26 22:01 nos/test/conftest.py
 -rw-rw-r--  2.0 unx     1347 b- defN 23-May-21 21:52 nos/test/utils.py
--rw-r--r--  2.0 unx     1068 b- defN 23-May-28 06:16 autonomi_nos-0.0.4a3.dist-info/LICENSE
--rw-rw-r--  2.0 unx     6257 b- defN 23-May-28 06:16 autonomi_nos-0.0.4a3.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-May-28 06:16 autonomi_nos-0.0.4a3.dist-info/WHEEL
--rw-rw-r--  2.0 unx       86 b- defN 23-May-28 06:16 autonomi_nos-0.0.4a3.dist-info/entry_points.txt
--rw-rw-r--  2.0 unx       12 b- defN 23-May-28 06:16 autonomi_nos-0.0.4a3.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     5016 b- defN 23-May-28 06:16 autonomi_nos-0.0.4a3.dist-info/RECORD
-58 files, 144185 bytes uncompressed, 47651 bytes compressed:  67.0%
+-rw-r--r--  2.0 unx     1068 b- defN 23-May-29 16:34 autonomi_nos-0.0.4a4.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     6257 b- defN 23-May-29 16:34 autonomi_nos-0.0.4a4.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-May-29 16:34 autonomi_nos-0.0.4a4.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       86 b- defN 23-May-29 16:34 autonomi_nos-0.0.4a4.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx       12 b- defN 23-May-29 16:34 autonomi_nos-0.0.4a4.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     5013 b- defN 23-May-29 16:34 autonomi_nos-0.0.4a4.dist-info/RECORD
+58 files, 145520 bytes uncompressed, 47892 bytes compressed:  67.1%
```

## zipnote {}

```diff
@@ -24,15 +24,15 @@
 
 Filename: nos/cli/docker.py
 Comment: 
 
 Filename: nos/cli/hub.py
 Comment: 
 
-Filename: nos/cli/serve_grpc.py
+Filename: nos/cli/predict.py
 Comment: 
 
 Filename: nos/cli/serve_http.py
 Comment: 
 
 Filename: nos/cli/system.py
 Comment: 
@@ -150,26 +150,26 @@
 
 Filename: nos/test/conftest.py
 Comment: 
 
 Filename: nos/test/utils.py
 Comment: 
 
-Filename: autonomi_nos-0.0.4a3.dist-info/LICENSE
+Filename: autonomi_nos-0.0.4a4.dist-info/LICENSE
 Comment: 
 
-Filename: autonomi_nos-0.0.4a3.dist-info/METADATA
+Filename: autonomi_nos-0.0.4a4.dist-info/METADATA
 Comment: 
 
-Filename: autonomi_nos-0.0.4a3.dist-info/WHEEL
+Filename: autonomi_nos-0.0.4a4.dist-info/WHEEL
 Comment: 
 
-Filename: autonomi_nos-0.0.4a3.dist-info/entry_points.txt
+Filename: autonomi_nos-0.0.4a4.dist-info/entry_points.txt
 Comment: 
 
-Filename: autonomi_nos-0.0.4a3.dist-info/top_level.txt
+Filename: autonomi_nos-0.0.4a4.dist-info/top_level.txt
 Comment: 
 
-Filename: autonomi_nos-0.0.4a3.dist-info/RECORD
+Filename: autonomi_nos-0.0.4a4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## nos/version.py

```diff
@@ -1 +1 @@
-__version__ = "0.0.4a3"
+__version__ = "0.0.4a4"
```

## nos/cli/cli.py

```diff
@@ -1,19 +1,19 @@
 import typer
 
 from nos.cli.benchmark import benchmark_cli
 from nos.cli.docker import docker_cli
 from nos.cli.hub import hub_cli
-from nos.cli.serve_grpc import serve_grpc_cli
+from nos.cli.predict import predict_cli
 from nos.cli.system import system_cli
 
 
 app_cli = typer.Typer(no_args_is_help=True)
 app_cli.add_typer(hub_cli)
 app_cli.add_typer(system_cli)
 app_cli.add_typer(benchmark_cli)
 app_cli.add_typer(docker_cli)
-app_cli.add_typer(serve_grpc_cli)
+app_cli.add_typer(predict_cli)
 
 
 if __name__ == "__main__":
     app_cli()
```

## nos/client/__init__.py

```diff
@@ -1,6 +1,6 @@
 from nos.client.exceptions import NosClientException  # noqa: F401
 from nos.client.grpc import InferenceClient  # noqa: F401
 from nos.common.spec import FunctionSignature, ModelSpec  # noqa: F401
 from nos.common.tasks import TaskType  # noqa: F401
-from nos.common.types import EmbeddingSpec, ImageSpec, TensorSpec  # noqa: F401
+from nos.common.types import Batch, EmbeddingSpec, ImageSpec, ImageT, TensorSpec, TensorT  # noqa: F401
 from nos.constants import DEFAULT_GRPC_PORT
```

## nos/common/__init__.py

```diff
@@ -1,6 +1,6 @@
 from typing import Any
 
 from .cloudpickle import dumps, loads
 from .spec import FunctionSignature, ModelSpec  # noqa: F401
 from .tasks import TaskType  # noqa: F401
-from .types import EmbeddingSpec, ImageSpec, TensorSpec  # noqa: F401
+from .types import Batch, EmbeddingSpec, ImageSpec, ImageT, TensorSpec, TensorT  # noqa: F401
```

## nos/common/spec.py

```diff
@@ -2,15 +2,15 @@
 from typing import Any, Callable, Dict, Optional, Tuple, Type, Union
 
 from pydantic import validator
 from pydantic.dataclasses import dataclass
 
 from nos.common.cloudpickle import dumps, loads
 from nos.common.tasks import TaskType
-from nos.common.types import EmbeddingSpec, ImageSpec, TensorSpec  # noqa: F401
+from nos.common.types import Batch, EmbeddingSpec, ImageSpec, TensorSpec  # noqa: F401
 
 
 @dataclass
 class FunctionSignature:
     """Function signature."""
 
     # TOFIX (spillai): Remove Any type, and explicitly define input/output types.
```

## nos/common/types.py

```diff
@@ -96,46 +96,67 @@
 
         Annotated requires atleast 2 parameters [type, metadata].
         Here `batch_size` is optional (i.e. Batch[T],
         is equivalent to Batch[T, None]).
         """
         if not isinstance(params, tuple):
             params = (params, None)
-        _, batch_size = params
+        if len(params) != 2:
+            raise TypeError(f"Invalid Batch parameters (T, batch_size), provided params={params}.")
+        object_type, batch_size = params
         if batch_size is not None:
             if isinstance(batch_size, int):
                 if batch_size < 1 or batch_size >= 65536:
                     raise ValueError(f"Invalid batch size [batch_size={batch_size}].")
             else:
                 raise TypeError(f"Invalid batch size type [type(batch_size)={type(batch_size)}].")
-        return Annotated[cls, params]
+        return Annotated[cls, object_type, batch_size]
 
 
 class TensorT(Generic[T]):
-    """Generic annotation/type-hint for batched data.
-
-    Inherits from typing.Annotated[T, x] (PEP 593) where T is the type,
-    and x is the metadata. The metadata is tpyically ignored,
-    but can be used to allow additional type checks and annotations
-    on the type.
-    """
-
     __slots__ = ()
 
     @typing._tp_cache
     def __class_getitem__(cls, params):
         """Support TensorT[type, tensor_spec].
 
         Annotated requires atleast 2 parameters [type, tensor_spec].
         Here `tensor_spec` is optional (i.e. TensorT[T],
         is equivalent to TensorT[T, None]).
+
+        Examples:
+            TensorT[np.ndarray, TensorSpec()] := Annotated[TensorT, np.ndarray, TensorSpec()]
+            TensorT[torch.Tensor, TensorSpec()] := Annotated[TensorT, torch.Tensor, TensorSpec()]
         """
         if not isinstance(params, tuple):
             params = (params, TensorSpec())
-        _, tensor_spec = params
+        if len(params) != 2:
+            raise TypeError(f"Invalid TensorT parameters (T, tensort_spec), provided params={params}.")
+        object_type, tensor_spec = params
         if tensor_spec is not None:
             if not isinstance(tensor_spec, TensorSpec):
                 raise TypeError(f"Invalid tensor_spec metadata [tensor_spec={type(tensor_spec)}].")
-        return Annotated[cls, params]
+        return Annotated[cls, object_type, tensor_spec]
 
 
-ImageT = TensorT
+class ImageT(Generic[T]):
+    __slots__ = ()
+
+    @typing._tp_cache
+    def __class_getitem__(cls, params):
+        """Support TensorT[type, image_spec].
+
+        Annotated requires atleast 2 parameters [type, image_spec].
+        Here `image_spec` is optional (i.e. ImageT[T], is equivalent to TensorT[T, ImageSpec()]).
+
+        Examples:
+            ImageT[PIL.Image.Image, ImageSpec()] := Annotated[ImageT, Image, ImageSpec()]
+        """
+        if not isinstance(params, tuple):
+            params = (params, ImageSpec())
+        if len(params) != 2:
+            raise TypeError(f"Invalid ImageT parameters (T, tensort_spec), provided params={params}.")
+        object_type, image_spec = params
+        if image_spec is not None:
+            if not isinstance(image_spec, ImageSpec):
+                raise TypeError(f"Invalid image_spec metadata [tensor_spec={type(image_spec)}].")
+        return Annotated[cls, object_type, image_spec]
```

## nos/hub/__init__.py

```diff
@@ -1,8 +1,8 @@
-from typing import Any, Dict, List, Optional, Type
+from typing import Any, Callable, Dict, List, Optional, Type
 
 from nos.common import FunctionSignature, ModelSpec, TaskType  # noqa: F401
 from nos.hub.config import HuggingFaceHubConfig, MMLabConfig, NosHubConfig, TorchHubConfig  # noqa: F401
 from nos.logging import logger
 
 
 class Hub:
@@ -65,15 +65,15 @@
         Returns:
             Any: Instantiated model.
         """
         spec: ModelSpec = cls.load_spec(model_name, task=task)
         return spec.cls(*spec.args, **spec.kwargs)
 
     @classmethod
-    def register(cls, model_name: str, task: TaskType, func_or_cls: Type[Any], **kwargs) -> None:
+    def register(cls, model_name: str, task: TaskType, func_or_cls: Callable, **kwargs) -> None:
         """Model registry decorator.
 
         Args:
             model_name (str): Model identifier (e.g. `openai/clip-vit-base-patch32`).
             task (TaskType): Task type (e.g. `TaskType.OBJECT_DETECTION_2D`).
             func_or_cls (Type[Any]): Model function or class.
         """
```

## nos/models/faster_rcnn.py

```diff
@@ -37,27 +37,27 @@
         self.model.eval()
 
     def predict(
         self, images: Union[Image.Image, np.ndarray, List[Image.Image], List[np.ndarray]]
     ) -> Dict[str, np.ndarray]:
         with torch.inference_mode():
             if isinstance(images, np.ndarray):
-                pass
+                images = [images]
             elif isinstance(images, Image.Image):
-                images = np.asarray(images)
+                images = [np.asarray(images)]
             elif isinstance(images, list):
-                raise ValueError("Batching not yet supported")
+                pass
 
-            img = F.to_tensor(images)
-            img = img.to(self.device)
-            predictions = self.model([img])
+            images = torch.stack([F.to_tensor(image) for image in images])
+            images = images.to(self.device)
+            predictions = self.model(images)
             return {
-                "scores": predictions[0]["boxes"].cpu().numpy(),
-                "labels": predictions[0]["labels"].cpu().numpy(),
-                "bboxes": predictions[0]["boxes"].cpu().numpy(),
+                "scores": [pred["boxes"].cpu().numpy() for pred in predictions],
+                "labels": [pred["labels"].cpu().numpy() for pred in predictions],
+                "bboxes": [pred["boxes"].cpu().numpy() for pred in predictions],
             }
 
 
 hub.register(
     "torchvision/fasterrcnn_mobilenet_v3_large_320_fpn",
     TaskType.OBJECT_DETECTION_2D,
     FasterRCNN,
```

## nos/server/service.py

```diff
@@ -1,7 +1,8 @@
+import copy
 from collections import OrderedDict
 from dataclasses import dataclass
 from typing import Union
 
 import grpc
 import numpy as np
 import ray
@@ -87,20 +88,20 @@
             raise ModelNotFoundError(f"Failed to load model spec: {model_name}, {e}")
 
         # If the model handle is full, pop the oldest model
         if len(self.model_handle) >= self.model_handle.maxlen:
             spec: ModelSpec = self.model_handle.popitem(last=False)
             self.delete_model(spec.name, task=spec.task)
             logger.info(f"Deleting oldest model: {model_name}")
-        logger.info(f"Initializing model: {model_name}")
+        logger.info(f"Initializing model with spec: {spec}")
 
         # Create the serve deployment from the model handle
         model_cls = spec.signature.func_or_cls
         actor_options = {"num_gpus": 1 if torch.cuda.is_available() else 0}
-        logger.debug(f"Creating actor: {actor_options}")
+        logger.debug(f"Creating actor: {actor_options}, {model_cls}")
         actor_cls = ray.remote(**actor_options)(model_cls)
         # Note: Currently one model per (model-name, task) is supported.
         self.model_handle[spec.id] = ModelHandle(
             spec, actor_cls.remote(*spec.signature.init_args, **spec.signature.init_kwargs)
         )
         logger.info(f"Created actor: {self.model_handle[spec.id]}, type={type(self.model_handle[spec.id])}")
         logger.info(f"Models ({len(self.model_handle)}): {self.model_handle.keys()}")
@@ -141,14 +142,15 @@
     def GetModelInfo(
         self, request: nos_service_pb2.ModelInfoRequest, context: grpc.ServicerContext
     ) -> nos_service_pb2.ModelInfoResponse:
         """Get model information."""
         try:
             model_info = request.request
             spec: ModelSpec = hub.load_spec(model_info.name, task=TaskType(model_info.task))
+            spec = copy.deepcopy(spec)
             spec.signature.func_or_cls = None
             spec.signature.init_args = ()
             spec.signature.init_kwargs = {}
             spec.signature.method_name = None
         except KeyError as e:
             context.abort(context, grpc.StatusCode.NOT_FOUND, str(e))
         return nos_service_pb2.ModelInfoResponse(
```

## Comparing `nos/cli/serve_grpc.py` & `nos/cli/predict.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,16 +1,15 @@
 """gRPC-based Client CLI for NOS.
 
 Usage:
-    $ nos serve-grpc --help
-    $ nos serve-grpc list
-    $ nos serve-grpc deploy -m stabilityai/stable-diffusion-v2
-    $ nos serve-grpc img2vec -i tests/test_data/test.jpg
-    $ nos serve-grpc txt2vec -i 'Hello World!'
-    $ nos serve-grpc txt2img -i 'a cat dancing on the grass'
+    $ nos predict --help
+    $ nos predict list
+    $ nos predict img2vec -i tests/test_data/test.jpg
+    $ nos predict txt2vec -i 'Hello World!'
+    $ nos predict txt2img -i 'a cat dancing on the grass'
 
 """
 import time
 from dataclasses import dataclass
 
 import rich.console
 import rich.status
@@ -18,49 +17,49 @@
 import typer
 
 from nos.client import InferenceClient
 from nos.client.exceptions import NosClientException
 from nos.common import TaskType
 
 
-serve_grpc_cli = typer.Typer(name="serve-grpc", help="NOS gRPC Serve CLI.", no_args_is_help=True)
+predict_cli = typer.Typer(name="predict", help="NOS gRPC Serve CLI.", no_args_is_help=True)
 console = rich.console.Console()
 
 
 @dataclass
 class gRPCConfig:
     """Common gRPC options"""
 
     address: str
     client: InferenceClient
 
 
-@serve_grpc_cli.callback()
+@predict_cli.callback()
 def grpc_config(
     ctx: typer.Context,
     address: str = typer.Option("[::]:50051", "-a", "--address", help="Address of the gRPC server."),
 ):
     """Common gRPC options"""
     client = InferenceClient(address)
     ctx.obj = gRPCConfig(address, client)
     # TODO (spillai): Deploy the gRPC server here in the background (as a docker daemon)
     # TOOD (spillai): Ping the gRPC server otherwise raise an error
 
 
-@serve_grpc_cli.command("list", help="List all gRPC deployments.")
-def _grpc_serve_list(ctx: typer.Context):
+@predict_cli.command("list", help="List all gRPC deployments.")
+def _list_models(ctx: typer.Context):
     """List all gRPC deployments."""
     try:
         models = ctx.obj.client.ListModels()
         console.print(models)
     except NosClientException as exc:
         console.print(f"[red] ✗ Failed to list models ({exc}).[/red]")
 
 
-@serve_grpc_cli.command("img2vec", help="Encode image into an embedding.")
+@predict_cli.command("img2vec", help="Encode image into an embedding.")
 def _predict_img2vec(
     ctx: typer.Context,
     model_name: str = typer.Option(
         "openai/clip-vit-base-patch32",
         "-m",
         "--model-name",
         help="Name of the model to use (e.g. openai/clip-vit-base-patch32).",
@@ -71,24 +70,24 @@
 
     img = Image.open(filename)
 
     st = time.perf_counter()
     # with rich.status.Status("[bold green] Generating embedding ...[/bold green]"):
     try:
         model = ctx.obj.client.Module(task=TaskType.IMAGE_EMBEDDING, model_name=model_name)
-        response = model(images=img)
+        response = model(images=[img])
     except NosClientException as exc:
         console.print(f"[red] ✗ Failed to encode image. [/red]\n[bold red]{exc}[/bold red]")
         return
     console.print(
         f"[bold green] ✓ Generated embedding ((1, {response['embedding'].shape[-1]}), time=~{(time.perf_counter() - st) * 1e3:.1f}ms) [/bold green]"
     )
 
 
-@serve_grpc_cli.command("txt2vec", help="Generate an embedding from a text prompt.")
+@predict_cli.command("txt2vec", help="Generate an embedding from a text prompt.")
 def _predict_txt2vec(
     ctx: typer.Context,
     model_name: str = typer.Option(
         "openai/clip-vit-base-patch32",
         "-m",
         "--model-name",
         help="Name of the model to use (e.g. openai/clip-vit-base-patch32).",
@@ -97,24 +96,24 @@
         ..., "-i", "--input", help="Prompt to generate image. (e.g. a cat dancing on the grass.)"
     ),
 ) -> None:
     st = time.perf_counter()
     with rich.status.Status("[bold green] Generating embedding ...[/bold green]"):
         try:
             model = ctx.obj.client.Module(task=TaskType.TEXT_EMBEDDING, model_name=model_name)
-            response = model(texts=prompt)
+            response = model(texts=[prompt])
         except NosClientException as exc:
             console.print(f"[red] ✗ Failed to generate image. [/red]\n[bold red]{exc}[/bold red]")
             return
     console.print(
         f"[bold green] ✓ Generated embedding ({response['embedding'][..., :].shape}..., time=~{(time.perf_counter() - st) * 1e3:.1f}ms) [/bold green]"
     )
 
 
-@serve_grpc_cli.command("txt2img", help="Generate an image from a text prompt.")
+@predict_cli.command("txt2img", help="Generate an image from a text prompt.")
 def _predict_txt2img(
     ctx: typer.Context,
     model_name: str = typer.Option(
         "stabilityai/stable-diffusion-2",
         "-m",
         "--model-name",
         help="Name of the model to use (e.g. stabilityai/stable-diffusion-2).",
@@ -124,24 +123,24 @@
     ),
     img_size: int = typer.Option(512, "-s", "--img-size", help="Image size to generate."),
 ) -> None:
     st = time.perf_counter()
     with rich.status.Status("[bold green] Generating image ...[/bold green]"):
         try:
             model = ctx.obj.client.Module(task=TaskType.IMAGE_GENERATION, model_name=model_name)
-            response = model(prompts=prompt)
+            response = model(prompts=[prompt])
         except NosClientException as exc:
             console.print(f"[red] ✗ Failed to generate image. [/red]\n[bold red]{exc}[/bold red]")
             return
     console.print(
         f"[bold green] ✓ Generated image ({response['images']}..., time=~{(time.perf_counter() - st) * 1e3:.1f}ms) [/bold green]"
     )
 
 
-@serve_grpc_cli.command("img2bbox", help="Predict bounding boxes from image.")
+@predict_cli.command("img2bbox", help="Predict bounding boxes from image.")
 def _predict_img2bbox(
     ctx: typer.Context,
     model_name: str = typer.Option(
         "torchvision/fasterrcnn_mobilenet_v3_large_320_fpn",
         "-m",
         "--model-name",
         help="Name of the model to use (e.g. torchvision/fasterrcnn_mobilenet_v3_large_320_fpn).",
@@ -152,15 +151,19 @@
 
     img = Image.open(filename).resize((640, 480))
     with rich.status.Status("[bold green] Predict bounding boxes ...[/bold green]"):
 
         st = time.perf_counter()
         try:
             model = ctx.obj.client.Module(task=TaskType.OBJECT_DETECTION_2D, model_name=model_name)
-            response = model(images=img)
+            response = model(
+                images=[
+                    img,
+                ]
+            )
             scores, labels, bboxes = response["bboxes"], response["scores"], response["labels"]
             console.print(
-                f"[bold green] ✓ Predicted bounding boxes (bboxes={bboxes.shape}, scores={scores.shape}, labels={labels.shape}, time=~{(time.perf_counter() - st) * 1e3:.1f}ms) [/bold green]"
+                f"[bold green] ✓ Predicted bounding boxes (bboxes={bboxes[0].shape}, scores={scores[0].shape}, labels={labels[0].shape}, time=~{(time.perf_counter() - st) * 1e3:.1f}ms) [/bold green]"
             )
         except NosClientException as exc:
             console.print(f"[red] ✗ Failed to predict bounding boxes. [/red]\n[bold red]{exc}[/bold red]")
             return
```

## Comparing `autonomi_nos-0.0.4a3.dist-info/LICENSE` & `autonomi_nos-0.0.4a4.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `autonomi_nos-0.0.4a3.dist-info/METADATA` & `autonomi_nos-0.0.4a4.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: autonomi-nos
-Version: 0.0.4a3
+Version: 0.0.4a4
 Summary: Nitrous oxide system (NOS) for computer-vision.
 License: MIT License
         
         Copyright (c) 2023 Autonomi AI
         
         Permission is hereby granted, free of charge, to any person obtaining a copy
         of this software and associated documentation files (the "Software"), to deal
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: autonomi-nos Version: 0.0.4a3 Summary: Nitrous
+Metadata-Version: 2.1 Name: autonomi-nos Version: 0.0.4a4 Summary: Nitrous
 oxide system (NOS) for computer-vision. License: MIT License Copyright (c) 2023
 Autonomi AI Permission is hereby granted, free of charge, to any person
 obtaining a copy of this software and associated documentation files (the
 "Software"), to deal in the Software without restriction, including without
 limitation the rights to use, copy, modify, merge, publish, distribute,
 sublicense, and/or sell copies of the Software, and to permit persons to whom
 the Software is furnished to do so, subject to the following conditions: The
```

## Comparing `autonomi_nos-0.0.4a3.dist-info/RECORD` & `autonomi_nos-0.0.4a4.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,58 +1,58 @@
 nos/__init__.py,sha256=51Y_o2LsEI8SmKeCFOZfz1aTYOCqrv8plfrpDyr_ILo,50
 nos/constants.py,sha256=j-nz48q31rE7eclMqkZH6xFJ0eGmtx2Jt5yr_wQA_1Y,561
 nos/exceptions.py,sha256=ocRCxTbzT_Q8WTobAbkbo4jl5a6F3xC_D2N7rtzfWeg,93
 nos/logging.py,sha256=D0QDNFGmAYshfnSC-ctEDSIeBO6TnLPz1babUmJGRSA,940
 nos/protoc.py,sha256=xUck1U30UqUEnTaFuWMGWagyDcIrjmcQo8xozqbypmI,2778
-nos/version.py,sha256=_F_fHgTBGYq2e7-TbhbE5I7jtO1VOzPKSeFDv6iVaAs,24
+nos/version.py,sha256=JLSwLnE-ot2_Nv7_Igf88GJOUdYe3EvUfeSjLkVGK7o,24
 nos/cli/benchmark.py,sha256=p-EGzEUDMFFv2hpB9Nn8-Xk1zW-hrYDaUzyNvWmSgzk,110
-nos/cli/cli.py,sha256=nO0Eg_zp7L6xt5ST0QteypNHky8TIms8JSOLsvtHhjY,455
+nos/cli/cli.py,sha256=JlkhPPinuMH6MFwm2TA97cZOWqYKXjQEORJ8eBSfw9M,446
 nos/cli/docker.py,sha256=uPGrLe8FlvwSNFGUqp-vw5VAZhCeyvrfUfwJZdqXypk,1983
 nos/cli/hub.py,sha256=USdzVgaZlPZABrrIZzCA7ySwXg1iseEk7GJ7iwanXIg,1294
-nos/cli/serve_grpc.py,sha256=ymFv5qfehj5jNnEOiku-Kp5oqjMUbl7pzG4eVYP3KhE,6202
+nos/cli/predict.py,sha256=7nZrQFFH5Zp-MNGcGCFKPxv7PlxkvIqWU5w35p1gjsQ,6182
 nos/cli/serve_http.py,sha256=xMwSE46-_uHLgif1gnJCRoLbBE3ttC2zkm2JXVooWg0,5962
 nos/cli/system.py,sha256=gFm8ngxyxcPThhjkgB8S8ZBmtYBcqLdSo4unaWTl0N8,3479
 nos/cli/utils.py,sha256=uR1lGZyyDEuflNvxKuAmVUP-DTE55PzZL5c0c3l2h4U,425
-nos/client/__init__.py,sha256=-J19VTXOiv9joF7SwPpoUW4_nBwq5_cBp8A1ghhFg70,372
+nos/client/__init__.py,sha256=oXG9pYr-XdtjExlDenSsleOzeCBzLGYIWwzD9-rkm6o,396
 nos/client/exceptions.py,sha256=Lqqeu_6oNSZgOUipXHFx20yeASJi9bEewpG1UYuy1gk,92
 nos/client/grpc.py,sha256=ELV1W7XyEq3WnSOWeGK-26vQHT9jKecbmqmP8HaF8_8,12429
-nos/common/__init__.py,sha256=Khg1qL0KMrW2-mMXipUktq2S43pVpb-pVqLsC7dSlo8,235
+nos/common/__init__.py,sha256=Y9F1EL0JF7FQLE49EyXLG1Pe02VmMc9mtthIFqiMnX4,259
 nos/common/cloudpickle.py,sha256=2VBtGaLHbVtKg9ICT-xUITweHQCd6PxsFobDKwSYE2I,204
-nos/common/spec.py,sha256=X9iaGnQLwSLl3faORUa2FMrhpJypVWdpJVIsOrGjv_s,3694
+nos/common/spec.py,sha256=mwLN3ocHj-2pmNhKXgf-RBCBNm2sfBQ6jNbQKOcuyaw,3701
 nos/common/tasks.py,sha256=AcEbh5gbpKt_77Ar9zRrRyiD8tyw264Wv2buyX9yxZ8,518
-nos/common/types.py,sha256=1EzLB5Oq1NZsyKmdz_vNbiDkZpvi7b80xcxHTq65LNA,4555
+nos/common/types.py,sha256=H026vunyM7tNfr4yphsV1VohhfWBQ8nPr4yINiuaIkA,5725
 nos/examples/vid2bbox.py,sha256=UNEYmxI5RILgpOz14m2LEr-WJdgrdHnFeIIsN91k88E,3470
 nos/executors/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 nos/executors/ray.py,sha256=aurGem2kgMMCdV-38kN6ozsNMbmKuIh4ywDEIuWNkBk,7401
 nos/experimental/conversion_flows/openmmlab/tensorrt/run_model.py,sha256=A8LoCm4YvApkw_AAAyGqNLKeAoqzK1xvBy4pLI_Y9TE,1246
 nos/experimental/http/__init__.py,sha256=5LrWYhbfJy60b1eHj_p5gq7huQqFxxt_ThErTEkrKyc,4559
 nos/experimental/http/client.py,sha256=IwsHUg1qQxf8dntIlRSHeabm3_akICgj2LtqzKxMCU8,1153
 nos/experimental/http/ingress.py,sha256=ih6GzTaFHDVxUPUJa0640A78WAY2COHpiZyHnlMFl6M,2605
 nos/experimental/http/service.py,sha256=cZvJ0cOnTr89oFioH9QrEaR3UGZDA3uq2TNgdSYPj7g,2688
-nos/hub/__init__.py,sha256=XqZ9yVrSnNGEPNfsc7pk6N0XS2nuiabZtEvaDtBbH8Y,3436
+nos/hub/__init__.py,sha256=_LLJIuawO06b1Be9Nan0LSXrKvE7wP5ZLI33MSHGXnc,3445
 nos/hub/config.py,sha256=DK0t6xrB6Sgf71YWnX_htNbbU4H2Bcdu9b7ujiA6QKY,2195
 nos/models/__init__.py,sha256=FMoBv4glDtKz1eCIvqOy0RDqWM6w0fP7fdT_NJR8Q3k,242
 nos/models/clip.py,sha256=ggVFUagLMZNA7N7U-sdvCGNRx4gF4qoW7C4Emjje6J0,3460
-nos/models/faster_rcnn.py,sha256=3q3COMvNDXYQLnWHLSfDLBnwq7X37YjKmPgloBSMM8s,2804
+nos/models/faster_rcnn.py,sha256=EA4XBbNMX_S-lqkoont9eoXsWhq99Bc0ycgg_K-xfSA,2869
 nos/models/stable_diffusion.py,sha256=q--CdCy0QLCEV5kfHOK8FOrUoQUhg63D6pVsdRnMLi4,3150
 nos/models/openmmlab/mmdetection/mmdetection.py,sha256=8M_30LRPv3UcrUuLq7MDB3UtKJPE_Ide5NhvfbBG1kM,2628
 nos/models/openmmlab/mmdetection/configs/_base_/default_runtime.py,sha256=tAbybUUg9TtBy_dqiXD5Zgl0kSs39JX7TiTeIYZrOUo,370
 nos/models/openmmlab/mmdetection/configs/_base_/datasets/coco_detection.py,sha256=MxNi_Sf1m8CNkR64vZWaFN2O2P2LBI1-EexpLr166YU,3187
 nos/models/openmmlab/mmdetection/configs/_base_/datasets/coco_instance.py,sha256=DVkj2zskGrXxiF6hVQ1ofsOsqQGHsdjAh5sXRkaxjiw,1765
 nos/models/openmmlab/mmdetection/configs/_base_/models/faster-rcnn_r50_fpn.py,sha256=Al2qpY2P-MzsfBCod5pjB6HrH7ZzFvQxICc1CVmpnRY,3828
 nos/models/openmmlab/mmdetection/configs/_base_/schedules/schedule_1x.py,sha256=G8gXisLhM7mBRlxrhTOLCsWD17zCyH7kBvVi7J4BICI,304
 nos/models/openmmlab/mmdetection/configs/efficientdet/efficientdet_effb3_bifpn_8xb16-crop896-300e_coco.py,sha256=RSkd9o1IO-YkWhIwnXU83tRyGeySiR1IMlSk14dTw9s,5340
 nos/models/openmmlab/mmdetection/configs/faster-rcnn/faster-rcnn_r50_fpn_1x_coco.py,sha256=Cm8lyQ3wOT5I9KR0m1TfTsPAGybs-buILRPLDZKzOPQ,177
 nos/proto/nos_service.proto,sha256=BEWdRsehHLaSjH2K2QEhtmaDqkwDZYdxKm1t4yg_0V8,2437
 nos/server/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 nos/server/docker.py,sha256=Wbob_pkHXKdMWliD2VTWw1U7R7dojBImYWZTeSNDfLY,6229
 nos/server/runtime.py,sha256=BzQsaMCBAxC73xfj2AR6RCjfWWOWwMQBAU0gxKut8rI,2976
-nos/server/service.py,sha256=B2PGt9hxY7zY1bGPC7y153XRNAEqY13jW2yFkfMnmGI,10065
+nos/server/service.py,sha256=1uihUmdkDlh4VoB1vnxRodSxaHS8qNWP1Qeh_srOeZ8,10133
 nos/test/benchmark.py,sha256=b_QMHfStY5iRjHGPZwaY7VrXzy_VeFKfjld9UEVbn-g,373
 nos/test/conftest.py,sha256=-mZNh-D-LsalJ5oL0NOW1B7G88o0W6rJ8dwNA08N8Ys,5764
 nos/test/utils.py,sha256=F8RTOZKIuYPguUOz3beERNbmCg3pYjvLFwS7bMp6ejw,1347
-autonomi_nos-0.0.4a3.dist-info/LICENSE,sha256=9TQFxQ2AkXOQuIHy9GueB_a18hayRXT7pDt9fJv9WLo,1068
-autonomi_nos-0.0.4a3.dist-info/METADATA,sha256=uqvuD2gQFTq7hzELBPD9TAiU4FkUKT-oyrGqi8Yf-t4,6257
-autonomi_nos-0.0.4a3.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-autonomi_nos-0.0.4a3.dist-info/entry_points.txt,sha256=UYtJAmFT3RPWmlKM11MMZvZPRHTeKyIh1BbZ3QpbsJs,86
-autonomi_nos-0.0.4a3.dist-info/top_level.txt,sha256=RgOntmzdTkyrY-Fj9H6bSke7af3bHLscoZnK1-7Aa8o,12
-autonomi_nos-0.0.4a3.dist-info/RECORD,,
+autonomi_nos-0.0.4a4.dist-info/LICENSE,sha256=9TQFxQ2AkXOQuIHy9GueB_a18hayRXT7pDt9fJv9WLo,1068
+autonomi_nos-0.0.4a4.dist-info/METADATA,sha256=NJ21pKwyTSznVmlBf12fuKXw_J-4ufjA8h4w7rgDmsA,6257
+autonomi_nos-0.0.4a4.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+autonomi_nos-0.0.4a4.dist-info/entry_points.txt,sha256=UYtJAmFT3RPWmlKM11MMZvZPRHTeKyIh1BbZ3QpbsJs,86
+autonomi_nos-0.0.4a4.dist-info/top_level.txt,sha256=RgOntmzdTkyrY-Fj9H6bSke7af3bHLscoZnK1-7Aa8o,12
+autonomi_nos-0.0.4a4.dist-info/RECORD,,
```

